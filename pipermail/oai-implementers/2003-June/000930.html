<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 3.2//EN">
<HTML>
 <HEAD>
   <TITLE> [OAI-implementers] Experience with large-scale harvesting
   </TITLE>
   <LINK REL="Index" HREF="index.html" >
   <LINK REL="made" HREF="mailto:hickey%40oclc.org">
   <META NAME="robots" CONTENT="index,nofollow">
   
   <LINK REL="Previous"  HREF="000929.html">
   <LINK REL="Next"  HREF="000931.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>[OAI-implementers] Experience with large-scale harvesting
   </H1>
    <B>Hickey,Thom
    </B> 
    <A HREF="mailto:hickey%40oclc.org"
       TITLE="[OAI-implementers] Experience with large-scale harvesting">hickey@oclc.org
       </A><BR>
    <I>Fri, 13 Jun 2003 15:59:59 -0400</I>
    <P><UL>
        <LI> Previous message: <A HREF="000929.html">[OAI-implementers] Registered Data Providers
</A></li>
        <LI> Next message: <A HREF="000931.html">[OAI-implementers] Fwd: [Oai-pear-devel] PEAR::OAI 0.4.0 Released
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#930">[ date ]</a>
              <a href="thread.html#930">[ thread ]</a>
              <a href="subject.html#930">[ subject ]</a>
              <a href="author.html#930">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--beginarticle-->
<PRE>This message is in MIME format. Since your mail reader does not understand
this format, some or all of this message may not be legible.

------_=_NextPart_001_01C331E6.5E75CAB2
Content-Type: text/plain;
	charset=&quot;iso-8859-1&quot;

Since creating a one-page Python OAI-PMH harvester (see an improved, even
shorter, version at  <A HREF="http://purl.oclc.org/net/hickey/oai/harvest.py">http://purl.oclc.org/net/hickey/oai/harvest.py</A>
&lt;<A HREF="http://purl.oclc.org/net/hickey/oai/harvest.py">http://purl.oclc.org/net/hickey/oai/harvest.py</A>&gt; ) , I've been seeing how
our OAI repositories perform on full harvests.
 
OCLC Research runs two main repositories of metadata about theses and
dissertations:
 
XTCat ( <A HREF="http://alcme.oclc.org/xtcat/">http://alcme.oclc.org/xtcat/</A> &lt;<A HREF="http://alcme.oclc.org/xtcat/">http://alcme.oclc.org/xtcat/</A>&gt; ) with
some 4.3 million bibliographic records 
NDLTD ( <A HREF="http://alcme.oclc.org/ndltd/">http://alcme.oclc.org/ndltd/</A> &lt;<A HREF="http://alcme.oclc.org/ndltd/">http://alcme.oclc.org/ndltd/</A>&gt; ) which
has around 38,000 records.
 
My workstation can harvest XTCat in around 90 minutes if compression is used
(over a 10 megabit line).  Without compression it takes at least half again
as long, and my machine is much busier.  I was slightly surprised at the
difference in bytes-received that compression makes:  8:1 for the larger
database and 7:1 for the smaller.
 
Harvesting at home via a cable modem takes slightly less than 4 hours to
harvest the 4.3 million records.  That is about 300 records/second.  Each
record is about 1,000 bytes (uncompressed).
 
The 90 minute harvest is 800 records/second (800,000 bytes/second).  The
best time observed for doing two harvests simultaneously was 120 minutes, or
1,200 records/second.  The most records/second observed was slightly more
than 1,400 records/second when running four simultaneous harvests, probably
close to the maximum rate the repository can support.
 
Running multiple harvests simultaneously did find a weakness in the
repository code, which would occasionally run out of memory.  We seem to
have that fixed now, but I expect that error recovery is important for
reliably accomplishing large harvests.
 
--Th

------_=_NextPart_001_01C331E6.5E75CAB2
Content-Type: text/html;
	charset=&quot;iso-8859-1&quot;

&lt;!DOCTYPE HTML PUBLIC &quot;-//W3C//DTD HTML 4.0 Transitional//EN&quot;&gt;
&lt;HTML&gt;&lt;HEAD&gt;
&lt;META HTTP-EQUIV=&quot;Content-Type&quot; CONTENT=&quot;text/html; charset=iso-8859-1&quot;&gt;


&lt;META content=&quot;MSHTML 6.00.2600.0&quot; name=GENERATOR&gt;&lt;/HEAD&gt;
&lt;BODY&gt;
&lt;DIV&gt;&lt;FONT face=Arial size=2&gt;&lt;SPAN class=776144917-13062003&gt;Since creating a 
one-page Python OAI-PMH harvester (see an improved,&amp;nbsp;even 
shorter,&amp;nbsp;version at&amp;nbsp;&lt;A 
href=&quot;<A HREF="http://purl.oclc.org/net/hickey/oai/harvest.py"">http://purl.oclc.org/net/hickey/oai/harvest.py&quot;</A>&gt;<A HREF="http://purl.oclc.org/net/hickey/oai/harvest.py</A">http://purl.oclc.org/net/hickey/oai/harvest.py&lt;/A</A>&gt;) 
, I've been seeing how our OAI repositories perform on full 
harvests.&lt;/SPAN&gt;&lt;/FONT&gt;&lt;/DIV&gt;
&lt;DIV&gt;&lt;FONT face=Arial size=2&gt;&lt;SPAN 
class=776144917-13062003&gt;&lt;/SPAN&gt;&lt;/FONT&gt;&amp;nbsp;&lt;/DIV&gt;
&lt;DIV&gt;&lt;FONT face=Arial size=2&gt;&lt;SPAN class=776144917-13062003&gt;OCLC Research runs 
two main repositories of metadata about theses and 
dissertations:&lt;/SPAN&gt;&lt;/FONT&gt;&lt;/DIV&gt;
&lt;DIV&gt;&lt;FONT face=Arial size=2&gt;&lt;SPAN 
class=776144917-13062003&gt;&lt;/SPAN&gt;&lt;/FONT&gt;&amp;nbsp;&lt;/DIV&gt;
&lt;DIV&gt;&lt;FONT face=Arial size=2&gt;&lt;SPAN class=776144917-13062003&gt;XTCat (&lt;A 
href=&quot;<A HREF="http://alcme.oclc.org/xtcat/"">http://alcme.oclc.org/xtcat/&quot;</A>&gt;<A HREF="http://alcme.oclc.org/xtcat/</A">http://alcme.oclc.org/xtcat/&lt;/A</A>&gt;)&amp;nbsp;with 
some 4.3 million bibliographic records &lt;/SPAN&gt;&lt;/FONT&gt;&lt;/DIV&gt;
&lt;DIV&gt;&lt;FONT face=Arial size=2&gt;&lt;SPAN class=776144917-13062003&gt;NDLTD (&lt;A 
href=&quot;<A HREF="http://alcme.oclc.org/ndltd/"">http://alcme.oclc.org/ndltd/&quot;</A>&gt;<A HREF="http://alcme.oclc.org/ndltd/</A">http://alcme.oclc.org/ndltd/&lt;/A</A>&gt;)&amp;nbsp;which 
has around 38,000 records.&lt;/SPAN&gt;&lt;/FONT&gt;&lt;/DIV&gt;
&lt;DIV&gt;&lt;FONT face=Arial size=2&gt;&lt;SPAN 
class=776144917-13062003&gt;&lt;/SPAN&gt;&lt;/FONT&gt;&amp;nbsp;&lt;/DIV&gt;
&lt;DIV&gt;&lt;FONT face=Arial size=2&gt;&lt;SPAN class=776144917-13062003&gt;My workstation can 
harvest XTCat in around 90 minutes if compression is used (over a 10 megabit 
line).&amp;nbsp; Without compression it takes at least half again as long, and my 
machine is much busier.&amp;nbsp; I was slightly surprised at the difference in 
bytes-received that compression makes:&amp;nbsp; 8:1 for the larger database and 7:1 
for the smaller.&lt;/SPAN&gt;&lt;/FONT&gt;&lt;/DIV&gt;
&lt;DIV&gt;&lt;FONT face=Arial size=2&gt;&lt;SPAN 
class=776144917-13062003&gt;&lt;/SPAN&gt;&lt;/FONT&gt;&amp;nbsp;&lt;/DIV&gt;
&lt;DIV&gt;&lt;FONT face=Arial size=2&gt;&lt;SPAN class=776144917-13062003&gt;Harvesting at home 
via a cable modem takes slightly less than 4 hours to harvest the 4.3 million 
records.&amp;nbsp; That is about 300 records/second.&amp;nbsp; Each record is about 
1,000 bytes (uncompressed).&lt;/SPAN&gt;&lt;/FONT&gt;&lt;/DIV&gt;
&lt;DIV&gt;&lt;FONT face=Arial size=2&gt;&lt;SPAN 
class=776144917-13062003&gt;&lt;/SPAN&gt;&lt;/FONT&gt;&amp;nbsp;&lt;/DIV&gt;
&lt;DIV&gt;&lt;FONT face=Arial size=2&gt;&lt;SPAN class=776144917-13062003&gt;The 90 minute 
harvest is 800 records/second (800,000 bytes/second).&amp;nbsp; The best time 
observed for doing two harvests simultaneously was 120 minutes, or 1,200 
records/second.&amp;nbsp; The most records/second observed was slightly more than 
1,400 records/second when running four simultaneous harvests, probably close to 
the maximum rate&amp;nbsp;the repository can support.&lt;/SPAN&gt;&lt;/FONT&gt;&lt;/DIV&gt;
&lt;DIV&gt;&lt;FONT face=Arial size=2&gt;&lt;SPAN 
class=776144917-13062003&gt;&lt;/SPAN&gt;&lt;/FONT&gt;&amp;nbsp;&lt;/DIV&gt;
&lt;DIV&gt;&lt;FONT face=Arial size=2&gt;&lt;SPAN class=776144917-13062003&gt;Running multiple 
harvests simultaneously did find a weakness in the repository code, which would 
occasionally run out of memory.&amp;nbsp;&amp;nbsp;We seem to have that fixed now, but I 
expect&amp;nbsp;that error recovery is important for reliably accomplishing large 
harvests.&lt;/SPAN&gt;&lt;/FONT&gt;&lt;/DIV&gt;
&lt;DIV&gt;&lt;FONT face=Arial size=2&gt;&lt;SPAN 
class=776144917-13062003&gt;&lt;/SPAN&gt;&lt;/FONT&gt;&amp;nbsp;&lt;/DIV&gt;
&lt;DIV&gt;&lt;FONT face=Arial size=2&gt;&lt;SPAN 
class=776144917-13062003&gt;--Th&lt;/SPAN&gt;&lt;/FONT&gt;&lt;/DIV&gt;&lt;/BODY&gt;&lt;/HTML&gt;

------_=_NextPart_001_01C331E6.5E75CAB2--

</PRE>
<!--endarticle-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI> Previous message: <A HREF="000929.html">[OAI-implementers] Registered Data Providers
</A></li>
	<LI> Next message: <A HREF="000931.html">[OAI-implementers] Fwd: [Oai-pear-devel] PEAR::OAI 0.4.0 Released
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#930">[ date ]</a>
              <a href="thread.html#930">[ thread ]</a>
              <a href="subject.html#930">[ subject ]</a>
              <a href="author.html#930">[ author ]</a>
         </LI>
       </UL>
</body></html>
