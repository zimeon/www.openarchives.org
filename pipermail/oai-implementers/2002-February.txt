From deridder@cs.utk.edu  Fri Feb  1 14:45:24 2002
From: deridder@cs.utk.edu (deridder)
Date: Fri, 1 Feb 2002 09:45:24 -0500 (EST)
Subject: [OAI-implementers] crosswalks out there?
In-Reply-To: <sc5954f4.093@salud.unm.edu>
Message-ID: <Pine.GSO.4.33.0202010936310.14817-100000@cetus3b.cs.utk.edu>

Hi folks, this is off the subject...

  One of the projects I've been asked to take a look at is
the feasibility of translating current formats of digitized
metadata into OAI-compliant records on the fly, for a search
engine to be used at/for one or more repositories.  This is
basically for folks who have *not* set up OAI-compliant
repositories, but who want to share their metadata via the
OAI harvesters (or other search engines) in OAI format.

  If you know of anyone working on a similar project--- or if
you know of existing translaters out there, please send me a contact
URL or email address.  If you yourself *have* such a translater in
use at your repository, please contact me and tell me how you
went about implementing it.
  Also, if you might be interested in making use of such a
translater, please tell me what format your files are currently in--
and if possible, send me a sample.

  Thanks!!

 --Jody DeRidder
   SunSITE Programmer
   University of Tennessee, Knoxville

***********************************************************
   PGPKey: http://www.cs.utk.edu/~deridder/jd-pgp.txt
***********************************************************


From hussein@vt.edu  Fri Feb  1 14:59:37 2002
From: hussein@vt.edu (Hussein Suleman)
Date: Fri, 01 Feb 2002 09:59:37 -0500
Subject: [OAI-implementers] crosswalks out there?
References: <Pine.GSO.4.33.0202010936310.14817-100000@cetus3b.cs.utk.edu>
Message-ID: <3C5AAD59.2000807@vt.edu>

hi

while i do not have a crosswalk per se, i have a perl package to make a 
collection of XML files into an OAI archive, using the filenames as 
identifiers, the directories as sets and a simple configuration file for 
the other info ...

you might be able to use this as a framework since it does on-the-fly 
transformations of the files into OAI metadata formats (the file could 
even be non-XML as long as a translator existed)

i don't think i linked it into the OAI website (yet) - but you can get 
it from:
  http://www.dlib.vt.edu/projects/OAI/software/oai-file/oai-file.html

ttfn
----hussein

deridder wrote:

> Hi folks, this is off the subject...
> 
>   One of the projects I've been asked to take a look at is
> the feasibility of translating current formats of digitized
> metadata into OAI-compliant records on the fly, for a search
> engine to be used at/for one or more repositories.  This is
> basically for folks who have *not* set up OAI-compliant
> repositories, but who want to share their metadata via the
> OAI harvesters (or other search engines) in OAI format.
> 
>   If you know of anyone working on a similar project--- or if
> you know of existing translaters out there, please send me a contact
> URL or email address.  If you yourself *have* such a translater in
> use at your repository, please contact me and tell me how you
> went about implementing it.
>   Also, if you might be interested in making use of such a
> translater, please tell me what format your files are currently in--
> and if possible, send me a sample.
> 
>   Thanks!!
> 
>  --Jody DeRidder
>    SunSITE Programmer
>    University of Tennessee, Knoxville
> 
> ***********************************************************
>    PGPKey: http://www.cs.utk.edu/~deridder/jd-pgp.txt
> ***********************************************************
> 
> _______________________________________________
> OAI-implementers mailing list
> OAI-implementers@oaisrv.nsdl.cornell.edu
> http://oaisrv.nsdl.cornell.edu/mailman/listinfo/oai-implementers
> 


-- 
======================================================================
hussein suleman - hussein@vt.edu - vtcs - http://www.husseinsspace.com
======================================================================


From zubair@cs.odu.edu  Fri Feb  1 15:14:46 2002
From: zubair@cs.odu.edu (zubair@cs.odu.edu)
Date: Fri, 1 Feb 2002 10:14:46 -0500
Subject: [OAI-implementers] crosswalks out there?
Message-ID: <OF4C193ED0.7C2ECB84-ON85256B53.00526EEC@cs.odu.edu>

Dear Jody:

We have been working on a similar project where we are developing a visual
tool that can be deployed on a Non-OAI compliant archive. This tool can be
used to define the mapping visually from the native format to oai_dc
format, and once this is done the tool can accept OAI request and on fly
convert the native format to oai_dc. The tool is self contained, it comes
with a light-weight http server and OAI request handler and is written in
Java. We have tried this tool for rfc1807 format.

Please note that this work is still in progress and the code is currently
not packaged nicely for easy distribution. However, If you are interested
in trying this out, we can work with you in setting up the tool at your
site to try it out.

Zubair






                                                                                                                                      
                    deridder <deridder@cs.utk.edu>                                                                                    
                    Sent by:                                    To:                                                                   
                    oai-implementers-admin@oaisrv.nsdl.c        cc:     <oai-implementers@oaisrv.nsdl.cornell.edu>                    
                    ornell.edu                                  Subject:     [OAI-implementers] crosswalks out there?                 
                                                                                                                                      
                                                                                                                                      
                    02/01/2002 09:45 AM                                                                                               
                                                                                                                                      
                                                                                                                                      





Hi folks, this is off the subject...

  One of the projects I've been asked to take a look at is
the feasibility of translating current formats of digitized
metadata into OAI-compliant records on the fly, for a search
engine to be used at/for one or more repositories.  This is
basically for folks who have *not* set up OAI-compliant
repositories, but who want to share their metadata via the
OAI harvesters (or other search engines) in OAI format.

  If you know of anyone working on a similar project--- or if
you know of existing translaters out there, please send me a contact
URL or email address.  If you yourself *have* such a translater in
use at your repository, please contact me and tell me how you
went about implementing it.
  Also, if you might be interested in making use of such a
translater, please tell me what format your files are currently in--
and if possible, send me a sample.

  Thanks!!

 --Jody DeRidder
   SunSITE Programmer
   University of Tennessee, Knoxville

***********************************************************
   PGPKey: http://www.cs.utk.edu/~deridder/jd-pgp.txt
***********************************************************

_______________________________________________
OAI-implementers mailing list
OAI-implementers@oaisrv.nsdl.cornell.edu
http://oaisrv.nsdl.cornell.edu/mailman/listinfo/oai-implementers




From stamer@uni-oldenburg.de  Fri Feb  1 16:03:10 2002
From: stamer@uni-oldenburg.de (Heinrich Stamerjohanns)
Date: Fri, 1 Feb 2002 17:03:10 +0100 (CET)
Subject: [OAI-implementers] crosswalks out there?
In-Reply-To: <Pine.GSO.4.33.0202010936310.14817-100000@cetus3b.cs.utk.edu>
Message-ID: <Pine.LNX.4.33.0202011632590.2727-100000@alexandria.physik.uni-oldenburg.de>

On Fri, 1 Feb 2002, deridder wrote:

>
> Hi folks, this is off the subject...
>
>   One of the projects I've been asked to take a look at is
> the feasibility of translating current formats of digitized
> metadata into OAI-compliant records on the fly, for a search
> engine to be used at/for one or more repositories.  This is
> basically for folks who have *not* set up OAI-compliant
> repositories, but who want to share their metadata via the
> OAI harvesters (or other search engines) in OAI format.
>
Hi,

We are converting SOIF (with some DC) records generated by Harvest to an
OAI-compliant form. Basically we scan through the filesystem, and convert
the SOIF records, collected by Harvest from many places, to DC data (if
there is enough metadata) and store the converted data in a database.

We have chosen not to do the conversion on-the fly. Although of course in
principle possible, it all depends on the quality of the metadata. We have
collected many records which turn out to have useless metadata. Even for
"listrecords" we would have to go through all of them again and again,
just to find out that the record has to be thrown away.

One advantage is also that is easier for us to check whether our mapping
and the normalizations (one really terrible thing with existing DC), and
the conversion to XML conformant data is correct.

It is just a bunch of scripts written in PHP, so if you are interested
send mail.

Heinrich

--
  Dr. Heinrich Stamerjohanns  Tel. +49-441-798-4276
  Department of Physics       stamer@uni-oldenburg.de
  University of Oldenburg     http://www.physik.uni-oldenburg.de/~stamer




From wunder@inktomi.com  Fri Feb  1 17:44:03 2002
From: wunder@inktomi.com (Walter Underwood)
Date: Fri, 01 Feb 2002 09:44:03 -0800
Subject: [OAI-implementers] DP9 and HTML metadata
In-Reply-To: <Pine.SOL.4.10.10201250006320.27005-100000@defiant.cs.odu.edu>
References: <Pine.SOL.4.10.10201250006320.27005-100000@defiant.cs.odu.edu>
Message-ID: <335412704.1012585443@diva.inktomi.com>

I have a search engine spidering the updated DP9 pages. Feel
free to give it a try. The index has about 65,000 documents in
it right now. There would be more, but DP9 is seeing a lot of
timeouts accessing the OAI servers, and the spider goes idle
for 10 minutes after each timeout in case it is a network
congestion problem.

Here is the engine:

  http://software-demo.ultraseek.com/?col=oai&qc=oai

Feel free to ask about how this was set up. The Inktomi engine
(formerly known as Ultraseek) is pretty widely used. It is the
web search engine for the institutions of over a third of the 
OAI technical committee (Cornell, Virginia Tech, NASA, LC,
MIT, CERN).

wunder
--
Walter Underwood
wunder@inktomi.com
Senior Staff Engineer, Inktomi
http://www.inktomi.com/


From Herbert.VandeSompel@bl.uk  Sat Feb  2 19:49:12 2002
From: Herbert.VandeSompel@bl.uk (Van de Sompel, Herbert)
Date: Sat, 2 Feb 2002 19:49:12 -0000
Subject: [OAI-implementers] OAI-PMH & SOAP
Message-ID: <F5753B6F5335D4118DEA00508BA54F5605BB7B37@nt-lonex1.bl.uk>

hi,

Following some recent mentioning of SOAP on oai-implementers, we felt it
would be informative to list some major reasons why the upcoming v.2.0 of
the OAI-PMH will not -- yet -- have a SOAP version: 

* At the occasion of the first public presentation of the OAI-PMH 1.0 (DC,
Jan 2001) it was announced that the protocol would be kept unchanged for a
period of approx 12-18 months in order to allow for thorough
experimentation.  Also, it was announced that a stabilized version of the
protocol, taking into account the feedback of implementers, would be
released at the end of that 18-month period.  In order not to demotivate
early implementers, a "promise" was made by the OAI that the stabilized
version would be kept as close to version 1.0/1.1 as possible.  Since
v.1.0/1.1 is a protocol layered on top of HTTP, it was felt strongly that
v.2.0 should -- at least -- also have a version that remained on that chosen
path.

* When starting the revision the OAI-PMH v.1.1., the OAI-tech group listed
approx. 20 issues for discussion.  One was the creation of a SOAP version of
the protocol (in addition to the HTTP-layered track).  Following the
procedure followed by oai-tech for this protocol revision, a white paper was
created by a member, which was brought forward for discussion.  Not a single
reaction was posted to the white paper, which presumably indicated the lack
of strong interest among the OAI-tech group and the communities it
represents. 

Next, again, following the OAI-tech procedure, the OAI Executive posted a
mail to OAI-tech suggesting to drop the SOAP path for version 2.0 of the
OAI-PMH.  The following motivations were given:

- No perceived demand (until very recently, there had been no postings re
SOAP on the oai-implementers list, which was created Jan 2001);

- SOAP-related activities may draw energy away from the ongoing efforts for
the stabilization of the current -- non-SOAP -- version of the protocol (at
this point in time we are 100% sure that it would have been impossible to
meet the 05/2002 deadline for the release of OAI-PMH 2.0 if we had decided
to create a SOAP version too);

- No overwhelming indication of the existence of SOAP champions in the
OAI-tech team, willing to lead an effort with this respect. 

In the same mail, the OAI-Executive suggested to finalize version 2.0 first,
and then take on a SOAP version of the protocol.  

This posting by the OAI-Exec resulted in 3 supportive mails from OAI-tech
members, and no opposition.  Later on, in a conference call where all issues
where brought up again, OAI-tech decided unanimously to focus efforts on
stabilization of the non-SOAP version of the protocol, meanwhile encouraging
experimentation with and exploration of the SOAP path, in order to get ready
for the release of a SOAP version somewhere down the line.

* Indirect feedback received from a group working on a SOAP-based "Z39.50
New Generation" protocol suggested that they were running into certain
issues caused by the lack of stability of SOAP.  

* v.2.0 of the protocol will be much more disentagled from HTTP than
v.1.0/1.1.  As a result, a move to a SOAP version seems to be a logical next
step.

Carl Lagoze & Herbert Van de Sompel
OAI Executive






*********************************************************************
The information contained in this e-mail is confidential and may be 
legally privileged. It is intended for the addressee(s) only. If you 
are not the intended recipient, please delete this e-mail and notify 
the postmaster@bl.uk : The contents of this e-mail must not be 
disclosed or copied without the sender's consent. 

The statements and opinions expressed in this message are those of 
the author and do not necessarily reflect those of the British 
Library. The British Library does not take any responsibility for 
the views of the author. 
*********************************************************************

From wunder@inktomi.com  Sat Feb  2 20:28:08 2002
From: wunder@inktomi.com (Walter Underwood)
Date: Sat, 02 Feb 2002 12:28:08 -0800
Subject: [OAI-implementers] OAI-PMH & SOAP
In-Reply-To: <F5753B6F5335D4118DEA00508BA54F5605BB7B37@nt-lonex1.bl.uk>
References: <F5753B6F5335D4118DEA00508BA54F5605BB7B37@nt-lonex1.bl.uk>
Message-ID: <10705016.1012652888@[0.0.0.0]>

Six months ago, SOAP was a new technology. Today, every major
software company has committed to it.

I've received two private responses strongly favoring a
SOAP-based OAI protocol.

OAI needs to make a better effort to include people outside of
the library community. For example, periodic postings to the
robots mailing list would seem almost necessary. Postings to
the (closed) OAI-tech list are not an effective way to get input.

Unlike the STARTS workshop, OAI seems to have almost no commercial
participation. This is unfortunate, because commercial harvester
technology is far ahead of public and academic technology.

This is a critical problem, because the primary users of OAI
will be harvesters. When metadata systems are developed without
the participation of users, the result will probably not work
well with harvesters. AGLS (Australian Government Locator Services)
is an example of a system which is a very poor match to modern robots.

"Build it and they will come" simply will not work for this
protocol. Currently, it is designed by providers, and for
providers. So only providers will use it.

wunder
--
Walter R. Underwood
Senior Staff Engineer
Inktomi Enterprise Search
http://search.inktomi.com/

From krichel@openlib.org  Sat Feb  2 21:25:41 2002
From: krichel@openlib.org (Thomas Krichel)
Date: Sat, 2 Feb 2002 15:25:41 -0600
Subject: [OAI-implementers] OAI-PMH & SOAP
In-Reply-To: <10705016.1012652888@[0.0.0.0]>; from wunder@inktomi.com on Sat, Feb 02, 2002 at 12:28:08PM -0800
References: <F5753B6F5335D4118DEA00508BA54F5605BB7B37@nt-lonex1.bl.uk> <10705016.1012652888@[0.0.0.0]>
Message-ID: <20020202152541.A18613@netec.wustl.edu>

  Walter Underwood writes

> Unlike the STARTS workshop, OAI seems to have almost no commercial
> participation. This is unfortunate, because commercial harvester
> technology is far ahead of public and academic technology.
> 
> This is a critical problem, because the primary users of OAI
> will be harvesters.

  I think that some notes on the background of OAI
  may help to put this into perspective. OAI was founded
  as an initiative to foster the interoperability between
  eprint initiatives. A harversting protocol and metadata
  scheme were produced. The harvesting protocol was  later on 
  "hijacked" as  general interoperability protocol by other groups
  working in the digital library setting. The OAI group
  felt that the protocol could be made sufficiently
  general so that it could be used outside the eprints
  community, without any loss to the eprints community.
  Thus the protocol is not planned as a general harvesting
  protocol for general contents.

> "Build it and they will come" simply will not work for this
> protocol. Currently, it is designed by providers, and for
> providers. So only providers will use it.

  It is true that there are a limited number of service
  providers out there. The stumbling block, in my 
  opinion is not with the harvesting protocol, but with
  the fact that there has not yet been sufficient community
  building around rich community specific metadata sets
  that would allow the construction of specific user
  services. Such a community building is a social
  process, not a technical one. Therefore it will
  take a long time. But OAI brings the right ethos, and
  that is what counts, as far as I am concerned.

  I am a member of the tech committee, but these remarks
  should be taken as personal. 

  Cheers,

  Thomas Krichel                              mailto:krichel@openlib.org
                                         http://openlib.org/home/krichel
                                     RePEc:per:1965-06-05:thomas_krichel



From hussein@vt.edu  Sat Feb  2 21:45:01 2002
From: hussein@vt.edu (Hussein Suleman)
Date: Sat, 02 Feb 2002 16:45:01 -0500
Subject: [OAI-implementers] OAI-PMH & SOAP
References: <F5753B6F5335D4118DEA00508BA54F5605BB7B37@nt-lonex1.bl.uk> <10705016.1012652888@[0.0.0.0]>
Message-ID: <3C5C5DDD.4070006@vt.edu>

hi

by my understanding of OAI, i think there are some slight misconceptions 
in this discussion and i am going to make a possibly non-pc attempt to 
address those from my personal perspective:

- OAI-PMH is not for everyone ... if we generalize it to serve the needs 
of every community it will not be as useful for the purposes for which 
it was intended originally (namely, high-quality metadata transfer among 
digital library systems)

- the primary users of OAI will not be "harvesters" (in the crawler 
sense) ... OAI is specifically NOT trying to create a better Google ... 
OAI-PMH is aimed at high-quality metadata transfer among managed digital 
libraries

- OAI-PMH is not the silver bullet ! this is a research project within 
the DL community. other people/communities ought to design protocols 
better suited to their needs (using SOAP if necessary).

this is not a political issue - most of us on this mailing list are 
technical/research people ... to all interested in SOAP, how about 
trying to implement OAI over SOAP and then discuss that ? this is after 
all an implementors mailing list ... personally, i am willing to try it 
- i just reread the SOAP spec the other day and it seems straightforward 
enough (to anyone willing to work with me, send me email). i cannot say 
"aye" or "nay" to SOAP until i have tested it and i think it is 
reasonable to expect the same of everyone else.

ttfn
----hussein

(yet another member of the tech committee, writing in a personal capacity)

-- 
======================================================================
hussein suleman - hussein@vt.edu - vtcs - http://www.husseinsspace.com
======================================================================


From wunder@inktomi.com  Sun Feb  3 00:34:08 2002
From: wunder@inktomi.com (Walter Underwood)
Date: Sat, 02 Feb 2002 16:34:08 -0800
Subject: [OAI-implementers] OAI-PMH & SOAP
In-Reply-To: <3C5C5DDD.4070006@vt.edu>
References: <F5753B6F5335D4118DEA00508BA54F5605BB7B37@nt-lonex1.bl.uk> <10705016.1012652888@[0.0.0.0]> <3C5C5DDD.4070006@vt.edu>
Message-ID: <11011175.1012667648@[0.0.0.0]>

--On Saturday, February 2, 2002 4:45 PM -0500 Hussein Suleman <hussein@vt.edu> wrote:
>
> - OAI-PMH is not for everyone ... if we generalize it to serve the needs
> of every community it will not be as useful for the purposes for which
> it was intended originally (namely, high-quality metadata transfer among
> digital library systems)

I want that library information to be easily available to all,
not just people willing to run a library-only protocol. I'm not
trying to make libraries different, or change the OAI goal.

With a SOAP protocol, any scripted web page can make a call to OAI.
Servers like DP9 and the repository explorer become very easy to
write. A professor's list of publications could be built from
the eprint data.

Many of our customers are libraries, or have libraries of valuable
docs. Pharaceutical and financial companies would love to have a
protocol like this. Customers regularly ask us how to deal with
metadata stored separately from documents.

> - the primary users of OAI will not be "harvesters" (in the crawler sense)
> ... OAI is specifically NOT trying to create a better Google ... OAI-PMH
> is aimed at high-quality metadata transfer among managed digital libraries

Well, Inktomi is a better Google, but that is a different issue.

PMH seems aimed at batch transfers between WAIS/Harvest style systems.
Modern spiders stopped doing that five years ago. We know a lot more
now. Modern spiders do incremental fetches, adaptive revisits, duplicate
detection, authentication, session cookies, etc.

We can share that experience.

For example, the current approach to lists (ListRecords) allows
a big server to accidentally mount a denial of service attack on a
client. All it has to do is return 1 million records of 1Kb each, and
watch the client die. That is bad.

In a safe list protocol, the client requests a number of results,
and the server is allowed to return fewer. That way, both sides are
safe.

> ... i cannot say "aye" or "nay" to SOAP until i have tested it and i
> think it is reasonable to expect the same of everyone else.

Or maybe not reasonable. The Aye's include: Microsoft, IBM, Sun, Apple,
Oracle, HP, Compaq, SAP, IONA, and so on. The Apache project has two
free implementations.

OAI is already using an XML RPC. Switching from a non-standard XML
RPC to a standard one should be an obvious decision.

Frankly, the only drawback to SOAP is that the interface definition
language, WSDL, is really ugly.

But go ahead and read the SOAP spec. It is rather clear and short
as these things go:

  http://www.w3.org/TR/SOAP/

wunder
--
Walter R. Underwood
Senior Staff Engineer
Inktomi Enterprise Search
http://search.inktomi.com/

From zubair@cs.odu.edu  Sun Feb  3 15:16:11 2002
From: zubair@cs.odu.edu (zubair@cs.odu.edu)
Date: Sun, 3 Feb 2002 10:16:11 -0500
Subject: [OAI-implementers] OAI-PMH & SOAP
Message-ID: <OFE26CFBC4.F2652D3F-ON85256B55.005206D8@cs.odu.edu>

I must admit that some of the points Walter is raising make sense to me
including the points he is making on the process. I am also excited to
learn that there is some interest in commercial sector regarding OAI, which
adds more credibility to our mission.    My personal opinion is that in
future (I hope there is one !) we should have some representation from the
Industry (people like  Walter) in the technical committee and the working
of technical committee should be more open.

Zubair



                                                                                                                                      
                    Walter Underwood                                                                                                  
                    <wunder@inktomi.com>                        To:     "'oai-implementers@oaisrv.nsdl.cornell.edu '"                 
                    Sent by:                                    <oai-implementers@oaisrv.nsdl.cornell.edu>                            
                    oai-implementers-admin@oaisrv.nsdl.c        cc:                                                                   
                    ornell.edu                                  Subject:     Re: [OAI-implementers] OAI-PMH & SOAP                    
                                                                                                                                      
                                                                                                                                      
                    02/02/2002 07:34 PM                                                                                               
                                                                                                                                      
                                                                                                                                      




--On Saturday, February 2, 2002 4:45 PM -0500 Hussein Suleman
<hussein@vt.edu> wrote:
>
> - OAI-PMH is not for everyone ... if we generalize it to serve the needs
> of every community it will not be as useful for the purposes for which
> it was intended originally (namely, high-quality metadata transfer among
> digital library systems)

I want that library information to be easily available to all,
not just people willing to run a library-only protocol. I'm not
trying to make libraries different, or change the OAI goal.

With a SOAP protocol, any scripted web page can make a call to OAI.
Servers like DP9 and the repository explorer become very easy to
write. A professor's list of publications could be built from
the eprint data.

Many of our customers are libraries, or have libraries of valuable
docs. Pharaceutical and financial companies would love to have a
protocol like this. Customers regularly ask us how to deal with
metadata stored separately from documents.

> - the primary users of OAI will not be "harvesters" (in the crawler
sense)
> ... OAI is specifically NOT trying to create a better Google ... OAI-PMH
> is aimed at high-quality metadata transfer among managed digital
libraries

Well, Inktomi is a better Google, but that is a different issue.

PMH seems aimed at batch transfers between WAIS/Harvest style systems.
Modern spiders stopped doing that five years ago. We know a lot more
now. Modern spiders do incremental fetches, adaptive revisits, duplicate
detection, authentication, session cookies, etc.

We can share that experience.

For example, the current approach to lists (ListRecords) allows
a big server to accidentally mount a denial of service attack on a
client. All it has to do is return 1 million records of 1Kb each, and
watch the client die. That is bad.

In a safe list protocol, the client requests a number of results,
and the server is allowed to return fewer. That way, both sides are
safe.

> ... i cannot say "aye" or "nay" to SOAP until i have tested it and i
> think it is reasonable to expect the same of everyone else.

Or maybe not reasonable. The Aye's include: Microsoft, IBM, Sun, Apple,
Oracle, HP, Compaq, SAP, IONA, and so on. The Apache project has two
free implementations.

OAI is already using an XML RPC. Switching from a non-standard XML
RPC to a standard one should be an obvious decision.

Frankly, the only drawback to SOAP is that the interface definition
language, WSDL, is really ugly.

But go ahead and read the SOAP spec. It is rather clear and short
as these things go:

  http://www.w3.org/TR/SOAP/

wunder
--
Walter R. Underwood
Senior Staff Engineer
Inktomi Enterprise Search
http://search.inktomi.com/
_______________________________________________
OAI-implementers mailing list
OAI-implementers@oaisrv.nsdl.cornell.edu
http://oaisrv.nsdl.cornell.edu/mailman/listinfo/oai-implementers




From T.W.Place@kub.nl  Sun Feb  3 16:30:26 2002
From: T.W.Place@kub.nl (Thomas Place)
Date: Sun, 03 Feb 2002 17:30:26 +0100
Subject: [OAI-implementers] OAI-PMH & SOAP
References: <F5753B6F5335D4118DEA00508BA54F5605BB7B37@nt-lonex1.bl.uk> <10705016.1012652888@[0.0.0.0]> <3C5C5DDD.4070006@vt.edu> <11011175.1012667648@[0.0.0.0]>
Message-ID: <3C5D65A2.8030609@kub.nl>

Walter Underwood wrote:

[...]

 > In a safe list protocol, the client requests a number of results,
 > and the server is allowed to return fewer. That way, both sides are
 > safe.

This is already available in a comparable protocol under development by 
the Z39.50 community: SRU - Search/Retrieve URI service 
(http://www.loc.gov/z3950/agency/zing/srw.html#sru). SRU is SRW 
mentioned by Herbert in his last message, where SOAP is replaced by HTTP.

I would applaud if the Z39.50 (http://www.loc.gov/z3950/agency/zing) and 
the OAi initiatives were coordinated.

In one of my implementations of OAi-PHM it is possible to use a query 
attribute in the HTTP request. The resumptiontoken implementation is 
based on a already existing result set mechanism. These are the elements 
needed to implement a SRU server.Adding SOAP and the SRU server is a SRW 
server.

My suggestion is that SRW becomes (in time) a richer version of OAI-PHM 
(or that OAi-PHM becomes a subset of SRW).

Thomas

-- 
Thomas W. Place (T.W.Place@kub.nl)
Tilburg University, PO Box 90153, 5000 LE Tilburg, the Netherlands
phone: +31 13 466 2474; fax: +31 13 466 3370


From wunder@inktomi.com  Mon Feb  4 00:05:27 2002
From: wunder@inktomi.com (Walter Underwood)
Date: Sun, 03 Feb 2002 16:05:27 -0800
Subject: [OAI-implementers] OAI-PMH & SOAP
In-Reply-To: <3C5D65A2.8030609@kub.nl>
References: <F5753B6F5335D4118DEA00508BA54F5605BB7B37@nt-lonex1.bl.uk> <10705016.1012652888@[0.0.0.0]> <3C5C5DDD.4070006@vt.edu> <11011175.1012667648@[0.0.0.0]> <3C5D65A2.8030609@kub.nl>
Message-ID: <11361744.1012752327@[0.0.0.0]>

--On Sunday, February 3, 2002 5:30 PM +0100 Thomas Place <T.W.Place@kub.nl> wrote:
> Walter Underwood wrote:
>
>  > In a safe list protocol, the client requests a number of results,
>  > and the server is allowed to return fewer. That way, both sides are
>  > safe.
>
> This is already available in a comparable protocol under development
> by the Z39.50 community: SRU - Search/Retrieve URI service
> (http://www.loc.gov/z3950/agency/zing/srw.html#sru). SRU is SRW
> mentioned by Herbert in his last message, where SOAP is replaced by HTTP.

SRU/SRW/Zing is still a moving target. There is a quite a bit of
discussion about the purpose of that protocol. The direction so
far looks promising.

My point is that the current OAI list design is unsafe, not that
I would like it to work differently.

LDAP, SRU, and every web search engine use the model I suggested.
The model in OAI is dangerous to clients.

> I would applaud if the Z39.50 (http://www.loc.gov/z3950/agency/zing)
> and the OAi initiatives were coordinated.

Yes, though I would be happy if OAI focussed on metadata access.
General search is a different problem.

wunder
--
Walter R. Underwood
Senior Staff Engineer
Inktomi Enterprise Search
http://search.inktomi.com/

From hussein@vt.edu  Mon Feb  4 00:20:37 2002
From: hussein@vt.edu (Hussein Suleman)
Date: Sun, 03 Feb 2002 19:20:37 -0500
Subject: [OAI-implementers] OAI-PMH & SOAP
References: <F5753B6F5335D4118DEA00508BA54F5605BB7B37@nt-lonex1.bl.uk> <10705016.1012652888@[0.0.0.0]> <3C5C5DDD.4070006@vt.edu> <11011175.1012667648@[0.0.0.0]> <3C5D65A2.8030609@kub.nl> <11361744.1012752327@[0.0.0.0]>
Message-ID: <3C5DD3D5.3060006@vt.edu>

hi

now this has me wondering - don't resumption tokens solve the "safe 
list" problem ?

if a client requests a chunk of records, the server can choose to send 
fewer records and send back a resumption token, with retry-after headers 
  if necessary (thus the server is safe). the client, on the other hand, 
can choose to terminate a connection if the server sends too much data 
(the client is therefore safe). in fact the client should always be safe 
by virtue of the fact that the protocol is almost stateless and strictly 
client-initiated.

of course terminating the connection is only necessary for servers that 
are implemented without a scaling policy; and this solution is still 
somewhat cooperative, without proper dynamic negotiation.

maybe i am just missing the point - if i am interpreting the problem 
incorrectly, please clarify

thanx
----hussein

Walter Underwood wrote:

> --On Sunday, February 3, 2002 5:30 PM +0100 Thomas Place 
> <T.W.Place@kub.nl> wrote:
> 
>> Walter Underwood wrote:
>>
>>  > In a safe list protocol, the client requests a number of results,
>>  > and the server is allowed to return fewer. That way, both sides are
>>  > safe.
>>
>> This is already available in a comparable protocol under development
>> by the Z39.50 community: SRU - Search/Retrieve URI service
>> (http://www.loc.gov/z3950/agency/zing/srw.html#sru). SRU is SRW
>> mentioned by Herbert in his last message, where SOAP is replaced by HTTP.
> 
> 
> SRU/SRW/Zing is still a moving target. There is a quite a bit of
> discussion about the purpose of that protocol. The direction so
> far looks promising.
> 
> My point is that the current OAI list design is unsafe, not that
> I would like it to work differently.
> 
> LDAP, SRU, and every web search engine use the model I suggested.
> The model in OAI is dangerous to clients.
> 
>> I would applaud if the Z39.50 (http://www.loc.gov/z3950/agency/zing)
>> and the OAi initiatives were coordinated.
> 
> 
> Yes, though I would be happy if OAI focussed on metadata access.
> General search is a different problem.
> 
> wunder
> -- 
> Walter R. Underwood
> Senior Staff Engineer
> Inktomi Enterprise Search
> http://search.inktomi.com/
> _______________________________________________
> OAI-implementers mailing list
> OAI-implementers@oaisrv.nsdl.cornell.edu
> http://oaisrv.nsdl.cornell.edu/mailman/listinfo/oai-implementers


-- 
======================================================================
hussein suleman - hussein@vt.edu - vtcs - http://www.husseinsspace.com
======================================================================


From wunder@inktomi.com  Mon Feb  4 04:21:59 2002
From: wunder@inktomi.com (Walter Underwood)
Date: Sun, 03 Feb 2002 20:21:59 -0800
Subject: [OAI-implementers] OAI-PMH & SOAP
In-Reply-To: <3C5DD3D5.3060006@vt.edu>
References: <F5753B6F5335D4118DEA00508BA54F5605BB7B37@nt-lonex1.bl.uk> <10705016.1012652888@[0.0.0.0]> <3C5C5DDD.4070006@vt.edu> <11011175.1012667648@[0.0.0.0]> <3C5D65A2.8030609@kub.nl> <11361744.1012752327@[0.0.0.0]> <3C5DD3D5.3060006@vt.edu>
Message-ID: <11467079.1012767719@[0.0.0.0]>

--On Sunday, February 3, 2002 7:20 PM -0500 Hussein Suleman <hussein@vt.edu> wrote:
>
> [....] the client, on the other hand, can choose to terminate a connection
> if the server sends too much data (the client is therefore safe). in fact
> the client should always be safe by virtue of the fact that the protocol
> is almost stateless and strictly client-initiated.

First, "almost stateless" is the same as "stateful".

Second, the guts of the XML parser or reader is a terrible place
to implement a limit on the number of records a protocol response
should return. And aborting the session is a poor way to limit the
number of records. It turns a limit into an unrecoverable error.

Layered protocol design is over twenty years old. This is pretty
serious layer-crossing.

I did think of this solution when I first brought this up, but
that is not a way to get interoperability. It is a defense against
malicious servers, which is important, but a different problem.

Other protocols send a request with the start number and the
number to return, and the reply has up to that number of records.
Clear and stateless, with no worries about what to do when the
resumption token times out because the browser comes back after
an hour or a day. Or never comes back at all because they crashed
or got bored. The resumption token implies that state will be
kept when it is not needed, and it requires a periodic cleanup
to get rid of abandoned state. Extra complexity which is really
unnecessary.

wunder
--
Walter R. Underwood
Senior Staff Engineer
Inktomi Enterprise Search
http://search.inktomi.com/

From tim@tim.brody.btinternet.co.uk  Mon Feb  4 11:26:50 2002
From: tim@tim.brody.btinternet.co.uk (Tim Brody)
Date: Mon, 4 Feb 2002 11:26:50 -0000
Subject: [OAI-implementers] OAI-PMH & SOAP
References: <F5753B6F5335D4118DEA00508BA54F5605BB7B37@nt-lonex1.bl.uk> <10705016.1012652888@[0.0.0.0]> <3C5C5DDD.4070006@vt.edu> <11011175.1012667648@[0.0.0.0]> <3C5D65A2.8030609@kub.nl> <11361744.1012752327@[0.0.0.0]> <3C5DD3D5.3060006@vt.edu> <11467079.1012767719@[0.0.0.0]>
Message-ID: <001601c1ad6e$d6ea9470$6400a8c0@Advocate>

Hi,

(I agree with you that the current resumptionToken method is inelegant - it
is the most complex part to implement on the repository-side)

You're suggestion still doesn't protect the client, as the server could send
back as many records as it likes (if the server can send less than the max
records, what's to say a badly behaved server won't send back many more than
it?).

In the end it comes down to either ensuring the server is well-behaved (in
the current OAI sense, manually checking for resumptionTokens), or putting
some protection into the XML parsing/sax layer.

I would be interested to know how resumptionTokens can be avoided, as RT is
both flow-control (which can be replaced by start-maxrows requests), but
also state information (i.e. which records are to be returned). If different
sections of the same query are requested, without state being maintained,
surely there is a risk that some records may be missed in the overlap?
(or are you presuming that all records are added, and returned,
sequentially?)

All the best,
Tim Brody

----- Original Message -----
From: "Walter Underwood" <wunder@inktomi.com>
To: <oai-implementers@oaisrv.nsdl.cornell.edu>
Sent: Monday, February 04, 2002 4:21 AM
Subject: Re: [OAI-implementers] OAI-PMH & SOAP


> --On Sunday, February 3, 2002 7:20 PM -0500 Hussein Suleman
<hussein@vt.edu> wrote:
> >
> > [....] the client, on the other hand, can choose to terminate a
connection
> > if the server sends too much data (the client is therefore safe). in
fact
> > the client should always be safe by virtue of the fact that the protocol
> > is almost stateless and strictly client-initiated.
>
> First, "almost stateless" is the same as "stateful".
>
> Second, the guts of the XML parser or reader is a terrible place
> to implement a limit on the number of records a protocol response
> should return. And aborting the session is a poor way to limit the
> number of records. It turns a limit into an unrecoverable error.
>
> Layered protocol design is over twenty years old. This is pretty
> serious layer-crossing.
>
> I did think of this solution when I first brought this up, but
> that is not a way to get interoperability. It is a defense against
> malicious servers, which is important, but a different problem.
>
> Other protocols send a request with the start number and the
> number to return, and the reply has up to that number of records.
> Clear and stateless, with no worries about what to do when the
> resumption token times out because the browser comes back after
> an hour or a day. Or never comes back at all because they crashed
> or got bored. The resumption token implies that state will be
> kept when it is not needed, and it requires a periodic cleanup
> to get rid of abandoned state. Extra complexity which is really
> unnecessary.
>
> wunder
> --
> Walter R. Underwood
> Senior Staff Engineer
> Inktomi Enterprise Search
> http://search.inktomi.com/
> _______________________________________________
> OAI-implementers mailing list
> OAI-implementers@oaisrv.nsdl.cornell.edu
> http://oaisrv.nsdl.cornell.edu/mailman/listinfo/oai-implementers


From lagoze@cs.cornell.edu  Mon Feb  4 17:04:48 2002
From: lagoze@cs.cornell.edu (Carl Lagoze)
Date: Mon, 4 Feb 2002 12:04:48 -0500
Subject: [OAI-implementers] Open Archives Initiative Protocol for Metadata Harvesting Version 2 news
Message-ID: <706871B20764CD449DB0E8E3D81C4D4301F2C762@opus.cs.cornell.edu>

Dear OAI community: 

In mid-2001 the Open Archives Initiative Technical Committee (OAI-TC) was
formed to develop and write version 2 of the Open Archives Protocol for
Metadata Harvesting (OAI-PMH).  In this email, we would like to inform you about:

* The context of this technical work;
* The process for undertaking the work;
* The schedule for the release of v.2.0 of the OAI-PMH;
* Anticipated changes in v.2.0 of the OAI-PMH.

Carl Lagoze and Herbert Van de Sompel

=> The context of this technical work was:

1. The original release of the OAI-PMH, version 1.x, was intended to
initiate a year long period of experimentation with the protocol.  The goal
was to make this experimental version as stable as possible to encourage
usage and testing. (In fact, only one change from version 1.0 to 1.1 was made
during the year in response to a W3C change in the XML schema
specification).

2. The OAI-TC work should avoid if possible the addition of significant
functionality to the protocol. Instead, the scope of work should be to
resolve problems that arose over the past year in reaction to experience in
the user community.

3. While it was not deemed necessary that version 2.0 be backward compatible
with version 1.x, the upgrade path when version 2 is release should be
reasonably straightforward.

4. The result of the work, version 2, should be a stable, "standard"
release.  It remains undecided as to whether a formal standardization
process will be undertaken with the version 2 protocol.


 => The process for undertaking this work has been: 

1. Formation of the OAI-TC representing technical expertise from a
cross-section of the OAI community.  Conduct of this work within a closed
technical committee follows the same procedure which was successfully used
for the development of OAI-PMH v. 1.x.  Members of OAI-TC are listed at
http://www.openarchives.org/organization/tech.comm.html.

2. Joint identification of issues 

3. Development of issue white papers 

4. Vetting of white papers to determine those that were in scope of OAI-TC
work 

5. Development of issue resolution 

6. On-line and phone meetings to reach final issue resolution 

7. Reporting and validation of the results of the work of OAI-TC to the OAI Steering Committee.
Members of OAI-SC are listed at
http://www.openarchives.org/news/oaiscpress000825.html

8. Protocol revision and writing 
      

=> The schedule for the release of v 2.0 of the protocol is as follows: 

1. March 1: release of the protocol to a limited group of alpha testers 

2. April 1: beta public release 

3. May 1: final public release 


=> The following is a summary of the changes that are anticipated for
version 2 of OAI-PMH: 

1. Dates and times - Standardize on UTC for all dates and times in protocol
requests ("from" and "until" arguments) and responses.
        
 2. Harvesting Granularity- Allow all ISO8601 time granularities in dates
and times in the "from" and "until" arguments of protocol requests.  Allow a
data provider to expose its support date/time granularity in the response to
an Identity request.  Default granularity is YYY-MM-DD.

3. Flow control - Improve flow control by allowing the following optional
attributes when a resumptionToken is returned:    
* retryAfter - a suggested wait time until the request should be resubmitted

* expirationDate - the projected expiration of the resumptionToken  
* completeListSize - total number of items across entire result set 
* cursor - index of first item in this batch within entire result set 

4. set functionality - It will be possible to specify an identifier as
argument to the ListSets verb, permitting a harvester to inquire to which
sets an item belongs.  Responses to ListRecords and GetRecord will return
the sets to which each item belongs. Support of sets remains optional.

5. base-URL - Insulate harvesters from proxy servers by mandating that the
visible identity of the "handling server" in responses be that of a
persistent "master", that may opaquely reflect requests to slaves. 

6. xml schema for mandatory Dublin Core - Coordinate with the DCMI so that
the schema used by the OAI is based on one managed by DCMI.  Must allow
inclusion of the xml lang attribute (specifying the language of the metadata
value). 
        
7. Dedupping - Define an optional "provenance" XML container that can be
attached to metadata records that a data provider aggregates from other
sources.  This will help harvesters in detecting duplicates harvested from
multiple data providers. 

8. Error handling - Report OAI errors in OAI responses in a manner
independent of HTTP status codes. 

9. Set description - Define an optional XML container with which communities
can describe individual sets. 

10. Multiple metadata formats - Modify ListIdentifiers to permit a metadata
format as argument, filtering the return to include only record identifiers
that support the specified format.
        

From support@eprints.org  Mon Feb  4 20:26:32 2002
From: support@eprints.org (ePrints Support)
Date: Mon, 4 Feb 2002 20:26:32 +0000
Subject: [OAI-implementers] Open Archives Initiative Protocol for Metadata Harvesting Version 2 news
In-Reply-To: <706871B20764CD449DB0E8E3D81C4D4301F2C762@opus.cs.cornell.edu>
References: <706871B20764CD449DB0E8E3D81C4D4301F2C762@opus.cs.cornell.edu>
Message-ID: <20020204202632.GB25807@ecs.soton.ac.uk>

I strongly feel that sets should be made optional (maybe flagging this in
the Identify response) to reduce the implementation load on small archives.

Sets do not appear to be widely used by harvesters (shout if this is wrong)
and increase implementation complexity by about 25%. The "which sets is this
in" query makes this even more fiddley.

It's easy for harvestors not to support sets, but if it's meaningless which
it seems to be for some (many?) archives then forcing them to do extra work
reduces the number who will uptake.

also:

> 10. Multiple metadata formats - Modify ListIdentifiers to permit a metadata
> format as argument, filtering the return to include only record identifiers
> that support the specified format.

This is also more complexity, why is it needed?

-- 

 Christopher Gutteridge                   support@eprints.org 
 ePrints Developer                        +44 23 8059 4833


On Mon, Feb 04, 2002 at 12:04:48PM -0500, Carl Lagoze wrote:
> Dear OAI community: 
> 
> In mid-2001 the Open Archives Initiative Technical Committee (OAI-TC) was
> formed to develop and write version 2 of the Open Archives Protocol for
> Metadata Harvesting (OAI-PMH).  In this email, we would like to inform you about:
> 
> * The context of this technical work;
> * The process for undertaking the work;
> * The schedule for the release of v.2.0 of the OAI-PMH;
> * Anticipated changes in v.2.0 of the OAI-PMH.
> 
> Carl Lagoze and Herbert Van de Sompel
> 
> => The context of this technical work was:
> 
> 1. The original release of the OAI-PMH, version 1.x, was intended to
> initiate a year long period of experimentation with the protocol.  The goal
> was to make this experimental version as stable as possible to encourage
> usage and testing. (In fact, only one change from version 1.0 to 1.1 was made
> during the year in response to a W3C change in the XML schema
> specification).
> 
> 2. The OAI-TC work should avoid if possible the addition of significant
> functionality to the protocol. Instead, the scope of work should be to
> resolve problems that arose over the past year in reaction to experience in
> the user community.
> 
> 3. While it was not deemed necessary that version 2.0 be backward compatible
> with version 1.x, the upgrade path when version 2 is release should be
> reasonably straightforward.
> 
> 4. The result of the work, version 2, should be a stable, "standard"
> release.  It remains undecided as to whether a formal standardization
> process will be undertaken with the version 2 protocol.
> 
> 
>  => The process for undertaking this work has been: 
> 
> 1. Formation of the OAI-TC representing technical expertise from a
> cross-section of the OAI community.  Conduct of this work within a closed
> technical committee follows the same procedure which was successfully used
> for the development of OAI-PMH v. 1.x.  Members of OAI-TC are listed at
> http://www.openarchives.org/organization/tech.comm.html.
> 
> 2. Joint identification of issues 
> 
> 3. Development of issue white papers 
> 
> 4. Vetting of white papers to determine those that were in scope of OAI-TC
> work 
> 
> 5. Development of issue resolution 
> 
> 6. On-line and phone meetings to reach final issue resolution 
> 
> 7. Reporting and validation of the results of the work of OAI-TC to the OAI Steering Committee.
> Members of OAI-SC are listed at
> http://www.openarchives.org/news/oaiscpress000825.html
> 
> 8. Protocol revision and writing 
>       
> 
> => The schedule for the release of v 2.0 of the protocol is as follows: 
> 
> 1. March 1: release of the protocol to a limited group of alpha testers 
> 
> 2. April 1: beta public release 
> 
> 3. May 1: final public release 
> 
> 
> => The following is a summary of the changes that are anticipated for
> version 2 of OAI-PMH: 
> 
> 1. Dates and times - Standardize on UTC for all dates and times in protocol
> requests ("from" and "until" arguments) and responses.
>         
>  2. Harvesting Granularity- Allow all ISO8601 time granularities in dates
> and times in the "from" and "until" arguments of protocol requests.  Allow a
> data provider to expose its support date/time granularity in the response to
> an Identity request.  Default granularity is YYY-MM-DD.
> 
> 3. Flow control - Improve flow control by allowing the following optional
> attributes when a resumptionToken is returned:    
> * retryAfter - a suggested wait time until the request should be resubmitted
> 
> * expirationDate - the projected expiration of the resumptionToken  
> * completeListSize - total number of items across entire result set 
> * cursor - index of first item in this batch within entire result set 
> 
> 4. set functionality - It will be possible to specify an identifier as
> argument to the ListSets verb, permitting a harvester to inquire to which
> sets an item belongs.  Responses to ListRecords and GetRecord will return
> the sets to which each item belongs. Support of sets remains optional.
> 
> 5. base-URL - Insulate harvesters from proxy servers by mandating that the
> visible identity of the "handling server" in responses be that of a
> persistent "master", that may opaquely reflect requests to slaves. 
> 
> 6. xml schema for mandatory Dublin Core - Coordinate with the DCMI so that
> the schema used by the OAI is based on one managed by DCMI.  Must allow
> inclusion of the xml lang attribute (specifying the language of the metadata
> value). 
>         
> 7. Dedupping - Define an optional "provenance" XML container that can be
> attached to metadata records that a data provider aggregates from other
> sources.  This will help harvesters in detecting duplicates harvested from
> multiple data providers. 
> 
> 8. Error handling - Report OAI errors in OAI responses in a manner
> independent of HTTP status codes. 
> 
> 9. Set description - Define an optional XML container with which communities
> can describe individual sets. 
> 
> 10. Multiple metadata formats - Modify ListIdentifiers to permit a metadata
> format as argument, filtering the return to include only record identifiers
> that support the specified format.
>         
> _______________________________________________
> OAI-implementers mailing list
> OAI-implementers@oaisrv.nsdl.cornell.edu
> http://oaisrv.nsdl.cornell.edu/mailman/listinfo/oai-implementers



From simeon@cs.cornell.edu  Mon Feb  4 20:34:10 2002
From: simeon@cs.cornell.edu (Simeon Warner)
Date: Mon, 4 Feb 2002 15:34:10 -0500 (EST)
Subject: [OAI-implementers] Open Archives Initiative Protocol for Metadata
 Harvesting Version 2 news
In-Reply-To: <20020204202632.GB25807@ecs.soton.ac.uk>
Message-ID: <Pine.LNX.4.44.0202041528240.6171-100000@ice.cs.cornell.edu>

I have always failed to see why sets cause so much confusion. Sets ARE 
(and will remain) optional! They are optional from both perspectives:

1) a repository may choose not to implement sets (only overhead is
providing a blank ListSets reply)

2) a harvester may ignore sets by never calling ListSets and never
specifying a 'set=' parameter.
 
I think there is sufficient interest in sets to keep them for those that 
do choose to use them. 

Cheers,
Simeon.


On Mon, 4 Feb 2002, ePrints Support wrote:
> I strongly feel that sets should be made optional (maybe flagging this in
> the Identify response) to reduce the implementation load on small archives.
> 
> Sets do not appear to be widely used by harvesters (shout if this is wrong)
> and increase implementation complexity by about 25%. The "which sets is this
> in" query makes this even more fiddley.
> 
> It's easy for harvestors not to support sets, but if it's meaningless which
> it seems to be for some (many?) archives then forcing them to do extra work
> reduces the number who will uptake.
> 
> also:
> 
> > 10. Multiple metadata formats - Modify ListIdentifiers to permit a metadata
> > format as argument, filtering the return to include only record identifiers
> > that support the specified format.
> 
> This is also more complexity, why is it needed?


From wunder@inktomi.com  Mon Feb  4 22:11:18 2002
From: wunder@inktomi.com (Walter Underwood)
Date: Mon, 04 Feb 2002 14:11:18 -0800
Subject: [OAI-implementers] Open Archives Initiative Protocol for Metadata Harvesting Version 2 news
In-Reply-To: <706871B20764CD449DB0E8E3D81C4D4301F2C762@opus.cs.cornell.edu>
References: <706871B20764CD449DB0E8E3D81C4D4301F2C762@opus.cs.cornell.edu>
Message-ID: <13161222.1012831877@[0.0.0.0]>

--On Monday, February 4, 2002 12:04 PM -0500 Carl Lagoze <lagoze@cs.cornell.edu> wrote:
>
> 1. Dates and times - Standardize on UTC for all dates and times in protocol
> requests ("from" and "until" arguments) and responses.

Excellent idea.

>  2. Harvesting Granularity- Allow all ISO8601 time granularities in dates
> and times in the "from" and "until" arguments of protocol requests.  Allow a
> data provider to expose its support date/time granularity in the response to
> an Identity request.  Default granularity is YYY-MM-DD.

Poor idea. This multiplies the test cases massively and makes the
protocol implementation more complex. Now the spec must define what
"until 2002-02-02" means (beginning or end of the day?), and it must
be tested for all granularities in all arguments, and all combinations.
Some clients don't even need to send day granularities. Why should
they be saddled with this complexity?

> 3. Flow control - Improve flow control by allowing the following optional
> attributes when a resumptionToken is returned:
> * retryAfter - a suggested wait time until the request should be resubmitted
> * expirationDate - the projected expiration of the resumptionToken
> * completeListSize - total number of items across entire result set
> * cursor - index of first item in this batch within entire result set

This is surprisingly close to my suggested list approach. If this was
changed to have the client to send the cursor and the number of records
requested, then the resumption token is no longer needed. Think of it as
moving the database cursor from the server the client. Offloading the
state. This approach is  proven in high-load applications like LDAP and
HTTP search engines.

The 2.0 approach does have the problem where a correctly implemented
server can crash a correctly implemented client. That is very bad.
To fix that, the client must be able to specify the desired number
of records.

completeListSize is an excellent thing to return. It is somewhat
simpler to return that every time, rather than optionally as part
of the resumption token.

wunder
--
Walter R. Underwood
Senior Staff Engineer
Inktomi Enterprise Search
http://search.inktomi.com/

From jimlay@atypedigital.com  Tue Feb  5 00:06:17 2002
From: jimlay@atypedigital.com (Josie Imlay)
Date: Mon, 4 Feb 2002 16:06:17 -0800
Subject: [OAI-implementers] Open Archives Initiative Protocol for Metadata Harvesting Version 2 news
In-Reply-To: <706871B20764CD449DB0E8E3D81C4D4301F2C762@opus.cs.cornell.edu>
References: <706871B20764CD449DB0E8E3D81C4D4301F2C762@opus.cs.cornell.edu>
Message-ID: <20020205000617.GA13487@atypedigital.com>

I was thinking that on the sets being optional it would make more sence if a particular archive does not want to use sets for their to be a standard responce, or way to handle this.

To me the way to do this is to make sets manditory, but say that if you don't want to use them then just have one set called "all" or something. This is hardly makes it any more dificult from the standpoint of the developer because he can just have a static responce. But from the harvester that's programmed to deal with sets, it doesn't even notice that there is a difference.

Josie Imlay
On Mon, Feb 04, 2002 at 12:04:48PM -0500, Carl Lagoze wrote:
> Dear OAI community: 
> 
> In mid-2001 the Open Archives Initiative Technical Committee (OAI-TC) was
> formed to develop and write version 2 of the Open Archives Protocol for
> Metadata Harvesting (OAI-PMH).  In this email, we would like to inform you about:
> 
> * The context of this technical work;
> * The process for undertaking the work;
> * The schedule for the release of v.2.0 of the OAI-PMH;
> * Anticipated changes in v.2.0 of the OAI-PMH.
> 
> Carl Lagoze and Herbert Van de Sompel
> 
> => The context of this technical work was:
> 
> 1. The original release of the OAI-PMH, version 1.x, was intended to
> initiate a year long period of experimentation with the protocol.  The goal
> was to make this experimental version as stable as possible to encourage
> usage and testing. (In fact, only one change from version 1.0 to 1.1 was made
> during the year in response to a W3C change in the XML schema
> specification).
> 
> 2. The OAI-TC work should avoid if possible the addition of significant
> functionality to the protocol. Instead, the scope of work should be to
> resolve problems that arose over the past year in reaction to experience in
> the user community.
> 
> 3. While it was not deemed necessary that version 2.0 be backward compatible
> with version 1.x, the upgrade path when version 2 is release should be
> reasonably straightforward.
> 
> 4. The result of the work, version 2, should be a stable, "standard"
> release.  It remains undecided as to whether a formal standardization
> process will be undertaken with the version 2 protocol.
> 
> 
>  => The process for undertaking this work has been: 
> 
> 1. Formation of the OAI-TC representing technical expertise from a
> cross-section of the OAI community.  Conduct of this work within a closed
> technical committee follows the same procedure which was successfully used
> for the development of OAI-PMH v. 1.x.  Members of OAI-TC are listed at
> http://www.openarchives.org/organization/tech.comm.html.
> 
> 2. Joint identification of issues 
> 
> 3. Development of issue white papers 
> 
> 4. Vetting of white papers to determine those that were in scope of OAI-TC
> work 
> 
> 5. Development of issue resolution 
> 
> 6. On-line and phone meetings to reach final issue resolution 
> 
> 7. Reporting and validation of the results of the work of OAI-TC to the OAI Steering Committee.
> Members of OAI-SC are listed at
> http://www.openarchives.org/news/oaiscpress000825.html
> 
> 8. Protocol revision and writing 
>       
> 
> => The schedule for the release of v 2.0 of the protocol is as follows: 
> 
> 1. March 1: release of the protocol to a limited group of alpha testers 
> 
> 2. April 1: beta public release 
> 
> 3. May 1: final public release 
> 
> 
> => The following is a summary of the changes that are anticipated for
> version 2 of OAI-PMH: 
> 
> 1. Dates and times - Standardize on UTC for all dates and times in protocol
> requests ("from" and "until" arguments) and responses.
>         
>  2. Harvesting Granularity- Allow all ISO8601 time granularities in dates
> and times in the "from" and "until" arguments of protocol requests.  Allow a
> data provider to expose its support date/time granularity in the response to
> an Identity request.  Default granularity is YYY-MM-DD.
> 
> 3. Flow control - Improve flow control by allowing the following optional
> attributes when a resumptionToken is returned:    
> * retryAfter - a suggested wait time until the request should be resubmitted
> 
> * expirationDate - the projected expiration of the resumptionToken  
> * completeListSize - total number of items across entire result set 
> * cursor - index of first item in this batch within entire result set 
> 
> 4. set functionality - It will be possible to specify an identifier as
> argument to the ListSets verb, permitting a harvester to inquire to which
> sets an item belongs.  Responses to ListRecords and GetRecord will return
> the sets to which each item belongs. Support of sets remains optional.
> 
> 5. base-URL - Insulate harvesters from proxy servers by mandating that the
> visible identity of the "handling server" in responses be that of a
> persistent "master", that may opaquely reflect requests to slaves. 
> 
> 6. xml schema for mandatory Dublin Core - Coordinate with the DCMI so that
> the schema used by the OAI is based on one managed by DCMI.  Must allow
> inclusion of the xml lang attribute (specifying the language of the metadata
> value). 
>         
> 7. Dedupping - Define an optional "provenance" XML container that can be
> attached to metadata records that a data provider aggregates from other
> sources.  This will help harvesters in detecting duplicates harvested from
> multiple data providers. 
> 
> 8. Error handling - Report OAI errors in OAI responses in a manner
> independent of HTTP status codes. 
> 
> 9. Set description - Define an optional XML container with which communities
> can describe individual sets. 
> 
> 10. Multiple metadata formats - Modify ListIdentifiers to permit a metadata
> format as argument, filtering the return to include only record identifiers
> that support the specified format.
>         
> _______________________________________________
> OAI-implementers mailing list
> OAI-implementers@oaisrv.nsdl.cornell.edu
> http://oaisrv.nsdl.cornell.edu/mailman/listinfo/oai-implementers

From simeon@cs.cornell.edu  Tue Feb  5 04:22:37 2002
From: simeon@cs.cornell.edu (Simeon Warner)
Date: Mon, 4 Feb 2002 23:22:37 -0500 (EST)
Subject: [OAI-implementers] Open Archives Initiative Protocol for Metadata
 Harvesting Version 2 news
In-Reply-To: <20020205000617.GA13487@atypedigital.com>
Message-ID: <Pine.LNX.4.44.0202042238001.7952-100000@ice.cs.cornell.edu>

On Mon, 4 Feb 2002, Josie Imlay wrote:

> I was thinking that on the sets being optional it would make more sence
> if a particular archive does not want to use sets for their to be a
> standard responce, or way to handle this.

The standard way to say 'I do not implement sets' is a to list no
sets in the ListSets response.

> To me the way to do this is to make sets manditory, but say that if you
> don't want to use them then just have one set called "all" or something.
> This is hardly makes it any more dificult from the standpoint of the
> developer because he can just have a static responce. But from the
> harvester that's programmed to deal with sets, it doesn't even notice
> that there is a difference.

no setSpec => universal set => all records

Consider two cases where a harvester might want to use sets:

1) to harvest part of a repository. This requires prior (outside the
protocol) knowledge of the set structure and hence the set or sets to be
harvested cannot be determined automatically.

2) to mirror/harvest the whole repository including the set structure. In
v1.1 it is necessary for a harvester to harvest from all sets and from the
universal set (no setSpec) to be able to deduce the set structure. In v2
all records will include set membership information so it will be
only be necessary to harvest the universal set.

Cheers,
Simeon



From support@eprints.org  Tue Feb  5 09:36:57 2002
From: support@eprints.org (ePrints Support)
Date: Tue, 5 Feb 2002 09:36:57 +0000
Subject: [OAI-implementers] Open Archives Initiative Protocol for Metadata Harvesting Version 2 news
In-Reply-To: <Pine.LNX.4.44.0202042238001.7952-100000@ice.cs.cornell.edu>
References: <20020205000617.GA13487@atypedigital.com> <Pine.LNX.4.44.0202042238001.7952-100000@ice.cs.cornell.edu>
Message-ID: <20020205093657.GA28223@ecs.soton.ac.uk>

OK. This all sounds sensible. Maybe openarchives.org could have the
"bare minimum howto" which tells you how to neatly do the bare minimum to
support the protocol. 

The next version sounds like it will be more complex, but that complexity
will be optional. 

We should make it clear to people "checking it out" that it's easy to meet
the minimum requirements.

Is there a plan to add some more characters to the setSpec regexp? Preferably
everything other than ":" or near enough.

thanks, Chris G / eprints.

On Mon, Feb 04, 2002 at 11:22:37PM -0500, Simeon Warner wrote:
> 
> On Mon, 4 Feb 2002, Josie Imlay wrote:
> 
> > I was thinking that on the sets being optional it would make more sence
> > if a particular archive does not want to use sets for their to be a
> > standard responce, or way to handle this.
> 
> The standard way to say 'I do not implement sets' is a to list no
> sets in the ListSets response.
> 
> > To me the way to do this is to make sets manditory, but say that if you
> > don't want to use them then just have one set called "all" or something.
> > This is hardly makes it any more dificult from the standpoint of the
> > developer because he can just have a static responce. But from the
> > harvester that's programmed to deal with sets, it doesn't even notice
> > that there is a difference.
> 
> no setSpec => universal set => all records
> 
> Consider two cases where a harvester might want to use sets:
> 
> 1) to harvest part of a repository. This requires prior (outside the
> protocol) knowledge of the set structure and hence the set or sets to be
> harvested cannot be determined automatically.
> 
> 2) to mirror/harvest the whole repository including the set structure. In
> v1.1 it is necessary for a harvester to harvest from all sets and from the
> universal set (no setSpec) to be able to deduce the set structure. In v2
> all records will include set membership information so it will be
> only be necessary to harvest the universal set.
> 
> Cheers,
> Simeon
> 
> 
> _______________________________________________
> OAI-implementers mailing list
> OAI-implementers@oaisrv.nsdl.cornell.edu
> http://oaisrv.nsdl.cornell.edu/mailman/listinfo/oai-implementers

-- 

 Christopher Gutteridge                   support@eprints.org 
 ePrints Developer                        +44 23 8059 4833


From jyoung@oclc.org  Tue Feb  5 17:27:06 2002
From: jyoung@oclc.org (Young,Jeff)
Date: Tue, 5 Feb 2002 12:27:06 -0500
Subject: FW: [OAI-implementers] Open Archives Initiative Protocol for Meta
 data Harvesting Version 2 news
Message-ID: <E5431CF93E29F9478878F623E5B9CE983424C2@OA3-SERVER.oa.oclc.org>

Sorry Walter, I forgot to copy the listserv in my response.

-----Original Message-----
From: Young,Jeff 
Sent: Tuesday, February 05, 2002 12:25 PM
To: 'Walter Underwood'
Subject: RE: [OAI-implementers] Open Archives Initiative Protocol for
Metadata Harvesting Version 2 news


> From: Walter Underwood [mailto:wunder@inktomi.com]
> Sent: Monday, February 04, 2002 5:11 PM
> This is surprisingly close to my suggested list approach. If this was
> changed to have the client to send the cursor and the number 
> of records
> requested, then the resumption token is no longer needed. 
> Think of it as
> moving the database cursor from the server the client. Offloading the
> state. This approach is  proven in high-load applications 
> like LDAP and
> HTTP search engines.

Tim Brody raised a point in a different thread that hasn't been addressed
yet:

	I would be interested to know how resumptionTokens can be avoided,
	as RT is both flow-control (which can be replaced by start-maxrows
	requests), but also state information (i.e. which records are to be 
	returned). If different sections of the same query are requested, 
	without state being maintained, surely there is a risk that some 
	records may be missed in the overlap? (or are you presuming that all

	records are added, and returned, sequentially?)

Of course, resumptionTokens don't guarantee that an arbitrary data provider
will return a complete set of results. They merely provide a mechanism to
make it possible. Without such a guarantee, harvesters are obliged to
periodically reharvest the entire repository if they want to pick up those
missed items.

Jeff

From wunder@inktomi.com  Wed Feb  6 17:09:34 2002
From: wunder@inktomi.com (Walter Underwood)
Date: Wed, 06 Feb 2002 09:09:34 -0800
Subject: FW: [OAI-implementers] Open Archives Initiative Protocol for Meta data Harvesting Version 2 news
In-Reply-To: <E5431CF93E29F9478878F623E5B9CE983424C2@OA3-SERVER.oa.oclc.org>
References: <E5431CF93E29F9478878F623E5B9CE983424C2@OA3-SERVER.oa.oclc.org>
Message-ID: <16342632.1012986574@[0.0.0.0]>

--On Tuesday, February 5, 2002 12:27 PM -0500 "Young,Jeff" <jyoung@oclc.org> wrote:
>
> Of course, resumptionTokens don't guarantee that an arbitrary data provider
> will return a complete set of results. They merely provide a mechanism to
> make it possible. Without such a guarantee, harvesters are obliged to
> periodically reharvest the entire repository if they want to pick up those
> missed items.

They have to do that anyway, since deleted record responses are
not guaranteed. For complete garbage collection, they need to
check all items to see if they still exist.

The list interfaces are mostly needed for new items. We don't mind
if the list is inconsistant or unsynchronized, as long as it has
all the new stuff.

There is one thing that the list should never do: include something
before it is available via getRecord. Our spider can check something
within a second, and we've run into problems with systems which
notify the spider, then publish the content. The spider checks,
gets a 404, and goes on to something else. Publish, then notify.

wunder
--
Walter R. Underwood
Senior Staff Engineer
Inktomi Enterprise Search
http://search.inktomi.com/

From caar@loc.gov  Wed Feb  6 17:21:26 2002
From: caar@loc.gov (Caroline Arms)
Date: Wed, 6 Feb 2002 12:21:26 -0500 (EST)
Subject: [OAI-implementers] Another "set" from American Memory
In-Reply-To: <Pine.LNX.4.44.0201301111490.21950-100000@ice.cs.cornell.edu>
Message-ID: <Pine.SOL.4.21.0202061141030.26401-100000@sun8.loc.gov>

Records for 7,000+ broadsides, pamphlets etc. from the Rare Book & Special
Collections Division of the Library of Congress are now available for
harvesting from

   http://memory.loc.gov/cgi-bin/oai

The source collection is at:
    http://memory.loc.gov/ammem/rbpehtml/pehome.html   

OAMH setSpec: rbpebib
OAMH setName: LC Printed Ephemera Selections 

Other American Memory collections, available as OAI sets -- are described
at
  http://memory.loc.gov/ammem/oamh/lcoa1_content.html
        
Caroline Arms                            caar@loc.gov
national Digital Library Program
Library of Congress        

Postscript on sets:

We make our record available as sets because we have people who want to
harvest them that way (for instance, I know of a group interested in
building a specialized service related to sheet music) AND we actually
manage the records that way.  And at least one of the service
providers already harvesting our records certainly does it by set,
since they, like us, do batch updates.  When you are dealing with old
materials, it makes lots of sense.  

Sets should certainly be optional, but they are very significant for some
communities.  I did an analysis of use of sets by *registered* OAI
repositories (and there are many unregistered ones) as part of the white
paper on the set description issue for the technical committee.  The
summary statement (by Andy Powell) was

  Out of 49 repositories, 39 are using sets. Of these 13 appear to
  partition their collection by subject area, 13 by genre, and 9 by source
  of records.

We wouldn't use sets if it wasn't easy.  It is in fact easier for us to
use them than not to use them.  Harvesters then have the choice.


From jyoung@oclc.org  Wed Feb  6 18:59:55 2002
From: jyoung@oclc.org (Young,Jeff)
Date: Wed, 6 Feb 2002 13:59:55 -0500
Subject: FW: [OAI-implementers] Open Archives Initiative Protocol for
 Meta data Harvesting Version 2 news
Message-ID: <E5431CF93E29F9478878F623E5B9CE983424CC@OA3-SERVER.oa.oclc.org>

> From: Walter Underwood [mailto:wunder@inktomi.com]
> Sent: Wednesday, February 06, 2002 12:10 PM
> The list interfaces are mostly needed for new items. We don't mind
> if the list is inconsistant or unsynchronized, as long as it has
> all the new stuff.

I guess I'm saying that resumptionTokens don't necessarily guarantee you'll
get "all the new stuff", but could if appropriately implemented. The
stateless alternative, though, seems to assume an idealistically static
repository. If records are deleted from the repository, a stateless
harvesting solution doesn't seem to allow for the possibility of getting all
the new stuff. 

Imagine a resultset with 1 million records served in 1000 record chunks.
During the course of the harvest 10 records get deleted from the repository.
Since the stateless solution relies on the position of a cursor, the
client's view of the cursor may be as many as 10 records beyond the server's
view and thus records will be missed. Using resumptionTokens, however, I can
maintain a consistent cursor between client and server.

Also, I'd like to use OAI for internal operations within our organization.
Under those circumstances, I can make assumptions about the OAI
server/harvester such as records will never vanish and instead will be
flagged as deleted. With millions records in our repository, I'd like to
avoid a complete reharvest wherever possible. I don't believe reharvests can
be avoided using stateless harvesting the way they can with stateful
harvesting.

Jeff


From jtregear@salud.unm.edu  Wed Feb  6 19:11:14 2002
From: jtregear@salud.unm.edu (Jonathan Tregear)
Date: Wed, 06 Feb 2002 12:11:14 -0700
Subject: [OAI-implementers] Notes on OAI 2.0 and SOAP
Message-ID: <sc611d7c.033@salud.unm.edu>

Thanks for the response on the OAI 2.0 schedule and process (contained
in messages from Mr. Van de Sompel and Mr. Lagoze). Before posting my
previous comment, I visited the OAI website and it appeared there that
the OAI 2.0 specification process was just beginning. I was not aware of
how much had already been discussed and decided. Nevertheless, I do have
a few additional comments to make.

1. OAI needs to get out of the web service infrastructure building
business and as Mr. Underwood states focus on metadata access. Perhaps
the resources that have been focused on custom protocol building could
be refocused to tackle the community building that Mr. Krichel refers
to. Misplacing resources on an obsolete protocol and the infrastructure
around it only exascerbates that problem.

2. The mantra of "simple to implement" seems to me to be something of a
red herring. OAI obviously realized early on that, for some institutions
if not most, no protocol would be simple enough to implement and that if
OAI wanted to reach those institutions they would have to provide
working implementations. Isn't that the reason that packages like
eprints, Kepler and the other OAI tools were produced? So the universe
of organizations that actually have to implement the protocol is
actually quite small. And I'm fairly sure that any of these institutions
have the technical ability to implement either protocol.

3. Finally, I strongly disagree with the restatement of the OAI mission
statement, limiting its goals to dissemination of information within
participating digital libraries. This is not the premise that is
promoted to repository providers. And it is certainly not a limitation
that I want for our repositories. I would add to Mr. Underwood's
statement that custom protocols are never simple, the statement that
custom protocols are never really "Open" either. They always create real
barriers to entry (e.g. Mr. Underwood's statement that it would not be
worth it for Inktomi to build a harvester for one-of-a-kind XML
protocol). As such, this is not a system being designed even for the
benefit of the limited group of repository providers (it certainly isn't
to our benefit or the benefit of potential searchers of our
repositories). And the net effect of this design is to replace one
resource oligopoly with another. Perhaps you ought to rename it the
SoOAI for "Sort of Open Archives Initiative" Or maybe NROAI for "Not
Really Open Archives Initiative". Just kidding.

The question is not whom on the technical, steering, or executive
committees or the participants of this listserv did or did not express
interest in whatever protocol and when. The right question is what
protocol potentially offers authors who contribute to these repositories
the widest possible resource discovery potential for the publications
they contribute. I don't think that, if they were asked, authors would
express much interest in any agenda other than that.

I know that there have been discussions in the past here about how to
generate the very interest from organizations like Inktomi that Mr.
Underwood seems to be offering. I don't understand now why you don't
jump at the opportunity when it is offered.

Jonathan Tregear
Health Sciences Center
University of New Mexico


From simeon@cs.cornell.edu  Wed Feb  6 19:18:18 2002
From: simeon@cs.cornell.edu (Simeon Warner)
Date: Wed, 6 Feb 2002 14:18:18 -0500 (EST)
Subject: FW: [OAI-implementers] Open Archives Initiative Protocol for
 Meta data Harvesting Version 2 news
In-Reply-To: <E5431CF93E29F9478878F623E5B9CE983424CC@OA3-SERVER.oa.oclc.org>
Message-ID: <Pine.LNX.4.44.0202061407270.10505-100000@ice.cs.cornell.edu>

[Admin point first: Can we stop this duplicate posting to oai-general? 
The description of oai-general is "The OAI list will keep you informed 
about OAI-related activities." I don't think these discussions fall 
within that.]


My main objection to including an option for harvesters to specify the
maximum number of records they wish to get in a reply is that this will
force ALL repositories to implement resumptionTokens.  Currently, small
repsotiories (say a few thousand records) can happily ignore that part of
the spec.

One of the primary objectives of OAI is to provide a low barrier to
adoption, particularly on the repository side. I therefore think that
requiring this would go against our objectives, even if it is cleaner in
some ways.

Cheers,
Simeon.


On Wed, 6 Feb 2002, Young,Jeff wrote:
> Imagine a resultset with 1 million records served in 1000 record chunks.
> During the course of the harvest 10 records get deleted from the repository.
> Since the stateless solution relies on the position of a cursor, the
> client's view of the cursor may be as many as 10 records beyond the server's
> view and thus records will be missed. Using resumptionTokens, however, I can
> maintain a consistent cursor between client and server.
> 
> Also, I'd like to use OAI for internal operations within our organization.
> Under those circumstances, I can make assumptions about the OAI
> server/harvester such as records will never vanish and instead will be
> flagged as deleted. With millions records in our repository, I'd like to
> avoid a complete reharvest wherever possible. I don't believe reharvests can
> be avoided using stateless harvesting the way they can with stateful
> harvesting.
> 
> Jeff


From wunder@inktomi.com  Wed Feb  6 21:42:55 2002
From: wunder@inktomi.com (Walter Underwood)
Date: Wed, 06 Feb 2002 13:42:55 -0800
Subject: FW: [OAI-implementers] Open Archives Initiative Protocol for  Meta data Harvesting Version 2 news
In-Reply-To: <Pine.LNX.4.44.0202061407270.10505-100000@ice.cs.cornell.edu>
References: <Pine.LNX.4.44.0202061407270.10505-100000@ice.cs.cornell.edu>
Message-ID: <17327178.1013002975@[0.0.0.0]>

--On Wednesday, February 6, 2002 2:18 PM -0500 Simeon Warner <simeon@cs.cornell.edu> wrote:
>
> My main objection to including an option for harvesters to specify the
> maximum number of records they wish to get in a reply is that this will
> force ALL repositories to implement resumptionTokens.  Currently, small
> repsotiories (say a few thousand records) can happily ignore that part of
> the spec.

I suggest getting rid of resumption tokens to make it
simpler for all sizes of repositories.

A very simple server can always calculate the entire result list,
then send the portion requested, for example, records 21-30.
Cache the result list to speed things up.

Internally, this is much easier to implement than resumption
tokens. Caching is independent of the correctness of the list,
so the two are loosely coupled. For simple databases, the slow
part is getting data from disk, and the existing OS file cache
will already provided the most important level of caching.

Large systems will probably use commercial databases, which
provide additional levels of caching.

A repository with only a few thousand records could load them
into memory at startup and reboot when there is a change.
1K per record, 10K records is only 10Meg. No caching needed.

wunder
--
Walter R. Underwood
Senior Staff Engineer
Inktomi Enterprise Search
http://search.inktomi.com/

From nbirgani@go.com  Wed Feb  6 22:46:30 2002
From: nbirgani@go.com (ebrahim najafi birgani)
Date: Wed, 06 Feb 2002 14:46:30 -0800 (PST)
Subject: [OAI-implementers] unsubscrib
Message-ID: <2026611.1013035590230.JavaMail.nbirgani@gomailjtp04>

please unsubscribe me from the list. thanks

___________________________________________________
GO.com Mail                                    
Get Your Free, Private E-mail at http://mail.go.com



From Martin Vesely <Martin.Vesely@cern.ch>  Thu Feb  7 22:14:30 2002
From: Martin Vesely <Martin.Vesely@cern.ch> (Martin Vesely)
Date: Thu, 7 Feb 2002 23:14:30 +0100 (CET)
Subject: FW: [OAI-implementers] Open Archives Initiative Protocol for  Meta data Harvesting Version 2 news
In-Reply-To: <17327178.1013002975@[0.0.0.0]>
Message-ID: <Pine.LNX.3.95a.1020207221544.30766G-100000@lxplus021.cern.ch>

Hello,

The described way of caching data is very similar to how the OAI flow
control is done in our repository. But still, I do not see how we can
get rid of resumption tokens.

Since HTTP is request-response, the cached data cannot be sent by the
server with no additional request. The subsequent request has to identify
itself, so the server knows what data are requested. Resumption token is
nothing but an identifier for server and for the reason of identification
is necessary.

I think that the harvesting transaction inevitably deals with such amount
of data that it hardly can be delivered within one HTTP request-response
session. Therefore there has to be some mechanism to enable the transfer
in smaller parts in a sequence of sessions.

There is always a way to issue ListIdentifiers and a sequence of
GetRecord(s), which actually is the way to avoid resumption tokens for
those who have this preference.

A connected issue: Could the protocol be made stateless by a statement
about the OAI transaction? Then this statement should be added to the
protocol. For example: The OAI-transaction is composed of an OAI-request
and a full OAI-response.  Before last package of OAI-response is
delivered, the OAI-transaction is considered not to be finished.

The same way how stateless HTTP deals with underlying packets. This way
the harvester cannot supply any part of the response before it has the
complete harvest available.


Regards,
Martin

--
CERN Document Server ** <http://cds.cern.ch/> ** <cds.support@cern.ch>
Room: Bldg 510-1-015 ** Voice: +41-22-7673527 ** Fax: +41-22-7678142

On Wed, 6 Feb 2002, Walter Underwood wrote:

>--On Wednesday, February 6, 2002 2:18 PM -0500 Simeon Warner <simeon@cs.cornell.edu> wrote:
>>
>> My main objection to including an option for harvesters to specify the
>> maximum number of records they wish to get in a reply is that this will
>> force ALL repositories to implement resumptionTokens.  Currently, small
>> repsotiories (say a few thousand records) can happily ignore that part of
>> the spec.
>
>I suggest getting rid of resumption tokens to make it
>simpler for all sizes of repositories.
>
>A very simple server can always calculate the entire result list,
>then send the portion requested, for example, records 21-30.
>Cache the result list to speed things up.
>
>Internally, this is much easier to implement than resumption
>tokens. Caching is independent of the correctness of the list,
>so the two are loosely coupled. For simple databases, the slow
>part is getting data from disk, and the existing OS file cache
>will already provided the most important level of caching.
>
>Large systems will probably use commercial databases, which
>provide additional levels of caching.
>
>A repository with only a few thousand records could load them
>into memory at startup and reboot when there is a change.
>1K per record, 10K records is only 10Meg. No caching needed.
>
>wunder
>--
>Walter R. Underwood
>Senior Staff Engineer
>Inktomi Enterprise Search
>http://search.inktomi.com/
>_______________________________________________
>OAI-implementers mailing list
>OAI-implementers@oaisrv.nsdl.cornell.edu
>http://oaisrv.nsdl.cornell.edu/mailman/listinfo/oai-implementers
>





From ajk@mds.rmit.edu.au  Thu Feb  7 22:24:36 2002
From: ajk@mds.rmit.edu.au (Alan Kent)
Date: Fri, 8 Feb 2002 09:24:36 +1100
Subject: [OAI-implementers] Newbie available sites question
Message-ID: <20020208092436.A4403@io.mds.rmit.edu.au>

Hi,

I am new to this list so I am not sure yet whether this is a 'general'
or 'implementors' question. But I am trying to implement a OAI Service
Provider from the spec so 'implementers' seemed reasonable.

I have built a first cut of a OAI Harvester, loading the data up into
a local database I have built. I believe I have correctly followed the
spec, but I have been trying to access many of the listed OAI sites
listed from the openarchives.org site and getting lots of problems.
Is this because the protocol is still new? Or are many of the sites
out of date now? Is there a more up to date list?

I am using POST methods, and quite a few of the errors indicates to
me the sites only accept GET methods with the verb etc tacked onto the
URL. Is there any up-to-date "state of the nation" statement around?
Is OAI in serious production, or still very experimental? The spec
recommends POST rather than GET, but is the practice that GET is more
interoperable than POST?

Another unrelated question is: are there any systems around that will
crawl a web site, pull DC metadata out of the Meta tags, and then dish
that up via OAI? I had an enquiry from someone who thought OAI would
be interesting to use, but they were not sure if they could convince
their data suppliers to implement OAI (too much cost/hard work). If there
was a simple product that could be installed at the data providers sites,
then it can do a local crawl and then use OAI to only distribute the
changes. If there was existing cheap/free software for this, the data
providers might be willing to do something.

A little back ground on myself: we have a Z39.50 database system with
lots of SGML and XML support. However we are not really in the library
marketplace at present - more document management. I came across OAI
again recently, read the 1.1 spec, so had a go at writing a crawler.
It only took one day to write, which is a probably a good report for OAI.
I have been loading the DC XML into our Z39.50 server. If there was
interest, I might be able to put it up for public access. But at this
stage I don't have a good feel of where OAI is up to in real life.

Another question I had is that ListRecords does not seem to guarantee
any order in the returned data. I am doing a crawl from 1900 as an initial
pass to get all the data using resumptionToken's to keep going. If something
fails half way through, I currently have to get the lot again. If the
records were guaranteed to come back in date sorted order, I could
resume from a more recent date/time. I could use from/util 1 year at a
time, but the nice thing about resumptionToken is that the server gets
to choose a reasonable lump size (eg: 100 records). The client does not
know if 1 year contains 1, 100, or 1000000 records. There has probably
been previous discussion on this. Does ListRecords guarantee the order
of records back (in date order)?

Another issue I had was it seemed strange that some date/time values
were accurate to the day, whereas others were accurate to the second.
My crawler when doing a query subtracts 1 day from the last crawl date
when doing the next crawl to ensure no records are lost, and to take
into account time zone differences etc. Is there any standard practice
here?

Thanks for any help people can provide, and sorry if these are old
topics. But I find crawling through the archives does not always give
you what the current feelings on topics are.

Alan
-- 
Alan Kent (mailto:ajk@mds.rmit.edu.au, http://www.mds.rmit.edu.au)
Postal: Multimedia Database Systems, RMIT, GPO Box 2476V, Melbourne 3001.
Where: RMIT MDS, Bld 91, Level 3, 110 Victoria St, Carlton 3053, VIC Australia.
Phone: +61 3 9925 4114  Reception: +61 3 9925 4099  Fax: +61 3 9925 4098 

From zubair@cs.odu.edu  Thu Feb  7 23:00:37 2002
From: zubair@cs.odu.edu (zubair@cs.odu.edu)
Date: Thu, 7 Feb 2002 18:00:37 -0500
Subject: [OAI-implementers] Newbie available sites question
Message-ID: <OF7FAB5A9B.5AC6A54A-ON85256B59.007C366A@cs.odu.edu>

Alan,

Regarding your question about a system that crawls a web site, extract and
map metadata to DC, and make it available through OAI, we have a
preliminary version of such a system. For web sites where DC metadata can
be obtained from META tags, the implementation is straightforward. We were
also looking for Web sites, which are not that structured and do not have
META tags. In addition, we wanted a data-centered architecture where we do
not have to change the code once we want to work with another Web site. For
this reason, the system we have built uses WIDL  (XML based Web Interface
Definition Language; Web Methods has a NOTE in W3C on this language) -like
language  to describe the  Web site and the mapping of information on the
Web pages to DC metadata. The system uses this description to mine,
extract, and map the metadata and stores all the information in MYSQL,
which has a servlet-based OAI wrapper. If you want more information on this
system, you can send me an email (zubair@cs.odu.edu).

Zubair



                                                                                                                                      
                    Alan Kent <ajk@mds.rmit.edu.au>                                                                                   
                    Sent by:                                    To:     OAI Implementors <oai-implementers@oaisrv.nsdl.cornell.edu>   
                    oai-implementers-admin@oaisrv.nsdl.c        cc:                                                                   
                    ornell.edu                                  Subject:     [OAI-implementers] Newbie available sites question       
                                                                                                                                      
                                                                                                                                      
                    02/07/2002 05:24 PM                                                                                               
                                                                                                                                      
                                                                                                                                      




Hi,

I am new to this list so I am not sure yet whether this is a 'general'
or 'implementors' question. But I am trying to implement a OAI Service
Provider from the spec so 'implementers' seemed reasonable.

I have built a first cut of a OAI Harvester, loading the data up into
a local database I have built. I believe I have correctly followed the
spec, but I have been trying to access many of the listed OAI sites
listed from the openarchives.org site and getting lots of problems.
Is this because the protocol is still new? Or are many of the sites
out of date now? Is there a more up to date list?

I am using POST methods, and quite a few of the errors indicates to
me the sites only accept GET methods with the verb etc tacked onto the
URL. Is there any up-to-date "state of the nation" statement around?
Is OAI in serious production, or still very experimental? The spec
recommends POST rather than GET, but is the practice that GET is more
interoperable than POST?

Another unrelated question is: are there any systems around that will
crawl a web site, pull DC metadata out of the Meta tags, and then dish
that up via OAI? I had an enquiry from someone who thought OAI would
be interesting to use, but they were not sure if they could convince
their data suppliers to implement OAI (too much cost/hard work). If there
was a simple product that could be installed at the data providers sites,
then it can do a local crawl and then use OAI to only distribute the
changes. If there was existing cheap/free software for this, the data
providers might be willing to do something.

A little back ground on myself: we have a Z39.50 database system with
lots of SGML and XML support. However we are not really in the library
marketplace at present - more document management. I came across OAI
again recently, read the 1.1 spec, so had a go at writing a crawler.
It only took one day to write, which is a probably a good report for OAI.
I have been loading the DC XML into our Z39.50 server. If there was
interest, I might be able to put it up for public access. But at this
stage I don't have a good feel of where OAI is up to in real life.

Another question I had is that ListRecords does not seem to guarantee
any order in the returned data. I am doing a crawl from 1900 as an initial
pass to get all the data using resumptionToken's to keep going. If
something
fails half way through, I currently have to get the lot again. If the
records were guaranteed to come back in date sorted order, I could
resume from a more recent date/time. I could use from/util 1 year at a
time, but the nice thing about resumptionToken is that the server gets
to choose a reasonable lump size (eg: 100 records). The client does not
know if 1 year contains 1, 100, or 1000000 records. There has probably
been previous discussion on this. Does ListRecords guarantee the order
of records back (in date order)?

Another issue I had was it seemed strange that some date/time values
were accurate to the day, whereas others were accurate to the second.
My crawler when doing a query subtracts 1 day from the last crawl date
when doing the next crawl to ensure no records are lost, and to take
into account time zone differences etc. Is there any standard practice
here?

Thanks for any help people can provide, and sorry if these are old
topics. But I find crawling through the archives does not always give
you what the current feelings on topics are.

Alan
--
Alan Kent (mailto:ajk@mds.rmit.edu.au, http://www.mds.rmit.edu.au)
Postal: Multimedia Database Systems, RMIT, GPO Box 2476V, Melbourne 3001.
Where: RMIT MDS, Bld 91, Level 3, 110 Victoria St, Carlton 3053, VIC
Australia.
Phone: +61 3 9925 4114  Reception: +61 3 9925 4099  Fax: +61 3 9925 4098
_______________________________________________
OAI-implementers mailing list
OAI-implementers@oaisrv.nsdl.cornell.edu
http://oaisrv.nsdl.cornell.edu/mailman/listinfo/oai-implementers




From wunder@inktomi.com  Thu Feb  7 23:06:48 2002
From: wunder@inktomi.com (Walter Underwood)
Date: Thu, 07 Feb 2002 15:06:48 -0800
Subject: FW: [OAI-implementers] Open Archives Initiative Protocol for  Meta data Harvesting Version 2 news
In-Reply-To: <Pine.LNX.3.95a.1020207221544.30766G-100000@lxplus021.cern.ch>
References: <Pine.LNX.3.95a.1020207221544.30766G-100000@lxplus021.cern.ch>
Message-ID: <1640302704.1013123208@diva.inktomi.com>

Replying to two related messages ...

--On Thursday, February 07, 2002 11:14:30 PM +0100 Martin Vesely <Martin.Vesely@cern.ch> wrote:
> 
> The described way of caching data is very similar to how the OAI flow
> control is done in our repository. But still, I do not see how we can
> get rid of resumption tokens.

A client can request elements 21-30 of a list, and get a response.
That might be the very first request from that client. Or the first
request after the server reboots. It could even go to a replica of
the server. No resumption token is needed. Calculate the list, and 
return that portion of it.

Here is a URL to get hits 21-30 about "face on mars" from the NASA
search engine. No need to fetch hits 1-20 and get a resumption token.
You can edit the "st" variable to change the start hit.

http://search.spacelink.nasa.gov/query.html?col=library+xreflib&qt=face+on+mars&st=21&nh=10

--On Wednesday, February 06, 2002 01:59:55 PM -0500 "Young,Jeff" <jyoung@oclc.org> wrote:
> 
> I guess I'm saying that resumptionTokens don't necessarily guarantee you'll
> get "all the new stuff", but could if appropriately implemented. The
> stateless alternative, though, seems to assume an idealistically static
> repository. If records are deleted from the repository, a stateless
> harvesting solution doesn't seem to allow for the possibility of getting all
> the new stuff. 

A request for all changes between two dates in the past should always get 
the same answer, so stateless harvesting should work. A half-open request, 
that is "until now", will have time-varying results. If harvesters always
make requests with both from and until, and make sure that the until date
is not in the future, then stateless harvesting is safe.

There should be some way to get the current time at the repository.
Clock skew will cause nasty problems in time-based harvesting. The only
safe solution is to always use the clock at the server, and to require
that it is non-decreasing.

wunder
--
Walter Underwood
wunder@inktomi.com
Senior Staff Engineer, Inktomi
http://www.inktomi.com/


From ajk@mds.rmit.edu.au  Thu Feb  7 23:44:25 2002
From: ajk@mds.rmit.edu.au (Alan Kent)
Date: Fri, 8 Feb 2002 10:44:25 +1100
Subject: FW: [OAI-implementers] Open Archives Initiative Protocol for  Meta data Harvesting Version 2 news
In-Reply-To: <1640302704.1013123208@diva.inktomi.com>; from Walter Underwood on Thu, Feb 07, 2002 at 03:06:48PM -0800
References: <Pine.LNX.3.95a.1020207221544.30766G-100000@lxplus021.cern.ch> <1640302704.1013123208@diva.inktomi.com>
Message-ID: <20020208104425.A9263@io.mds.rmit.edu.au>

On Thu, Feb 07, 2002 at 03:06:48PM -0800, Walter Underwood wrote:
> There should be some way to get the current time at the repository.
> Clock skew will cause nasty problems in time-based harvesting. The only
> safe solution is to always use the clock at the server, and to require
> that it is non-decreasing.

Not letting lack of knowledge from stopping me from diving in
immediately :-), I had thought that it would be good if for every
request, the server also returned a guaranteed date range that the
fully covered up to. If it was not the end of the day yet, then it
would take that into account to make sure nothing was missed
(possibly resulting in the same information being sent more than
once).

The reason I thought this would be useful relates to resumption tokens.
If 10 requests are done with resumption tokens then something messes up,
then at client can work out a safe time to resume from without having
to go back to the very original date. If the server returns the records
in date order, then recovering during a big download would be more
efficient. If the records are not in date order, the server would
return the 'from' date every time (meaning recovery would just start
again from scratch). Making the extra <resumptionFromDate> or whatever
optional means clients could optimized the recovery if the server
provided the details.

Alan

From liu_x@cs.odu.edu  Fri Feb  8 02:50:27 2002
From: liu_x@cs.odu.edu (Xiaoming Liu)
Date: Thu, 07 Feb 2002 21:50:27 -0500
Subject: FW: [OAI-implementers] Open Archives Initiative Protocol for  Meta
 data Harvesting Version 2 news
References: <Pine.LNX.3.95a.1020207221544.30766G-100000@lxplus021.cern.ch> <1640302704.1013123208@diva.inktomi.com>
Message-ID: <3C633CF3.6F7C874@cs.odu.edu>

--------------A07397DD47F45319B435C394
Content-Type: text/plain; charset=us-ascii
Content-Transfer-Encoding: 7bit

Maybe there is one way to implement a stateless protocol in current OAI: encode query parameters
in ResumptionToken:

For example, the format of resumptionToken could be
from:to:Sets:MetadataSet:cursor

one example is:
resumptionToken= 1999:2000:math:oai_dc:100

By this way,  the state information is kept in resumptionToken, the data provider doesn't need
keep it. I have seen some implementations in this way.


--- Walter Underwood wrote:
> A request for all changes between two dates in the past should always get
> the same answer, so stateless harvesting should work.

This is a neat way, but I am now sure how well the past is kept in digital library ;-) Especially
in OAI protocol, whenever a record is changed, its datestamp is changed too.  So even a request
for past may not get the same answer.

regards,
liu








Walter Underwood wrote:

> Replying to two related messages ...
>
> --On Thursday, February 07, 2002 11:14:30 PM +0100 Martin Vesely <Martin.Vesely@cern.ch> wrote:
> >
> > The described way of caching data is very similar to how the OAI flow
> > control is done in our repository. But still, I do not see how we can
> > get rid of resumption tokens.
>
> A client can request elements 21-30 of a list, and get a response.
> That might be the very first request from that client. Or the first
> request after the server reboots. It could even go to a replica of
> the server. No resumption token is needed. Calculate the list, and
> return that portion of it.
>
> Here is a URL to get hits 21-30 about "face on mars" from the NASA
> search engine. No need to fetch hits 1-20 and get a resumption token.
> You can edit the "st" variable to change the start hit.
>
> http://search.spacelink.nasa.gov/query.html?col=library+xreflib&qt=face+on+mars&st=21&nh=10
>
> --On Wednesday, February 06, 2002 01:59:55 PM -0500 "Young,Jeff" <jyoung@oclc.org> wrote:
> >
> > I guess I'm saying that resumptionTokens don't necessarily guarantee you'll
> > get "all the new stuff", but could if appropriately implemented. The
> > stateless alternative, though, seems to assume an idealistically static
> > repository. If records are deleted from the repository, a stateless
> > harvesting solution doesn't seem to allow for the possibility of getting all
> > the new stuff.
>
> A request for all changes between two dates in the past should always get
> the same answer, so stateless harvesting should work. A half-open request,
> that is "until now", will have time-varying results. If harvesters always
> make requests with both from and until, and make sure that the until date
> is not in the future, then stateless harvesting is safe.
>
> There should be some way to get the current time at the repository.
> Clock skew will cause nasty problems in time-based harvesting. The only
> safe solution is to always use the clock at the server, and to require
> that it is non-decreasing.
>
> wunder
> --
> Walter Underwood
> wunder@inktomi.com
> Senior Staff Engineer, Inktomi
> http://www.inktomi.com/
>
> _______________________________________________
> OAI-implementers mailing list
> OAI-implementers@oaisrv.nsdl.cornell.edu
> http://oaisrv.nsdl.cornell.edu/mailman/listinfo/oai-implementers

--------------A07397DD47F45319B435C394
Content-Type: text/html; charset=us-ascii
Content-Transfer-Encoding: 7bit

<!doctype html public "-//w3c//dtd html 4.0 transitional//en">
<html>
Maybe there is one way to implement a stateless protocol in current OAI:
encode query parameters in ResumptionToken:
<p>For example, the format of resumptionToken could be
<br>from:to:Sets:MetadataSet:cursor
<p>one example is:
<br>resumptionToken= 1999:2000:math:oai_dc:100
<p>By this way,&nbsp; the state information is kept in resumptionToken,
the data provider doesn't need keep it. I&nbsp;have seen some implementations
in this way.
<br>&nbsp;
<p>--- Walter Underwood wrote:
<br>> A request for all changes between two dates in the past should always
get
<br>> the same answer, so stateless harvesting should work.
<p>This is a neat way, but I am now sure how well the past is kept in digital
library ;-) Especially in OAI&nbsp;protocol, whenever a record is changed,
its datestamp is changed too.&nbsp; So even a request for past may not
get the same answer.
<p>regards,
<br>liu
<br>&nbsp;
<br>&nbsp;
<br>&nbsp;
<br>&nbsp;
<br>&nbsp;
<br>&nbsp;
<br>&nbsp;
<p>Walter Underwood wrote:
<blockquote TYPE=CITE>Replying to two related messages ...
<p>--On Thursday, February 07, 2002 11:14:30 PM +0100 Martin Vesely &lt;Martin.Vesely@cern.ch>
wrote:
<br>>
<br>> The described way of caching data is very similar to how the OAI
flow
<br>> control is done in our repository. But still, I do not see how we
can
<br>> get rid of resumption tokens.
<p>A client can request elements 21-30 of a list, and get a response.
<br>That might be the very first request from that client. Or the first
<br>request after the server reboots. It could even go to a replica of
<br>the server. No resumption token is needed. Calculate the list, and
<br>return that portion of it.
<p>Here is a URL to get hits 21-30 about "face on mars" from the NASA
<br>search engine. No need to fetch hits 1-20 and get a resumption token.
<br>You can edit the "st" variable to change the start hit.
<p><a href="http://search.spacelink.nasa.gov/query.html?col=library+xreflib&qt=face+on+mars&st=21&nh=10">http://search.spacelink.nasa.gov/query.html?col=library+xreflib&amp;qt=face+on+mars&amp;st=21&amp;nh=10</a>
<p>--On Wednesday, February 06, 2002 01:59:55 PM -0500 "Young,Jeff" &lt;jyoung@oclc.org>
wrote:
<br>>
<br>> I guess I'm saying that resumptionTokens don't necessarily guarantee
you'll
<br>> get "all the new stuff", but could if appropriately implemented.
The
<br>> stateless alternative, though, seems to assume an idealistically
static
<br>> repository. If records are deleted from the repository, a stateless
<br>> harvesting solution doesn't seem to allow for the possibility of
getting all
<br>> the new stuff.
<p>A request for all changes between two dates in the past should always
get
<br>the same answer, so stateless harvesting should work. A half-open request,
<br>that is "until now", will have time-varying results. If harvesters
always
<br>make requests with both from and until, and make sure that the until
date
<br>is not in the future, then stateless harvesting is safe.
<p>There should be some way to get the current time at the repository.
<br>Clock skew will cause nasty problems in time-based harvesting. The
only
<br>safe solution is to always use the clock at the server, and to require
<br>that it is non-decreasing.
<p>wunder
<br>--
<br>Walter Underwood
<br>wunder@inktomi.com
<br>Senior Staff Engineer, Inktomi
<br><a href="http://www.inktomi.com/">http://www.inktomi.com/</a>
<p>_______________________________________________
<br>OAI-implementers mailing list
<br>OAI-implementers@oaisrv.nsdl.cornell.edu
<br><a href="http://oaisrv.nsdl.cornell.edu/mailman/listinfo/oai-implementers">http://oaisrv.nsdl.cornell.edu/mailman/listinfo/oai-implementers</a></blockquote>
</html>

--------------A07397DD47F45319B435C394--


From ajk@mds.rmit.edu.au  Fri Feb  8 03:53:56 2002
From: ajk@mds.rmit.edu.au (Alan Kent)
Date: Fri, 8 Feb 2002 14:53:56 +1100
Subject: FW: [OAI-implementers] Open Archives Initiative Protocol for  Meta data Harvesting Version 2 news
In-Reply-To: <3C633CF3.6F7C874@cs.odu.edu>; from Xiaoming Liu on Thu, Feb 07, 2002 at 09:50:27PM -0500
References: <Pine.LNX.3.95a.1020207221544.30766G-100000@lxplus021.cern.ch> <1640302704.1013123208@diva.inktomi.com> <3C633CF3.6F7C874@cs.odu.edu>
Message-ID: <20020208145356.D12368@io.mds.rmit.edu.au>

Sorry if this is all old hat to other people, but I find getting involved
is the best way to learn and understand. People can always ignore me! :-)

On Thu, Feb 07, 2002 at 09:50:27PM -0500, Xiaoming Liu wrote:
> --- Walter Underwood wrote:
> > A request for all changes between two dates in the past should always get
> > the same answer, so stateless harvesting should work.
> 
> This is a neat way, but I am now sure how well the past is kept in digital
> library ;-) Especially
> in OAI protocol, whenever a record is changed, its datestamp is changed
> too.  So even a request
> for past may not get the same answer.

and

> Maybe there is one way to implement a stateless protocol in current OAI:
> encode query parameters in ResumptionToken:
...
> one example is:
> resumptionToken= 1999:2000:math:oai_dc:100

I assume the 100 means start from record 100.

So by your own argument, the contents of previous queries may change
between requests. So the server *must* keep a copy of the state of the
system when the original query was issued and continue to provide
that consistently to the client. If the results are not consistent,
data could be lost (overlooked) during a long transfer.

Let me expand and ask a few questions (partly from my ignorance).
Is it expected with OAI that new records will come into existance
at a previous point in time? Or are all new records always added
created with monotomically increasing date/time values? For example,
if metadata is harvested from a web site, would the dates of the
web pages be used? Or the date the data was harvested be used?
If the date of the web page, then when a new site is crawled,
new pages can come into existence dated in the past. If the date
the metadata was collected from the web page, then dates increase
monotomically.

If new records are *not* created with monotomic dates, then OAI falls
down doesn't it? Any one who has done a previous crawl may never crawl
for that old date range again and so not get the data. So to be safe,
dates must be monotomically increasing for metadata modified in the
repository.

If changes to the repository are then always given monotomically
increasing dates, then history will never be added to. However,
history can be lost if an old entry is updated (as it will be given
a newer date). So if a cursor scheme is used which says 'give me
records starting from 100' is used, then if a record that was in
the range 1-99 is updated between requests, then what was record
number 100 would slip back to become record number 99. The request
starting from 100 would then miss that record.

Or is the idea with OAI that if a record is updated, then the
old slot is marked as 'deleted' and a new record added as 'inserted'
to keep the same number of slots around?

The normal way this problem is addressed in database systems of
course is to use transactions. When the query is used, the full
answer is effectively worked out and kept around. Any updates,
inserts, or deletes do not affect the query results. The current
OAI protocol then uses the resumptionToken to identify the query
set. But at some stage, the query may be discarded. If the client
has not got all the data yet, then it has to start again from
scratch (unless the data is guaranteed to be returned in monotomically
increasing date order - which its not at present I think).

Using the identifier of a record to remember the position in a
result set is no good either. If that record is updated, it will
move in the result set, messing things up again.

The only invariant that I can think of is the date stamp.
If date/time stamps (to a high resolution) were used, and the
results of ListRecords was in monotomically increasing order
of time, then you actually no longer need resumptionToken at all.
Instead, a new request can be specified with a precise 'from'
value. That would make requests completely stateless. Deletions
in history (due to an update) would not be a problem.

Ok, I will be quiet now and let someone with more history behind
OAI and all its goals etc speak instead.

Alan

From liu_x@cs.odu.edu  Fri Feb  8 04:59:11 2002
From: liu_x@cs.odu.edu (Xiaoming Liu)
Date: Thu, 7 Feb 2002 23:59:11 -0500 (EST)
Subject: FW: [OAI-implementers] Open Archives Initiative Protocol for
 Meta data Harvesting Version 2 news
In-Reply-To: <20020208145356.D12368@io.mds.rmit.edu.au>
Message-ID: <Pine.SOL.4.10.10202072320530.11927-100000@defiant.cs.odu.edu>

Alan,

I guess there are two aspects of my arguments,(DP) data provider and
(SP) service provider.

From the side of SP, it could not presume "a request for the past will
always get the same answer". So the method suggested by Walter won't work.
Instead, SP has to use the resumptionToken to get the right anwser.

From the side of DP, they could implement the resumptionToken by its own
way. If DP can promise "a request for the past will never change", or
they don't care missing something, they can use the method I suggest.
That's the case for CVS-like system (keep each version with different
release number), or maybe some historical documents.

So my opinion is: SP has to use resumptionToken, DP has its own options
about how to implement it. 


About "whether new records are created with monotomic dates" See
definition of datestamp in OAMHP:
"A datestamp is the date of creation, deletion, or latest date of
modification of an item, the effect of which is a change in the metadata
of a record disseminated from that item."

So in a correctly-implemented OAI repository, the new records should be
created with monotomic dates, in your case of webpage/crawler, the date of
the metadata is the date of webpage is harvested.

> Or is the idea with OAI that if a record is updated, then the
> old slot is marked as 'deleted' and a new record added as 'inserted'
> to keep the same number of slots around?

If one record is changed (but identifier keeps same), the correct way is
to change the datestamp. However, if you have a version control system and
change identifier each time, the "deleted"/"inserted" is also a right way.

> The only invariant that I can think of is the date stamp.
> If date/time stamps (to a high resolution) were used, and the
> results of ListRecords was in monotomically increasing order
> of time, then you actually no longer need resumptionToken at all.

By my understanding, OAI2.0 (from Carl&Herbert's email) will support high
resolution date/time stamps as an option. However, there is no promise
that results of ListRecords will be in monotomically increasing order of
time. (It may be unnecessary limitation to some data providers). 

But I agree it will support a pure stateless protocol if all assumption
are satisfied (high resolution date stamps and results is ordered by
time).

Regards,
liu








On Fri, 8 Feb 2002, Alan Kent wrote:

> Sorry if this is all old hat to other people, but I find getting involved
> is the best way to learn and understand. People can always ignore me! :-)
> 
> On Thu, Feb 07, 2002 at 09:50:27PM -0500, Xiaoming Liu wrote:
> > --- Walter Underwood wrote:
> > > A request for all changes between two dates in the past should always get
> > > the same answer, so stateless harvesting should work.
> > 
> > This is a neat way, but I am now sure how well the past is kept in digital
> > library ;-) Especially
> > in OAI protocol, whenever a record is changed, its datestamp is changed
> > too.  So even a request
> > for past may not get the same answer.
> 
> and
> 
> > Maybe there is one way to implement a stateless protocol in current OAI:
> > encode query parameters in ResumptionToken:
> ...
> > one example is:
> > resumptionToken= 1999:2000:math:oai_dc:100
> 
> I assume the 100 means start from record 100.
> 
> So by your own argument, the contents of previous queries may change
> between requests. So the server *must* keep a copy of the state of the
> system when the original query was issued and continue to provide
> that consistently to the client. If the results are not consistent,
> data could be lost (overlooked) during a long transfer.
> 
> Let me expand and ask a few questions (partly from my ignorance).
> Is it expected with OAI that new records will come into existance
> at a previous point in time? Or are all new records always added
> created with monotomically increasing date/time values? For example,
> if metadata is harvested from a web site, would the dates of the
> web pages be used? Or the date the data was harvested be used?
> If the date of the web page, then when a new site is crawled,
> new pages can come into existence dated in the past. If the date
> the metadata was collected from the web page, then dates increase
> monotomically.
> 
> If new records are *not* created with monotomic dates, then OAI falls
> down doesn't it? Any one who has done a previous crawl may never crawl
> for that old date range again and so not get the data. So to be safe,
> dates must be monotomically increasing for metadata modified in the
> repository.
> 
> If changes to the repository are then always given monotomically
> increasing dates, then history will never be added to. However,
> history can be lost if an old entry is updated (as it will be given
> a newer date). So if a cursor scheme is used which says 'give me
> records starting from 100' is used, then if a record that was in
> the range 1-99 is updated between requests, then what was record
> number 100 would slip back to become record number 99. The request
> starting from 100 would then miss that record.
> 
> Or is the idea with OAI that if a record is updated, then the
> old slot is marked as 'deleted' and a new record added as 'inserted'
> to keep the same number of slots around?
> 
> The normal way this problem is addressed in database systems of
> course is to use transactions. When the query is used, the full
> answer is effectively worked out and kept around. Any updates,
> inserts, or deletes do not affect the query results. The current
> OAI protocol then uses the resumptionToken to identify the query
> set. But at some stage, the query may be discarded. If the client
> has not got all the data yet, then it has to start again from
> scratch (unless the data is guaranteed to be returned in monotomically
> increasing date order - which its not at present I think).
> 
> Using the identifier of a record to remember the position in a
> result set is no good either. If that record is updated, it will
> move in the result set, messing things up again.
> 
> The only invariant that I can think of is the date stamp.
> If date/time stamps (to a high resolution) were used, and the
> results of ListRecords was in monotomically increasing order
> of time, then you actually no longer need resumptionToken at all.
> Instead, a new request can be specified with a precise 'from'
> value. That would make requests completely stateless. Deletions
> in history (due to an update) would not be a problem.
> 
> Ok, I will be quiet now and let someone with more history behind
> OAI and all its goals etc speak instead.
> 
> Alan
> _______________________________________________
> OAI-implementers mailing list
> OAI-implementers@oaisrv.nsdl.cornell.edu
> http://oaisrv.nsdl.cornell.edu/mailman/listinfo/oai-implementers
> 


From liu_x@cs.odu.edu  Fri Feb  8 12:57:36 2002
From: liu_x@cs.odu.edu (Xiaoming Liu)
Date: Fri, 8 Feb 2002 07:57:36 -0500 (EST)
Subject: FW: [OAI-implementers] Open Archives Initiative Protocol for
 Meta data Harvesting Version 2 news
In-Reply-To: <Pine.SOL.4.10.10202072320530.11927-100000@defiant.cs.odu.edu>
Message-ID: <Pine.SOL.4.10.10202080722430.12226-100000@defiant.cs.odu.edu>

Sorry for replying my own email ;-)

The more I think this problem, the more I believe it's not a
stateful/stateless problem. If we all agree that Http is a stateless
protocol, what's the fundemental differences between URL rewriting and  
resumptionToken?

I believe the real problem is a read/write lock problem, if a data
provider wants to implement a perfect service , namely return a consistent
cursor between DP (data provider) and SP (service provider), it has to be
working either the way Jeff has suggested: Keep a snapshot of all
identifiers at the instant (a huge work for 1M records); or totally
read lock the whole database.

Because the datastamp is always increasing in OAI, I think  Alan's
method (high resolution date stamps and results is ordered by
time) will also work, but not necessarily monatomically, if the DP could
return all records of a specific datestamp in one reply. But it did
put some dangers to harvester as Walter suggested, if suddenly DP creates
10K records with same datestamp, it has to return them in one response, it
quite possibly will break the harvester.

liu  



On Thu, 7 Feb 2002, Xiaoming Liu wrote:

> Alan,
> 
> I guess there are two aspects of my arguments,(DP) data provider and
> (SP) service provider.
> 
> >From the side of SP, it could not presume "a request for the past will
> always get the same answer". So the method suggested by Walter won't work.
> Instead, SP has to use the resumptionToken to get the right anwser.
> 
> >From the side of DP, they could implement the resumptionToken by its own
> way. If DP can promise "a request for the past will never change", or
> they don't care missing something, they can use the method I suggest.
> That's the case for CVS-like system (keep each version with different
> release number), or maybe some historical documents.
> 
> So my opinion is: SP has to use resumptionToken, DP has its own options
> about how to implement it. 
> 
> 
> About "whether new records are created with monotomic dates" See
> definition of datestamp in OAMHP:
> "A datestamp is the date of creation, deletion, or latest date of
> modification of an item, the effect of which is a change in the metadata
> of a record disseminated from that item."
> 
> So in a correctly-implemented OAI repository, the new records should be
> created with monotomic dates, in your case of webpage/crawler, the date of
> the metadata is the date of webpage is harvested.
> 
> > Or is the idea with OAI that if a record is updated, then the
> > old slot is marked as 'deleted' and a new record added as 'inserted'
> > to keep the same number of slots around?
> 
> If one record is changed (but identifier keeps same), the correct way is
> to change the datestamp. However, if you have a version control system and
> change identifier each time, the "deleted"/"inserted" is also a right way.
> 
> > The only invariant that I can think of is the date stamp.
> > If date/time stamps (to a high resolution) were used, and the
> > results of ListRecords was in monotomically increasing order
> > of time, then you actually no longer need resumptionToken at all.
> 
> By my understanding, OAI2.0 (from Carl&Herbert's email) will support high
> resolution date/time stamps as an option. However, there is no promise
> that results of ListRecords will be in monotomically increasing order of
> time. (It may be unnecessary limitation to some data providers). 
> 
> But I agree it will support a pure stateless protocol if all assumption
> are satisfied (high resolution date stamps and results is ordered by
> time).
> 
> Regards,
> liu
> 
> 
> 
> 
> 
> 
> 
> 
> On Fri, 8 Feb 2002, Alan Kent wrote:
> 
> > Sorry if this is all old hat to other people, but I find getting involved
> > is the best way to learn and understand. People can always ignore me! :-)
> > 
> > On Thu, Feb 07, 2002 at 09:50:27PM -0500, Xiaoming Liu wrote:
> > > --- Walter Underwood wrote:
> > > > A request for all changes between two dates in the past should always get
> > > > the same answer, so stateless harvesting should work.
> > > 
> > > This is a neat way, but I am now sure how well the past is kept in digital
> > > library ;-) Especially
> > > in OAI protocol, whenever a record is changed, its datestamp is changed
> > > too.  So even a request
> > > for past may not get the same answer.
> > 
> > and
> > 
> > > Maybe there is one way to implement a stateless protocol in current OAI:
> > > encode query parameters in ResumptionToken:
> > ...
> > > one example is:
> > > resumptionToken= 1999:2000:math:oai_dc:100
> > 
> > I assume the 100 means start from record 100.
> > 
> > So by your own argument, the contents of previous queries may change
> > between requests. So the server *must* keep a copy of the state of the
> > system when the original query was issued and continue to provide
> > that consistently to the client. If the results are not consistent,
> > data could be lost (overlooked) during a long transfer.
> > 
> > Let me expand and ask a few questions (partly from my ignorance).
> > Is it expected with OAI that new records will come into existance
> > at a previous point in time? Or are all new records always added
> > created with monotomically increasing date/time values? For example,
> > if metadata is harvested from a web site, would the dates of the
> > web pages be used? Or the date the data was harvested be used?
> > If the date of the web page, then when a new site is crawled,
> > new pages can come into existence dated in the past. If the date
> > the metadata was collected from the web page, then dates increase
> > monotomically.
> > 
> > If new records are *not* created with monotomic dates, then OAI falls
> > down doesn't it? Any one who has done a previous crawl may never crawl
> > for that old date range again and so not get the data. So to be safe,
> > dates must be monotomically increasing for metadata modified in the
> > repository.
> > 
> > If changes to the repository are then always given monotomically
> > increasing dates, then history will never be added to. However,
> > history can be lost if an old entry is updated (as it will be given
> > a newer date). So if a cursor scheme is used which says 'give me
> > records starting from 100' is used, then if a record that was in
> > the range 1-99 is updated between requests, then what was record
> > number 100 would slip back to become record number 99. The request
> > starting from 100 would then miss that record.
> > 
> > Or is the idea with OAI that if a record is updated, then the
> > old slot is marked as 'deleted' and a new record added as 'inserted'
> > to keep the same number of slots around?
> > 
> > The normal way this problem is addressed in database systems of
> > course is to use transactions. When the query is used, the full
> > answer is effectively worked out and kept around. Any updates,
> > inserts, or deletes do not affect the query results. The current
> > OAI protocol then uses the resumptionToken to identify the query
> > set. But at some stage, the query may be discarded. If the client
> > has not got all the data yet, then it has to start again from
> > scratch (unless the data is guaranteed to be returned in monotomically
> > increasing date order - which its not at present I think).
> > 
> > Using the identifier of a record to remember the position in a
> > result set is no good either. If that record is updated, it will
> > move in the result set, messing things up again.
> > 
> > The only invariant that I can think of is the date stamp.
> > If date/time stamps (to a high resolution) were used, and the
> > results of ListRecords was in monotomically increasing order
> > of time, then you actually no longer need resumptionToken at all.
> > Instead, a new request can be specified with a precise 'from'
> > value. That would make requests completely stateless. Deletions
> > in history (due to an update) would not be a problem.
> > 
> > Ok, I will be quiet now and let someone with more history behind
> > OAI and all its goals etc speak instead.
> > 
> > Alan
> > _______________________________________________
> > OAI-implementers mailing list
> > OAI-implementers@oaisrv.nsdl.cornell.edu
> > http://oaisrv.nsdl.cornell.edu/mailman/listinfo/oai-implementers
> > 
> 
> _______________________________________________
> OAI-implementers mailing list
> OAI-implementers@oaisrv.nsdl.cornell.edu
> http://oaisrv.nsdl.cornell.edu/mailman/listinfo/oai-implementers
> 


From Tim Cole" <t-cole3@uiuc.edu  Fri Feb  8 23:02:50 2002
From: Tim Cole" <t-cole3@uiuc.edu (Tim Cole)
Date: Fri, 8 Feb 2002 17:02:50 -0600
Subject: FW: [OAI-implementers] Open Archives Initiative Protocol for  Meta data Harvesting Version 2 news
References: <Pine.SOL.4.10.10202080722430.12226-100000@defiant.cs.odu.edu>
Message-ID: <004a01c1b0f4$bda4af80$8e197e82@LIBGRISIS>

Not to curtail the very interesting technical back and forth, but...

The flexible and naive nature of the resumptionToken parameter and the fact
that the OAI-PMH doesn't allow Service Providers to request a fixed number
of records is very much by design.  The minimum granularity and inherent
limitations of the datestamp argument was also a decision made after some
thought.  Given the intended mission of the OAI PMH, I believe the decisions
were correct.  (Whether there's really a niche for what OAI-PMH is intended
to be is of course open to debate.)

OAI PMH was created initially to facilitate interchange of metadata between
E-Print archives.  These archives could be characterized by several
characteristics -- among them that data contained in the archive changed
relatively slowly (i.e., on average relatively few new records added,
changed or deleted day to day) and that the repositories were built on
limited resources and with limited capabilities (some didn't even support
keyword search of full-text of documents held in the repository).

Accordingly OAI PMH built in a lot of flexibility (and a certain amount of
wiggle room) for implementers, particularly metadata providers.  Timestamps
with granularity of only 1 day were allowed.  Flow control was implemented
in the least prescriptive, most stateless way possible.

Some metadata provider services have been built to take advantage of this
flexibility.  For instance I have an experimental OAI provider service that
has no database management software behind it at all.  Instead it relies on
the implementation platform's file system.  Metadata is stored in XML files
and dynamically transformed when requested to the requested metadata schema
using XSLT.  The number of record chunk size returned for a ListRecord
request varies according to the number of records in each file system
directory at the time the request is received.  The order in which records
are returned is determined by the implementation platform's file system and
typically is not chronological, meaning it will change between requests as
records are added, deleted, and updated.  This implementation would not be
able to return a fixed number of records specified by the Service Provider
without substansial changes to its basic design.

The resumption token as used in this implementation includes the requested
metadata prefix, the date range values of the original request, and a list
of remaining directories to be exported.  No state information is ever
maintained on the server side, and the number of records returned in
response to a request with a resumption token isn't determined until the
request is received and processed.  (Thus a later request with same
resumption token may get more or less records.) Datestamps are maintained to
the day only (no hours, minutes, or seconds).  Implementing locking or
creating some sort of state maintainence mechanism would require substansial
and fundamental changes to the design of this implemetation.

I believe the implementation conforms to the current protocol document, and
I'm reasonably sure that with only minor changes it will conform to the 2.0
spec.  I've been surprised at how hard it is to break, though I certainly
don't expect it to be as reliable and robust as some other implementations
I've seen..  It does what it was designed to do.

However this implementation clearly does not support precise harvesting
along the lines that have been discussed on this list over the course of the
last week or two.  The resumptionToken is not deterministic, but only a
somewhat imprecise method used to chunk a long response.  I would contend
that given that the provider implementation descirbed is intended only to
handle a respository of at most a few 10s of thousands of metadata records
and in which additions, updates, and deletions occur at most weekly, and
more often monthly, the imprecise harvesting does not lead to poor
representation of the metadata stored in my repository, and therefore should
not be of concern to Service Providers.  Of course that's debatable.

Which is the question before the OAI Community at this point in time.  Is
there really a niche for a relatively simple protocol that allows in certain
instances for less precise harvesting?  (For instance we've known from the
start that some re-harvesting occurs because datestamps only have
granularity of one day.)  Can services built on such a protocol be useful --
at least for certain purposes?  Obviously not for a bank trying to do
financial transactions, but perhaps in the DL world.  A number of us are
trying to answer these kinds of questions by empirical means rather than
speculation.

Given that there can be circumstances when a metadata provider might want to
avoid overhead of a transactional database system, I would very much oppose
moving OAI-PMH in the direction of SQL style transactions and cursors.  I
would also oppose, especially as a required functionality, upgrading flow
control to allow SPs to specify numbers of records wanted, or to specify
resuming from a particularly record (which implictly assumes an ordered,
persistent response object).  These changes would require providers to
maintain state and would effectively require them to provide transactional
functionalities -- things many of the current providers aren't in a good
position to do.  The benefits of such changes for the target audience don't
seem worth it.  (Which comes back to question raised earlier about whether a
niche protocol aimed at a particular target audience can survive.  I think
it can, but we'll have to see.)

Tim Cole
University of Illinois at Urbana-Champaign

----- Original Message -----
From: "Xiaoming Liu" <liu_x@cs.odu.edu>
To: "Alan Kent" <ajk@mds.rmit.edu.au>
Cc: <oai-implementers@openarchives.org>
Sent: Friday, February 08, 2002 6:57 AM
Subject: Re: FW: [OAI-implementers] Open Archives Initiative Protocol for
Meta data Harvesting Version 2 news


> Sorry for replying my own email ;-)
>
> The more I think this problem, the more I believe it's not a
> stateful/stateless problem. If we all agree that Http is a stateless
> protocol, what's the fundemental differences between URL rewriting and
> resumptionToken?
>
> I believe the real problem is a read/write lock problem, if a data
> provider wants to implement a perfect service , namely return a consistent
> cursor between DP (data provider) and SP (service provider), it has to be
> working either the way Jeff has suggested: Keep a snapshot of all
> identifiers at the instant (a huge work for 1M records); or totally
> read lock the whole database.
>
> Because the datastamp is always increasing in OAI, I think  Alan's
> method (high resolution date stamps and results is ordered by
> time) will also work, but not necessarily monatomically, if the DP could
> return all records of a specific datestamp in one reply. But it did
> put some dangers to harvester as Walter suggested, if suddenly DP creates
> 10K records with same datestamp, it has to return them in one response, it
> quite possibly will break the harvester.
>
> liu
>
>
>
> On Thu, 7 Feb 2002, Xiaoming Liu wrote:
>
> > Alan,
> >
> > I guess there are two aspects of my arguments,(DP) data provider and
> > (SP) service provider.
> >
> > >From the side of SP, it could not presume "a request for the past will
> > always get the same answer". So the method suggested by Walter won't
work.
> > Instead, SP has to use the resumptionToken to get the right anwser.
> >
> > >From the side of DP, they could implement the resumptionToken by its
own
> > way. If DP can promise "a request for the past will never change", or
> > they don't care missing something, they can use the method I suggest.
> > That's the case for CVS-like system (keep each version with different
> > release number), or maybe some historical documents.
> >
> > So my opinion is: SP has to use resumptionToken, DP has its own options
> > about how to implement it.
> >
> >
> > About "whether new records are created with monotomic dates" See
> > definition of datestamp in OAMHP:
> > "A datestamp is the date of creation, deletion, or latest date of
> > modification of an item, the effect of which is a change in the metadata
> > of a record disseminated from that item."
> >
> > So in a correctly-implemented OAI repository, the new records should be
> > created with monotomic dates, in your case of webpage/crawler, the date
of
> > the metadata is the date of webpage is harvested.
> >
> > > Or is the idea with OAI that if a record is updated, then the
> > > old slot is marked as 'deleted' and a new record added as 'inserted'
> > > to keep the same number of slots around?
> >
> > If one record is changed (but identifier keeps same), the correct way is
> > to change the datestamp. However, if you have a version control system
and
> > change identifier each time, the "deleted"/"inserted" is also a right
way.
> >
> > > The only invariant that I can think of is the date stamp.
> > > If date/time stamps (to a high resolution) were used, and the
> > > results of ListRecords was in monotomically increasing order
> > > of time, then you actually no longer need resumptionToken at all.
> >
> > By my understanding, OAI2.0 (from Carl&Herbert's email) will support
high
> > resolution date/time stamps as an option. However, there is no promise
> > that results of ListRecords will be in monotomically increasing order of
> > time. (It may be unnecessary limitation to some data providers).
> >
> > But I agree it will support a pure stateless protocol if all assumption
> > are satisfied (high resolution date stamps and results is ordered by
> > time).
> >
> > Regards,
> > liu
> >
> >
> >
> >
> >
> >
> >
> >
> > On Fri, 8 Feb 2002, Alan Kent wrote:
> >
> > > Sorry if this is all old hat to other people, but I find getting
involved
> > > is the best way to learn and understand. People can always ignore me!
:-)
> > >
> > > On Thu, Feb 07, 2002 at 09:50:27PM -0500, Xiaoming Liu wrote:
> > > > --- Walter Underwood wrote:
> > > > > A request for all changes between two dates in the past should
always get
> > > > > the same answer, so stateless harvesting should work.
> > > >
> > > > This is a neat way, but I am now sure how well the past is kept in
digital
> > > > library ;-) Especially
> > > > in OAI protocol, whenever a record is changed, its datestamp is
changed
> > > > too.  So even a request
> > > > for past may not get the same answer.
> > >
> > > and
> > >
> > > > Maybe there is one way to implement a stateless protocol in current
OAI:
> > > > encode query parameters in ResumptionToken:
> > > ...
> > > > one example is:
> > > > resumptionToken= 1999:2000:math:oai_dc:100
> > >
> > > I assume the 100 means start from record 100.
> > >
> > > So by your own argument, the contents of previous queries may change
> > > between requests. So the server *must* keep a copy of the state of the
> > > system when the original query was issued and continue to provide
> > > that consistently to the client. If the results are not consistent,
> > > data could be lost (overlooked) during a long transfer.
> > >
> > > Let me expand and ask a few questions (partly from my ignorance).
> > > Is it expected with OAI that new records will come into existance
> > > at a previous point in time? Or are all new records always added
> > > created with monotomically increasing date/time values? For example,
> > > if metadata is harvested from a web site, would the dates of the
> > > web pages be used? Or the date the data was harvested be used?
> > > If the date of the web page, then when a new site is crawled,
> > > new pages can come into existence dated in the past. If the date
> > > the metadata was collected from the web page, then dates increase
> > > monotomically.
> > >
> > > If new records are *not* created with monotomic dates, then OAI falls
> > > down doesn't it? Any one who has done a previous crawl may never crawl
> > > for that old date range again and so not get the data. So to be safe,
> > > dates must be monotomically increasing for metadata modified in the
> > > repository.
> > >
> > > If changes to the repository are then always given monotomically
> > > increasing dates, then history will never be added to. However,
> > > history can be lost if an old entry is updated (as it will be given
> > > a newer date). So if a cursor scheme is used which says 'give me
> > > records starting from 100' is used, then if a record that was in
> > > the range 1-99 is updated between requests, then what was record
> > > number 100 would slip back to become record number 99. The request
> > > starting from 100 would then miss that record.
> > >
> > > Or is the idea with OAI that if a record is updated, then the
> > > old slot is marked as 'deleted' and a new record added as 'inserted'
> > > to keep the same number of slots around?
> > >
> > > The normal way this problem is addressed in database systems of
> > > course is to use transactions. When the query is used, the full
> > > answer is effectively worked out and kept around. Any updates,
> > > inserts, or deletes do not affect the query results. The current
> > > OAI protocol then uses the resumptionToken to identify the query
> > > set. But at some stage, the query may be discarded. If the client
> > > has not got all the data yet, then it has to start again from
> > > scratch (unless the data is guaranteed to be returned in monotomically
> > > increasing date order - which its not at present I think).
> > >
> > > Using the identifier of a record to remember the position in a
> > > result set is no good either. If that record is updated, it will
> > > move in the result set, messing things up again.
> > >
> > > The only invariant that I can think of is the date stamp.
> > > If date/time stamps (to a high resolution) were used, and the
> > > results of ListRecords was in monotomically increasing order
> > > of time, then you actually no longer need resumptionToken at all.
> > > Instead, a new request can be specified with a precise 'from'
> > > value. That would make requests completely stateless. Deletions
> > > in history (due to an update) would not be a problem.
> > >
> > > Ok, I will be quiet now and let someone with more history behind
> > > OAI and all its goals etc speak instead.
> > >
> > > Alan
> > > _______________________________________________
> > > OAI-implementers mailing list
> > > OAI-implementers@oaisrv.nsdl.cornell.edu
> > > http://oaisrv.nsdl.cornell.edu/mailman/listinfo/oai-implementers
> > >
> >
> > _______________________________________________
> > OAI-implementers mailing list
> > OAI-implementers@oaisrv.nsdl.cornell.edu
> > http://oaisrv.nsdl.cornell.edu/mailman/listinfo/oai-implementers
> >
>
> _______________________________________________
> OAI-implementers mailing list
> OAI-implementers@oaisrv.nsdl.cornell.edu
> http://oaisrv.nsdl.cornell.edu/mailman/listinfo/oai-implementers
>


From deridder@cs.utk.edu  Sat Feb  9 13:15:57 2002
From: deridder@cs.utk.edu (deridder)
Date: Sat, 9 Feb 2002 08:15:57 -0500 (EST)
Subject: [OAI-implementers] version 2.0
In-Reply-To: <004a01c1b0f4$bda4af80$8e197e82@LIBGRISIS>
Message-ID: <Pine.GSO.4.33.0202090813500.13688-100000@cetus3b.cs.utk.edu>

to the technical committee--

May I ask what changes we can expect to see in version 2.0, and when it is
expected to be released?

  I would appreciate some advance information!  Thanks!

 --jody


From support@eprints.org  Sat Feb  9 15:08:53 2002
From: support@eprints.org (ePrints Support)
Date: Sat, 9 Feb 2002 15:08:53 +0000
Subject: [OAI-implementers] version 2.0
In-Reply-To: <Pine.GSO.4.33.0202090813500.13688-100000@cetus3b.cs.utk.edu>
References: <004a01c1b0f4$bda4af80$8e197e82@LIBGRISIS> <Pine.GSO.4.33.0202090813500.13688-100000@cetus3b.cs.utk.edu>
Message-ID: <20020209150852.GA3383@ecs.soton.ac.uk>

It would seem like a good plan to let the comunnity comment on OAI2.0
before it is declared the official standard - the RFC approach.

On Sat, Feb 09, 2002 at 08:15:57AM -0500, deridder wrote:
> to the technical committee--
> 
> May I ask what changes we can expect to see in version 2.0, and when it is
> expected to be released?
> 
>   I would appreciate some advance information!  Thanks!
> 
>  --jody
> 
> _______________________________________________
> OAI-implementers mailing list
> OAI-implementers@oaisrv.nsdl.cornell.edu
> http://oaisrv.nsdl.cornell.edu/mailman/listinfo/oai-implementers

-- 

 Christopher Gutteridge                   support@eprints.org 
 ePrints Developer                        +44 23 8059 4833


From hussein@vt.edu  Sat Feb  9 15:24:08 2002
From: hussein@vt.edu (Hussein Suleman)
Date: Sat, 09 Feb 2002 10:24:08 -0500
Subject: [Fwd: [OAI-implementers] Open Archives Initiative Protocol for Metadata Harvesting Version 2 news]
Message-ID: <3C653F18.4000203@vt.edu>

hi

in case you missed it, here is the message from Carl Lagoze that answers 
the last two posters' questions ...

ttfn
----hussein

-------- Original Message --------
Subject: [OAI-implementers] Open Archives Initiative Protocol for 
Metadata Harvesting Version 2 news
Date: Mon, 04 Feb 2002 12:04:48 -0500
From: Carl Lagoze <lagoze@cs.cornell.edu>
To: oai-implementers@openarchives.org, oai-general@openarchives.org

Dear OAI community:

In mid-2001 the Open Archives Initiative Technical Committee (OAI-TC) was
formed to develop and write version 2 of the Open Archives Protocol for
Metadata Harvesting (OAI-PMH).  In this email, we would like to inform 
you about:

* The context of this technical work;
* The process for undertaking the work;
* The schedule for the release of v.2.0 of the OAI-PMH;
* Anticipated changes in v.2.0 of the OAI-PMH.

Carl Lagoze and Herbert Van de Sompel

=> The context of this technical work was:

1. The original release of the OAI-PMH, version 1.x, was intended to
initiate a year long period of experimentation with the protocol.  The goal
was to make this experimental version as stable as possible to encourage
usage and testing. (In fact, only one change from version 1.0 to 1.1 was 
made
during the year in response to a W3C change in the XML schema
specification).

2. The OAI-TC work should avoid if possible the addition of significant
functionality to the protocol. Instead, the scope of work should be to
resolve problems that arose over the past year in reaction to experience in
the user community.

3. While it was not deemed necessary that version 2.0 be backward compatible
with version 1.x, the upgrade path when version 2 is release should be
reasonably straightforward.

4. The result of the work, version 2, should be a stable, "standard"
release.  It remains undecided as to whether a formal standardization
process will be undertaken with the version 2 protocol.


  => The process for undertaking this work has been:

1. Formation of the OAI-TC representing technical expertise from a
cross-section of the OAI community.  Conduct of this work within a closed
technical committee follows the same procedure which was successfully used
for the development of OAI-PMH v. 1.x.  Members of OAI-TC are listed at
http://www.openarchives.org/organization/tech.comm.html.

2. Joint identification of issues

3. Development of issue white papers

4. Vetting of white papers to determine those that were in scope of OAI-TC
work

5. Development of issue resolution

6. On-line and phone meetings to reach final issue resolution

7. Reporting and validation of the results of the work of OAI-TC to the 
OAI Steering Committee.
Members of OAI-SC are listed at
http://www.openarchives.org/news/oaiscpress000825.html

8. Protocol revision and writing


=> The schedule for the release of v 2.0 of the protocol is as follows:

1. March 1: release of the protocol to a limited group of alpha testers

2. April 1: beta public release

3. May 1: final public release


=> The following is a summary of the changes that are anticipated for
version 2 of OAI-PMH:

1. Dates and times - Standardize on UTC for all dates and times in protocol
requests ("from" and "until" arguments) and responses.

  2. Harvesting Granularity- Allow all ISO8601 time granularities in dates
and times in the "from" and "until" arguments of protocol requests.  Allow a
data provider to expose its support date/time granularity in the response to
an Identity request.  Default granularity is YYY-MM-DD.

3. Flow control - Improve flow control by allowing the following optional
attributes when a resumptionToken is returned:
* retryAfter - a suggested wait time until the request should be resubmitted

* expirationDate - the projected expiration of the resumptionToken
* completeListSize - total number of items across entire result set
* cursor - index of first item in this batch within entire result set

4. set functionality - It will be possible to specify an identifier as
argument to the ListSets verb, permitting a harvester to inquire to which
sets an item belongs.  Responses to ListRecords and GetRecord will return
the sets to which each item belongs. Support of sets remains optional.

5. base-URL - Insulate harvesters from proxy servers by mandating that the
visible identity of the "handling server" in responses be that of a
persistent "master", that may opaquely reflect requests to slaves.

6. xml schema for mandatory Dublin Core - Coordinate with the DCMI so that
the schema used by the OAI is based on one managed by DCMI.  Must allow
inclusion of the xml lang attribute (specifying the language of the metadata
value).

7. Dedupping - Define an optional "provenance" XML container that can be
attached to metadata records that a data provider aggregates from other
sources.  This will help harvesters in detecting duplicates harvested from
multiple data providers.

8. Error handling - Report OAI errors in OAI responses in a manner
independent of HTTP status codes.

9. Set description - Define an optional XML container with which communities
can describe individual sets.

10. Multiple metadata formats - Modify ListIdentifiers to permit a metadata
format as argument, filtering the return to include only record identifiers
that support the specified format.

_______________________________________________
OAI-implementers mailing list
OAI-implementers@oaisrv.nsdl.cornell.edu
http://oaisrv.nsdl.cornell.edu/mailman/listinfo/oai-implementers

-- 
=======================================================================
hussein suleman -- hussein@vt.edu - vtcs - http://www.husseinsspace.com
=======================================================================


From Steven Bird <sb@ldc.upenn.edu>  Fri Feb  8 15:24:56 2002
From: Steven Bird <sb@ldc.upenn.edu> (Steven Bird)
Date: Fri, 08 Feb 2002 10:24:56 EST
Subject: [OAI-implementers] Validating ListMetadataFormats
Message-ID: <200202081524.g18FOuG14131@unagi.cis.upenn.edu>

I would like to use an XML validation language (e.g. XML Schema) to test
that the document returned by ListMetadataFormats includes a specific
format.  The return typically lists multiple formats, and I just want to
check that the list includes one specific format, e.g.:

<ListMetadataFormats>
  ...
  <metadataFormat>
    <metadataPrefix>olac</metadataPrefix>
    <schema>http://www.language-archives.org/OLAC/0.4/olac.xsd</schema>
    <metadataNamespace>http://www.language-archives.org/OLAC/0.4/</metadataNamespace>
  </metadataFormat>
  ...
</ListMetadataFormats>

The ListMetadataFormats container is supposed to have set semantics.  I
guess I need a set-membership test, and it also needs to work on element
content (not just element names, attribute names, or attribute values).

Of course it is trivial to write a program to do the test, but I was hoping
to find a fully declarative solution, so that our formal requirements
[http://www.language-archives.org/OLAC/protocol.html] can be accompanied by
one or more XML documents which more or less transparently implement them.

I would be grateful for any advice about how to test for set membership
using an XML validation language.

Thanks,
Steven Bird

--
Steven.Bird@ldc.upenn.edu  http://www.ldc.upenn.edu/sb
Assoc Director, LDC; Adj Assoc Prof, CIS & Linguistics
Linguistic Data Consortium, University of Pennsylvania
3615 Market St, Suite 200, Philadelphia, PA 19104-2608




From hussein@vt.edu  Sun Feb 10 22:37:02 2002
From: hussein@vt.edu (Hussein Suleman)
Date: Sun, 10 Feb 2002 17:37:02 -0500
Subject: [OAI-implementers] Validating ListMetadataFormats
References: <200202081524.g18FOuG14131@unagi.cis.upenn.edu>
Message-ID: <3C66F60E.6030206@vt.edu>

This is a multi-part message in MIME format.
--------------020008060509010109040009
Content-Type: text/plain; charset=us-ascii; format=flowed
Content-Transfer-Encoding: 7bit

hi

sounds like an interesting problem for a sunday afternoon :)

i don't believe that XML Schema has the declarative power to 
differentiate between two tags with the same tag name and different 
content. so, i will stick my head out and suggest that it can't be done.

fwiw, XSLT comes to mind since XPath can handle content as well as 
structure. maybe you could just ask that people run their XML through an 
XSL script for checking - or maybe an XSL transformation and then schema 
validation ? its not exactly what u're looking for, but its more useful 
in that people implementing the OLAC format would have XSLT processors 
on their machines with much greater likelihood than any XML validators 
(at least at this point in time).

(i have attached 2 quickly hacked together XSL checkers)

as another suggestion, how about a repository-explorer-like web-based 
compliance test ... you can get compliance-checking code from me or 
Donna and then customize it ...

ttfn
----hussein

Steven Bird wrote:

> I would like to use an XML validation language (e.g. XML Schema) to test
> that the document returned by ListMetadataFormats includes a specific
> format.  The return typically lists multiple formats, and I just want to
> check that the list includes one specific format, e.g.:
> 
> <ListMetadataFormats>
>   ...
>   <metadataFormat>
>     <metadataPrefix>olac</metadataPrefix>
>     <schema>http://www.language-archives.org/OLAC/0.4/olac.xsd</schema>
>     <metadataNamespace>http://www.language-archives.org/OLAC/0.4/</metadataNamespace>
>   </metadataFormat>
>   ...
> </ListMetadataFormats>
> 
> The ListMetadataFormats container is supposed to have set semantics.  I
> guess I need a set-membership test, and it also needs to work on element
> content (not just element names, attribute names, or attribute values).
> 
> Of course it is trivial to write a program to do the test, but I was hoping
> to find a fully declarative solution, so that our formal requirements
> [http://www.language-archives.org/OLAC/protocol.html] can be accompanied by
> one or more XML documents which more or less transparently implement them.
> 
> I would be grateful for any advice about how to test for set membership
> using an XML validation language.
> 
> Thanks,
> Steven Bird
> 
> --
> Steven.Bird@ldc.upenn.edu  http://www.ldc.upenn.edu/sb
> Assoc Director, LDC; Adj Assoc Prof, CIS & Linguistics
> Linguistic Data Consortium, University of Pennsylvania
> 3615 Market St, Suite 200, Philadelphia, PA 19104-2608
> 
> 
> 
> _______________________________________________
> OAI-implementers mailing list
> OAI-implementers@oaisrv.nsdl.cornell.edu
> http://oaisrv.nsdl.cornell.edu/mailman/listinfo/oai-implementers
> 


-- 
======================================================================
hussein suleman - hussein@vt.edu - vtcs - http://www.husseinsspace.com
======================================================================

--------------020008060509010109040009
Content-Type: text/xml;
 name="testmdf1.xsl"
Content-Transfer-Encoding: 7bit
Content-Disposition: inline;
 filename="testmdf1.xsl"

<?xml version="1.0"?>

<!-- 
  check for presence of one or more metadata formats in an OAI 
   ListMetadataFormats response v1
  hussein suleman, VT-DLRL, 10 feb 2001
-->

<xsl:stylesheet version="1.0"
 xmlns:xsl="http://www.w3.org/1999/XSL/Transform"
 xmlns:oai="http://www.openarchives.org/OAI/1.1/OAI_ListMetadataFormats"
>

 <xsl:output method="text"/>
 
 <xsl:variable name="olac02">http://www.language-archives.org/OLAC/olac-0.2.xsd</xsl:variable>
 <xsl:variable name="olac04">http://www.language-archives.org/OLAC/0.4/olac.xsd</xsl:variable>
 
 <xsl:template match="oai:ListMetadataFormats">
    <xsl:apply-templates select="oai:metadataFormat/oai:schema"/>
 </xsl:template>
 
 <xsl:template match="oai:metadataFormat/oai:schema[.=$olac02]">
    <xsl:text>Got OLAC v0.2 metadata</xsl:text>
 </xsl:template>

 <xsl:template match="oai:metadataFormat/oai:schema[.=$olac04]">
    <xsl:text>Got OLAC v0.4 metadata</xsl:text>
 </xsl:template>
 
 <xsl:template match="*"/>
 
</xsl:stylesheet> 

--------------020008060509010109040009
Content-Type: text/xml;
 name="testmdf2.xsl"
Content-Transfer-Encoding: 7bit
Content-Disposition: inline;
 filename="testmdf2.xsl"

<?xml version="1.0"?>

<!-- 
  check for presence of one or more metadata formats in an OAI 
   ListMetadataFormats response v2
  hussein suleman, VT-DLRL, 10 feb 2001
-->

<xsl:stylesheet version="1.0"
 xmlns:xsl="http://www.w3.org/1999/XSL/Transform"
 xmlns:oai="http://www.openarchives.org/OAI/1.1/OAI_ListMetadataFormats"
>

 <xsl:output method="text"/>
 
 <xsl:variable name="olac02">http://www.language-archives.org/OLAC/olac-0.2.xsd</xsl:variable>
 <xsl:variable name="olac04">http://www.language-archives.org/OLAC/0.4/olac.xsd</xsl:variable>
 
 <xsl:template match="oai:ListMetadataFormats">
    <xsl:choose>
       <xsl:when test="count(oai:metadataFormat/oai:schema[.=$olac02]) > 0">
          <xsl:text>Got OLAC v0.2 metadata</xsl:text>
       </xsl:when>
       <xsl:when test="count(oai:metadataFormat/oai:schema[.=$olac04]) > 0">
          <xsl:text>Got OLAC v0.4 metadata</xsl:text>
       </xsl:when>
       <xsl:otherwise>
          <xsl:text>No OLAC format</xsl:text>
       </xsl:otherwise>
    </xsl:choose>
 </xsl:template>
 
</xsl:stylesheet> 

--------------020008060509010109040009--


From ajk@mds.rmit.edu.au  Sun Feb 10 23:18:52 2002
From: ajk@mds.rmit.edu.au (Alan Kent)
Date: Mon, 11 Feb 2002 10:18:52 +1100
Subject: [OAI-implementers] Resumption 'from' date.
In-Reply-To: <004a01c1b0f4$bda4af80$8e197e82@LIBGRISIS>; from Tim Cole on Fri, Feb 08, 2002 at 05:02:50PM -0600
References: <Pine.SOL.4.10.10202080722430.12226-100000@defiant.cs.odu.edu> <004a01c1b0f4$bda4af80$8e197e82@LIBGRISIS>
Message-ID: <20020211101852.A11892@io.mds.rmit.edu.au>

On Fri, Feb 08, 2002 at 05:02:50PM -0600, Tim Cole wrote:
> Not to curtail the very interesting technical back and forth, but...

If a goal of OAI is to keep it simple and not change radically (which
I can appreciate), then I would revert to my simpler proposed extension
which is to allow a server to return an optional addtional date/time in
ListRecords/ListIdentifiers responses indicating that "the client can
use this as a 'from' date to resume if the response token times out".

For the very simple implementations (or small data volume sites), the
server just omits this value.

For more sophisticated implementations with a database engine behind
the scenes (for example, so it can easly sort the records), then for
each packet it can say "I am guaranteeing to at least have returned
everything up to this date". This allows a harvester client hitting a
large site for a first time to not have to start again from scratch if
something goes wrong (resumption token time out etc). Date resolution
is fine here (getting some entries a second time is not the problem -
the problem is starting again from the very beginning).

My first attempt at a client harvester for example took about a day to
go to several sites and download everything. It hung several times
(unknown network issues), meaning I had to restart it on some large
sites from scratch. Many other sites it failed for (I can post a list
if people are interested - many seemed to only support GET and not POST).

Alan

From ajk@mds.rmit.edu.au  Mon Feb 11 01:08:49 2002
From: ajk@mds.rmit.edu.au (Alan Kent)
Date: Mon, 11 Feb 2002 12:08:49 +1100
Subject: [OAI-implementers] Results for various sites trying POST requests
Message-ID: <20020211120849.D11892@io.mds.rmit.edu.au>

I have built up a HTML page of interop tests of a simple client
I was trying to write (ie: might be buggy from my end) when trying
to POST to various other servers out there. I have not tried GET
requests instead. I supply the VERB in the POST data (not on the
URL) which I think caused many of the faults.

There are several sites that I have not yet sucesfully completed
a download of. A network problem or similar occurs before they
finish, so I have to restart from scratch.

If people are interested, the results can be found at:

    http://www.mds.rmit.edu.au/~ajk/oai/interop.htm

In the SOAP interop test bed (which I have been involved a little bit
in), people with clients and servers tend to host such pages which
has helped a lot in achieving interoperability. Nothing like airing
dirty laundry to get people to clean up their act! :-) From my
reading so far of OAI, I suspect there may not be the same push
behind OAI.

If I have missed a site, please let me know and I will add it.
The table is currently manually maintained - I am still investigating
OAI to see if its worth pursuing further. If people are interested
(including me! :-), I could investigate generating such tables
automatically including more detail (wire dumps). A sample page
for SOAP interop is at

    http://www.mds.rmit.edu.au/~ajk/soap/interop-results.htm

Alan

ps: The product I work on is currently undergoing a name change from
SIM to TeraText, so I probably will mix up the names until I brainwash
myself to the new name! :-)

From liu_x@cs.odu.edu  Mon Feb 11 02:17:51 2002
From: liu_x@cs.odu.edu (Xiaoming Liu)
Date: Sun, 10 Feb 2002 21:17:51 -0500 (EST)
Subject: [OAI-implementers] Resumption 'from' date.
In-Reply-To: <20020211101852.A11892@io.mds.rmit.edu.au>
Message-ID: <Pine.SOL.4.10.10202102100510.13729-100000@defiant.cs.odu.edu>

On Mon, 11 Feb 2002, Alan Kent wrote:

> If a goal of OAI is to keep it simple and not change radically (which
> I can appreciate), then I would revert to my simpler proposed extension

Based on previous discussions in this list, I think there is one way to
implement a consistent/stateless view (from the harvester) without
modifying protocol.

The suggested way is to encode the resumptionToken with the query
parameter, at the same time data provider always uses datestamp to sort
the query result.

The format should be almost same as I suggested before, but the cursor
will be the current processed datestamp (borrowed from your solution).
likely:

resumptionToken=sets:from:until:metadataformat:processed_datestamp.

The resumptionToken is transparent to service provider, but when data
provider sees this resumptionToken, it will re-create the query, and use
this "processed_datestamp" as a "from" date.

And whether to implement such a mechanism is totally depended on the data
provider, a large /frequently changed data provider may want to use such a
mechanism to support a consistent view to harvester. 

regards,
liu


> which is to allow a server to return an optional addtional date/time in
> ListRecords/ListIdentifiers responses indicating that "the client can
> use this as a 'from' date to resume if the response token times out".
> 
> For the very simple implementations (or small data volume sites), the
> server just omits this value.
> 
> For more sophisticated implementations with a database engine behind
> the scenes (for example, so it can easly sort the records), then for
> each packet it can say "I am guaranteeing to at least have returned
> everything up to this date". This allows a harvester client hitting a
> large site for a first time to not have to start again from scratch if
> something goes wrong (resumption token time out etc). Date resolution
> is fine here (getting some entries a second time is not the problem -
> the problem is starting again from the very beginning).
> 
> My first attempt at a client harvester for example took about a day to
> go to several sites and download everything. It hung several times
> (unknown network issues), meaning I had to restart it on some large
> sites from scratch. Many other sites it failed for (I can post a list
> if people are interested - many seemed to only support GET and not POST).
> 
> Alan
> _______________________________________________
> OAI-implementers mailing list
> OAI-implementers@oaisrv.nsdl.cornell.edu
> http://oaisrv.nsdl.cornell.edu/mailman/listinfo/oai-implementers
> 


From tim@tim.brody.btinternet.co.uk  Mon Feb 11 12:21:04 2002
From: tim@tim.brody.btinternet.co.uk (Tim Brody)
Date: Mon, 11 Feb 2002 12:21:04 -0000
Subject: [OAI-implementers] Results for various sites trying POST requests
References: <20020211120849.D11892@io.mds.rmit.edu.au>
Message-ID: <00d301c1b2f6$9372d580$14414e98@Shrek>

Hi Alan,

I don't believe the issue of "naming and shaming" repositories has come up
before in OAI. I believe the theory is that the validation carried our
during registration should make sure that publicly-accessible repositories
are sufficiently error-free to be harvested.
(so I don't know whether your results reflect more upon repository's
implementations, or the OAI testing process ...)

What would be very interesting would be to correlate your results with how
OAI-PMH has been implemented at the repository - whether the admin has used
one of the available APIs, languages, and so on.
(It's a shame that many repositories seem to code their own implementation.
Perhaps OAI should be more pro-active in promoting the development of, and
use of standard APIs, including standard error messages)


Might I suggest an addition to your testing, that should be relatively
simple (from the last new problem I found with a repository):
Do records have an identifier and datestamp?

I noticed there were some problems with resumptionTokens - how does the
repository behave when its given escaped/unescaped resumptionTokens?

I guess the verb problem is related to POST (and a misleading error
message).

The required metadataPrefix/resumptionToken problem is because the protocol
document isn't very clear. No arguments, apart from the verb, should be
given when a resumptionToken is used. This exclusivity is confusing when the
document says metadataPrefix is required.
(perhaps a note should be added, making this clear?)

All the best,
Tim.

----- Original Message -----
From: "Alan Kent" <ajk@mds.rmit.edu.au>
To: "OAI Implementors" <oai-implementers@oaisrv.nsdl.cornell.edu>
Sent: Monday, February 11, 2002 1:08 AM
Subject: [OAI-implementers] Results for various sites trying POST requests


> I have built up a HTML page of interop tests of a simple client
> I was trying to write (ie: might be buggy from my end) when trying
> to POST to various other servers out there. I have not tried GET
> requests instead. I supply the VERB in the POST data (not on the
> URL) which I think caused many of the faults.
>
> There are several sites that I have not yet sucesfully completed
> a download of. A network problem or similar occurs before they
> finish, so I have to restart from scratch.
>
> If people are interested, the results can be found at:
>
>     http://www.mds.rmit.edu.au/~ajk/oai/interop.htm
>
> In the SOAP interop test bed (which I have been involved a little bit
> in), people with clients and servers tend to host such pages which
> has helped a lot in achieving interoperability. Nothing like airing
> dirty laundry to get people to clean up their act! :-) From my
> reading so far of OAI, I suspect there may not be the same push
> behind OAI.
>
> If I have missed a site, please let me know and I will add it.
> The table is currently manually maintained - I am still investigating
> OAI to see if its worth pursuing further. If people are interested
> (including me! :-), I could investigate generating such tables
> automatically including more detail (wire dumps). A sample page
> for SOAP interop is at
>
>     http://www.mds.rmit.edu.au/~ajk/soap/interop-results.htm
>
> Alan
>
> ps: The product I work on is currently undergoing a name change from
> SIM to TeraText, so I probably will mix up the names until I brainwash
> myself to the new name! :-)
> _______________________________________________
> OAI-implementers mailing list
> OAI-implementers@oaisrv.nsdl.cornell.edu
> http://oaisrv.nsdl.cornell.edu/mailman/listinfo/oai-implementers


From support@eprints.org  Mon Feb 11 19:32:12 2002
From: support@eprints.org (ePrints Support)
Date: Mon, 11 Feb 2002 19:32:12 +0000
Subject: [OAI-implementers] Results for various sites trying POST requests
In-Reply-To: <00d301c1b2f6$9372d580$14414e98@Shrek>
References: <20020211120849.D11892@io.mds.rmit.edu.au> <00d301c1b2f6$9372d580$14414e98@Shrek>
Message-ID: <20020211193212.GD24932@ecs.soton.ac.uk>

<shame> cogprints has that bad XML glitch. I'm not sure how someone managed
to input such whacky data, but still the XML library it uses didn't handle it
in any clever way :(

cogprints is runing the latest version of eprints 1, and I plan to upgrade it
to eprints 2 when I find the time. If anyone else has got a problem with 
eprints 1 OAI I'll work it out. Probably a couple of lines to change.

I think the naming & shaming is a good idea as it will save serious harvestors
dealing with messy services and will encourage us naughty providers to clean
up our act!

chris/eprints.org

On Mon, Feb 11, 2002 at 12:21:04PM -0000, Tim Brody wrote:
> Hi Alan,
> 
> I don't believe the issue of "naming and shaming" repositories has come up
> before in OAI. I believe the theory is that the validation carried our
> during registration should make sure that publicly-accessible repositories
> are sufficiently error-free to be harvested.
> (so I don't know whether your results reflect more upon repository's
> implementations, or the OAI testing process ...)
> 
> What would be very interesting would be to correlate your results with how
> OAI-PMH has been implemented at the repository - whether the admin has used
> one of the available APIs, languages, and so on.
> (It's a shame that many repositories seem to code their own implementation.
> Perhaps OAI should be more pro-active in promoting the development of, and
> use of standard APIs, including standard error messages)
> 
> 
> Might I suggest an addition to your testing, that should be relatively
> simple (from the last new problem I found with a repository):
> Do records have an identifier and datestamp?
> 
> I noticed there were some problems with resumptionTokens - how does the
> repository behave when its given escaped/unescaped resumptionTokens?
> 
> I guess the verb problem is related to POST (and a misleading error
> message).
> 
> The required metadataPrefix/resumptionToken problem is because the protocol
> document isn't very clear. No arguments, apart from the verb, should be
> given when a resumptionToken is used. This exclusivity is confusing when the
> document says metadataPrefix is required.
> (perhaps a note should be added, making this clear?)
> 
> All the best,
> Tim.
> 
> ----- Original Message -----
> From: "Alan Kent" <ajk@mds.rmit.edu.au>
> To: "OAI Implementors" <oai-implementers@oaisrv.nsdl.cornell.edu>
> Sent: Monday, February 11, 2002 1:08 AM
> Subject: [OAI-implementers] Results for various sites trying POST requests
> 
> 
> > I have built up a HTML page of interop tests of a simple client
> > I was trying to write (ie: might be buggy from my end) when trying
> > to POST to various other servers out there. I have not tried GET
> > requests instead. I supply the VERB in the POST data (not on the
> > URL) which I think caused many of the faults.
> >
> > There are several sites that I have not yet sucesfully completed
> > a download of. A network problem or similar occurs before they
> > finish, so I have to restart from scratch.
> >
> > If people are interested, the results can be found at:
> >
> >     http://www.mds.rmit.edu.au/~ajk/oai/interop.htm
> >
> > In the SOAP interop test bed (which I have been involved a little bit
> > in), people with clients and servers tend to host such pages which
> > has helped a lot in achieving interoperability. Nothing like airing
> > dirty laundry to get people to clean up their act! :-) From my
> > reading so far of OAI, I suspect there may not be the same push
> > behind OAI.
> >
> > If I have missed a site, please let me know and I will add it.
> > The table is currently manually maintained - I am still investigating
> > OAI to see if its worth pursuing further. If people are interested
> > (including me! :-), I could investigate generating such tables
> > automatically including more detail (wire dumps). A sample page
> > for SOAP interop is at
> >
> >     http://www.mds.rmit.edu.au/~ajk/soap/interop-results.htm
> >
> > Alan
> >
> > ps: The product I work on is currently undergoing a name change from
> > SIM to TeraText, so I probably will mix up the names until I brainwash
> > myself to the new name! :-)
> > _______________________________________________
> > OAI-implementers mailing list
> > OAI-implementers@oaisrv.nsdl.cornell.edu
> > http://oaisrv.nsdl.cornell.edu/mailman/listinfo/oai-implementers
> 
> _______________________________________________
> OAI-implementers mailing list
> OAI-implementers@oaisrv.nsdl.cornell.edu
> http://oaisrv.nsdl.cornell.edu/mailman/listinfo/oai-implementers

-- 

 Christopher Gutteridge                   support@eprints.org 
 ePrints Developer                        +44 23 8059 4833


From ajk@mds.rmit.edu.au  Tue Feb 12 01:18:47 2002
From: ajk@mds.rmit.edu.au (Alan Kent)
Date: Tue, 12 Feb 2002 12:18:47 +1100
Subject: [OAI-implementers] Results for various sites trying POST requests
In-Reply-To: <00d301c1b2f6$9372d580$14414e98@Shrek>; from Tim Brody on Mon, Feb 11, 2002 at 12:21:04PM -0000
References: <20020211120849.D11892@io.mds.rmit.edu.au> <00d301c1b2f6$9372d580$14414e98@Shrek>
Message-ID: <20020212121847.B28179@io.mds.rmit.edu.au>

On Mon, Feb 11, 2002 at 12:21:04PM -0000, Tim Brody wrote:
> What would be very interesting would be to correlate your results with how
> OAI-PMH has been implemented at the repository - whether the admin has used
> one of the available APIs, languages, and so on.

Maybe as part of OAI 2.0 the Identify command could have a standard
slot (if its not there already) identifying the toolkit implementation.
Sort of like User-Agent in HTTP or implementation in Z39.50. I certainly
noticed some consistent errors which I *assume* are toolkit implementation
issues.

> (It's a shame that many repositories seem to code their own implementation.
> Perhaps OAI should be more pro-active in promoting the development of, and
> use of standard APIs, including standard error messages)

I am in two minds here. I think a good thing about OAI is that it is
a relatively simple protocol. Wide adoptance I think is better based
on easy implementation and easy verification. SOAP for example has
benefited greatly from an interoperability testbed. People put up
test servers strictly for the purpose of interop testing. People
agree what the answers should be, and then fire their clients against
each other's servers to see if the results are correct. This may
be out of scope for OAI - it depends on the scale you want to achieve
for OAI.

For example, my personal current interest in OAI is not for digital
libraries. I see that it has potential for any site with metadata
to reduce their traffic from web crawlers.

I do not know what OAI 2.0 is going to be like. If it is XML request
and response packets (as distinct from HTTP variables and XML responses)
then you can easily come up with 'doing OAI with SOAP' documents.
It might not be the ideal way to do it, but SOAP supports the concept
of document/literal encoding where XML can be (almost!!) verbatim
dropped in wrapper SOAP elements. Basically there would be a mechanism
to get it more widely noticed.

> All the best,
> Tim.

Thanks for the above and all your other comments.

Alan

ps: I have done another pass over various sites using POST having fixed
bugs in my client. Things worked better. Full results are at

    http://www.mds.rmit.edu.au/~ajk/oai/interop.htm

Summary of failures (remember, bugs may be my client!):

    XML parse errors: aim25, anlc, cogprints, NSDL-DEV-CU, SUUB
    POST not supported: cimi, HUBerlin, lacito, physdoc
    Resumption related: ethnologue, hsss
    Other: aisri, CPS, EKUTuebingen, ibiblio, in2p3, mit.etheses, ota,
	thesis, tkn UDLAthesis, yea

But on the success side, I have managed to collect 381,000 metadata
records so far. I wonder what our next internet bill is going to be! :-)

From leop@engr.arizona.edu  Tue Feb 12 15:22:08 2002
From: leop@engr.arizona.edu (Leo)
Date: Tue, 12 Feb 2002 08:22:08 -0700
Subject: [OAI-implementers] Results for various sites trying POST requests
References: <20020211120849.D11892@io.mds.rmit.edu.au> <00d301c1b2f6$9372d580$14414e98@Shrek> <20020212121847.B28179@io.mds.rmit.edu.au>
Message-ID: <013201c1b3d9$0993f090$cdddc480@LIBRARY05>

> > (It's a shame that many repositories seem to code their own
implementation.
> > Perhaps OAI should be more pro-active in promoting the development of,
and
> > use of standard APIs, including standard error messages)

I'm pretty new to OAI, but my use of it has primarily been as a protocol
layer for my project's cataloging and webcrawling interface for standards
like dublin-core or dublin-core extended and MARC.  Enough of that though.
Since I use it as a protocol, I would rather not expect it to deliver
anything else (like standard error messages or handling through an API);
however, it would be very nice to see those things.

I noticed a few postings back there was talk of a skeleton or base framework
for implementing OAI. Whatever did happen to that, I wonder?

-Leo

----- Original Message -----
From: "Alan Kent" <ajk@mds.rmit.edu.au>
To: "OAI Implementors" <oai-implementers@oaisrv.nsdl.cornell.edu>
Sent: Monday, February 11, 2002 18:18
Subject: Re: [OAI-implementers] Results for various sites trying POST
requests


> On Mon, Feb 11, 2002 at 12:21:04PM -0000, Tim Brody wrote:
> > What would be very interesting would be to correlate your results with
how
> > OAI-PMH has been implemented at the repository - whether the admin has
used
> > one of the available APIs, languages, and so on.
>
> Maybe as part of OAI 2.0 the Identify command could have a standard
> slot (if its not there already) identifying the toolkit implementation.
> Sort of like User-Agent in HTTP or implementation in Z39.50. I certainly
> noticed some consistent errors which I *assume* are toolkit implementation
> issues.
>
> > (It's a shame that many repositories seem to code their own
implementation.
> > Perhaps OAI should be more pro-active in promoting the development of,
and
> > use of standard APIs, including standard error messages)
>
> I am in two minds here. I think a good thing about OAI is that it is
> a relatively simple protocol. Wide adoptance I think is better based
> on easy implementation and easy verification. SOAP for example has
> benefited greatly from an interoperability testbed. People put up
> test servers strictly for the purpose of interop testing. People
> agree what the answers should be, and then fire their clients against
> each other's servers to see if the results are correct. This may
> be out of scope for OAI - it depends on the scale you want to achieve
> for OAI.
>
> For example, my personal current interest in OAI is not for digital
> libraries. I see that it has potential for any site with metadata
> to reduce their traffic from web crawlers.
>
> I do not know what OAI 2.0 is going to be like. If it is XML request
> and response packets (as distinct from HTTP variables and XML responses)
> then you can easily come up with 'doing OAI with SOAP' documents.
> It might not be the ideal way to do it, but SOAP supports the concept
> of document/literal encoding where XML can be (almost!!) verbatim
> dropped in wrapper SOAP elements. Basically there would be a mechanism
> to get it more widely noticed.
>
> > All the best,
> > Tim.
>
> Thanks for the above and all your other comments.
>
> Alan
>
> ps: I have done another pass over various sites using POST having fixed
> bugs in my client. Things worked better. Full results are at
>
>     http://www.mds.rmit.edu.au/~ajk/oai/interop.htm
>
> Summary of failures (remember, bugs may be my client!):
>
>     XML parse errors: aim25, anlc, cogprints, NSDL-DEV-CU, SUUB
>     POST not supported: cimi, HUBerlin, lacito, physdoc
>     Resumption related: ethnologue, hsss
>     Other: aisri, CPS, EKUTuebingen, ibiblio, in2p3, mit.etheses, ota,
> thesis, tkn UDLAthesis, yea
>
> But on the success side, I have managed to collect 381,000 metadata
> records so far. I wonder what our next internet bill is going to be! :-)
> _______________________________________________
> OAI-implementers mailing list
> OAI-implementers@oaisrv.nsdl.cornell.edu
> http://oaisrv.nsdl.cornell.edu/mailman/listinfo/oai-implementers
>


From caar@loc.gov  Tue Feb 12 18:13:01 2002
From: caar@loc.gov (Caroline Arms)
Date: Tue, 12 Feb 2002 13:13:01 -0500 (EST)
Subject: [OAI-implementers] Support for Tim Cole's comments
In-Reply-To: <004a01c1b0f4$bda4af80$8e197e82@LIBGRISIS>
Message-ID: <Pine.SOL.4.21.0202121254190.6521-100000@sun8.loc.gov>

I would just like to endorse Tim Cole's comments about appreciating the
flexibility of the resumptionToken.  Our implementation is somewhat
similar to his in that there is no database management system, but static
files of records, which are updated infrequently.  In our case, a whole
"set" is likely to be updated at once, which means that fine granularity
of timestamps will not help with the issue of dividing the response into
chunks.  We have been using fairly small response sets for records and
expiring the resumptionTokens fairly quickly, in order to avoid problems
from major updates between issue of the token and its use.  We have no way
to ensure that the order would be the same after the update.

We would certainly be interested in hearing from harvesters if our chunks
are annoyingly small and if our short expiry times are causing problems.  
We made implementation decisions for these based on no information and
would be happy to reconsider based on real experience.

    Caroline Arms                                    caar@loc.gov
    National Digital Library Program
      &
    Information Technology Services
    
PS I will be away for a week.  I'll deal with any responses to this
message on my return.

On Fri, 8 Feb 2002, Tim Cole wrote:

> Not to curtail the very interesting technical back and forth, but...
> 
> The flexible and naive nature of the resumptionToken parameter and the fact
> that the OAI-PMH doesn't allow Service Providers to request a fixed number
> of records is very much by design.  The minimum granularity and inherent
> limitations of the datestamp argument was also a decision made after some
> thought.  Given the intended mission of the OAI PMH, I believe the decisions
> were correct.  (Whether there's really a niche for what OAI-PMH is intended
> to be is of course open to debate.)
> 
> OAI PMH was created initially to facilitate interchange of metadata between
> E-Print archives.  These archives could be characterized by several
> characteristics -- among them that data contained in the archive changed
> relatively slowly (i.e., on average relatively few new records added,
> changed or deleted day to day) and that the repositories were built on
> limited resources and with limited capabilities (some didn't even support
> keyword search of full-text of documents held in the repository).
> 
> Accordingly OAI PMH built in a lot of flexibility (and a certain amount of
> wiggle room) for implementers, particularly metadata providers.  Timestamps
> with granularity of only 1 day were allowed.  Flow control was implemented
> in the least prescriptive, most stateless way possible.
> 
> Some metadata provider services have been built to take advantage of this
> flexibility.  For instance I have an experimental OAI provider service that
> has no database management software behind it at all.  Instead it relies on
> the implementation platform's file system.  Metadata is stored in XML files
> and dynamically transformed when requested to the requested metadata schema
> using XSLT.  The number of record chunk size returned for a ListRecord
> request varies according to the number of records in each file system
> directory at the time the request is received.  The order in which records
> are returned is determined by the implementation platform's file system and
> typically is not chronological, meaning it will change between requests as
> records are added, deleted, and updated.  This implementation would not be
> able to return a fixed number of records specified by the Service Provider
> without substansial changes to its basic design.
> 
> The resumption token as used in this implementation includes the requested
> metadata prefix, the date range values of the original request, and a list
> of remaining directories to be exported.  No state information is ever
> maintained on the server side, and the number of records returned in
> response to a request with a resumption token isn't determined until the
> request is received and processed.  (Thus a later request with same
> resumption token may get more or less records.) Datestamps are maintained to
> the day only (no hours, minutes, or seconds).  Implementing locking or
> creating some sort of state maintainence mechanism would require substansial
> and fundamental changes to the design of this implemetation.
> 
> I believe the implementation conforms to the current protocol document, and
> I'm reasonably sure that with only minor changes it will conform to the 2.0
> spec.  I've been surprised at how hard it is to break, though I certainly
> don't expect it to be as reliable and robust as some other implementations
> I've seen..  It does what it was designed to do.
> 
> However this implementation clearly does not support precise harvesting
> along the lines that have been discussed on this list over the course of the
> last week or two.  The resumptionToken is not deterministic, but only a
> somewhat imprecise method used to chunk a long response.  I would contend
> that given that the provider implementation descirbed is intended only to
> handle a respository of at most a few 10s of thousands of metadata records
> and in which additions, updates, and deletions occur at most weekly, and
> more often monthly, the imprecise harvesting does not lead to poor
> representation of the metadata stored in my repository, and therefore should
> not be of concern to Service Providers.  Of course that's debatable.
> 
> Which is the question before the OAI Community at this point in time.  Is
> there really a niche for a relatively simple protocol that allows in certain
> instances for less precise harvesting?  (For instance we've known from the
> start that some re-harvesting occurs because datestamps only have
> granularity of one day.)  Can services built on such a protocol be useful --
> at least for certain purposes?  Obviously not for a bank trying to do
> financial transactions, but perhaps in the DL world.  A number of us are
> trying to answer these kinds of questions by empirical means rather than
> speculation.
> 
> Given that there can be circumstances when a metadata provider might want to
> avoid overhead of a transactional database system, I would very much oppose
> moving OAI-PMH in the direction of SQL style transactions and cursors.  I
> would also oppose, especially as a required functionality, upgrading flow
> control to allow SPs to specify numbers of records wanted, or to specify
> resuming from a particularly record (which implictly assumes an ordered,
> persistent response object).  These changes would require providers to
> maintain state and would effectively require them to provide transactional
> functionalities -- things many of the current providers aren't in a good
> position to do.  The benefits of such changes for the target audience don't
> seem worth it.  (Which comes back to question raised earlier about whether a
> niche protocol aimed at a particular target audience can survive.  I think
> it can, but we'll have to see.)
> 
> Tim Cole
> University of Illinois at Urbana-Champaign
> 


From ajk@mds.rmit.edu.au  Wed Feb 13 00:29:03 2002
From: ajk@mds.rmit.edu.au (Alan Kent)
Date: Wed, 13 Feb 2002 11:29:03 +1100
Subject: [OAI-implementers] Support for Tim Cole's comments
In-Reply-To: <Pine.SOL.4.21.0202121254190.6521-100000@sun8.loc.gov>; from Caroline Arms on Tue, Feb 12, 2002 at 01:13:01PM -0500
References: <004a01c1b0f4$bda4af80$8e197e82@LIBGRISIS> <Pine.SOL.4.21.0202121254190.6521-100000@sun8.loc.gov>
Message-ID: <20020213112903.B16742@io.mds.rmit.edu.au>

On Tue, Feb 12, 2002 at 01:13:01PM -0500, Caroline Arms wrote:
> We would certainly be interested in hearing from harvesters if our chunks
> are annoyingly small and if our short expiry times are causing problems.  
> We made implementation decisions for these based on no information and
> would be happy to reconsider based on real experience.

I don't have any hard evidence at present, but here are my initial
impressions (personal opinions! :-).

I have not yet experienced any problems with timeouts (that looked 
like problems with timeouts) - except one, where the data provider
told me that was what a problem was due to.

Different sites have used different chunk sizes. I think the smallest
was 5 records and the largest 7,500 records (the whole collection!).
Both worked. 100 to 200 seemed more common.

It terms of network bandwidth, since records tend to be 1k to 2k long
on average (with DC metadata anyway in my limited experience), 100
records forming a 100kb packet seems fine when connecting from here
in Australia over to all the other countries tried.

As a (play) harvester, I would rather not see packets get too big.
For the site with 7,500 records, that would have been around a single
7.5mb packet. This is starting to get on the large size in terms
of memory management etc.

The counter side however is that remotely, network delays are
substantial. That is, the length of time to do a round trip across
the globe is significant. To download a site with 5 records per
packet (5kb) for a very large site may never finish! Most time
would be spent waiting rather than transferring.

One thing that I think sometimes people forget is that there are
really two distinct phases to havesting. OAI is designed well
for the second phase of keeping up to date with metadata on the
site. 5 records per packet is probably fine for many sites because
the sites are pretty static. Only one or two packets per day are
probably needed. But the first phase is where you add a new site
to the list of sites you manage. At this time, you have to get
everything. OAI (in my opinion) does not do a very good job here
yet. Because the harvester does not know the date/time stamp 
distribution of data on the source site, it is hard to automatically
ask for multiple requests to get data from=X to=Y to get reasonable
chunk sites (for recovery purposes). Instead, I would rather a
harvester be able to say 'give me everything', but be given hints
to help with recovery in case things go wrong before finishing the
whole transfer. (Hence my suggested optional 'there is more coming,
but you have everything up to this date guaranteed in case you need
to start again with a network failure.)

So 100 to 1000 records per chunk seems like a good compromise to me,
even for static sites where only 1 or 2 updates are expected per
progressive update. I would not be daunted by 1000 records per packet
(if records are about 1kb) because 1mb is not really that much data
these days (others might disagree). Going beyond that I suspect the
overheads of multiple HTTP requests wont impact performance too much
so there is not much need to go bigger.

But others with more experience may have other suggestions. All this
sort of thing surely has been worked out before with protocols such
as FTP.

Alan

From liu_x@cs.odu.edu  Wed Feb 13 01:37:10 2002
From: liu_x@cs.odu.edu (Xiaoming Liu)
Date: Tue, 12 Feb 2002 20:37:10 -0500 (EST)
Subject: [OAI-implementers] Support for Tim Cole's comments
In-Reply-To: <20020213112903.B16742@io.mds.rmit.edu.au>
Message-ID: <Pine.SOL.4.10.10202122009430.14948-100000@defiant.cs.odu.edu>

On Wed, 13 Feb 2002, Alan Kent wrote:

> 
> So 100 to 1000 records per chunk seems like a good compromise to me,


From our experience in Arc I agree that 100~1000 records is good. ">>1000"
may bring about significant memory issues considering XML parsing
overhead.

I never noticed "time-out" problem, maybe because our harvester do a
continuous harvesting, or there is no special error code for timeout in
OAI-PMH? 

> everything. OAI (in my opinion) does not do a very good job here
> yet. Because the harvester does not know the date/time stamp
> distribution of data on the source site, it is hard to automatically
> ask for multiple requests to get data from=X to=Y to get reasonable
> chunk sites (for recovery purposes). Instead, I would rather a  
> harvester be able to say 'give me everything', but be given hints
> to help with recovery in case things go wrong before finishing the
> whole transfer. (Hence my suggested optional 'there is more coming,
> but you have everything up to this date guaranteed in case you need
> to start again with a network failure.)

I think resumptionToken is current OAI's answer to this problem.

In current implementation, whenever a network failure happends, the
harvester may restart from the last successful "resumptionToken", if it's
lucky and the "resumptionToken" is still valid, everything is fine.
Otherwise it may have to harvest everything again. Of course, the
harvester may choose to harvest by date/set, it certainly will save the
finished part.

And a data provider may keep a "resumptionToken" always valid by  encoding
queries like we discussed in previous emails.

liu 




From ajk@mds.rmit.edu.au  Wed Feb 13 03:20:31 2002
From: ajk@mds.rmit.edu.au (Alan Kent)
Date: Wed, 13 Feb 2002 14:20:31 +1100
Subject: [OAI-implementers] Resumption Token usage for recovery question
In-Reply-To: <Pine.SOL.4.10.10202122009430.14948-100000@defiant.cs.odu.edu>; from Xiaoming Liu on Tue, Feb 12, 2002 at 08:37:10PM -0500
References: <20020213112903.B16742@io.mds.rmit.edu.au> <Pine.SOL.4.10.10202122009430.14948-100000@defiant.cs.odu.edu>
Message-ID: <20020213142031.D16742@io.mds.rmit.edu.au>

On Tue, Feb 12, 2002 at 08:37:10PM -0500, Xiaoming Liu wrote:
> In current implementation, whenever a network failure happends, the
> harvester may restart from the last successful "resumptionToken", if it's
> lucky and the "resumptionToken" is still valid, everything is fine.
> Otherwise it may have to harvest everything again. Of course, the
> harvester may choose to harvest by date/set, it certainly will save the
> finished part.

Are resumptionTokens therefore guaranteed to be different for each
chunk? (I cannot find that in the spec). I thought OAI allowed a
server to reuse the same resumptionToken for an original request
and followup requests. That is, the resumption token could identify
an original request, but not which incomplete-list of records from
that request to return.

If OAI does not guarantee a distinct resumption token per request,
then its not safe to use them more than once. If a unique token is
guaranteed per request, then yes, I guess they could be used to
recover (if you attempt recovery immediately - before the expiry
on the token runs out).

Are resumptionToken's implicitly assumed to be different for each
incomplete-sublist of a complete-list?

Thanks,
Alan

From liu_x@cs.odu.edu  Wed Feb 13 04:09:50 2002
From: liu_x@cs.odu.edu (Xiaoming Liu)
Date: Tue, 12 Feb 2002 23:09:50 -0500 (EST)
Subject: [OAI-implementers] Resumption Token usage for recovery question
In-Reply-To: <20020213142031.D16742@io.mds.rmit.edu.au>
Message-ID: <Pine.SOL.4.10.10202122253250.15086-100000@defiant.cs.odu.edu>

On Wed, 13 Feb 2002, Alan Kent wrote:

> Are resumptionTokens therefore guaranteed to be different for each
> chunk? (I cannot find that in the spec). I thought OAI allowed a
> server to reuse the same resumptionToken for an original request
> and followup requests. That is, the resumption token could identify
> an original request, but not which incomplete-list of records from
> that request to return.

I guess this is an implementation issue, therefore it's not covered in the
OAI-PMH. A data provider may have a distinct resumption token per
request, or not. I have seen both implementations.

> 
> If OAI does not guarantee a distinct resumption token per request,
> then its not safe to use them more than once. If a unique token is
> guaranteed per request, then yes, I guess they could be used to
> recover (if you attempt recovery immediately - before the expiry
> on the token runs out).

At this point I think harvester must trust data providers will do the
right thing. If data provider feel it is unsafe, it will return a http
400, so harvester must restart the orignal request again.

For example, due to the network failure, the harvester may present same
resumptionToken twice, if harvester is OK with it (like stateless
implementation of resumptionToken), it will continue the remaining
records; otherwise it may return a http 400.

Regards,
liu




> 
> Are resumptionToken's implicitly assumed to be different for each
> incomplete-sublist of a complete-list?
> 
> Thanks,
> Alan
> _______________________________________________
> OAI-implementers mailing list
> OAI-implementers@oaisrv.nsdl.cornell.edu
> http://oaisrv.nsdl.cornell.edu/mailman/listinfo/oai-implementers
> 


From ajk@mds.rmit.edu.au  Wed Feb 13 04:17:01 2002
From: ajk@mds.rmit.edu.au (Alan Kent)
Date: Wed, 13 Feb 2002 15:17:01 +1100
Subject: [OAI-implementers] Queries and OAI
Message-ID: <20020213151701.F16742@io.mds.rmit.edu.au>

Hi. I was just reading through a DLib magazine article (Dec 2001), and
noticed an article talking about OAI and using set id's to put queries into.
The example was verb=ListIdentifiers&set=odlsearch1/computer%20science/1/10

Is there any general work being done on such things? Or is this just an
individual group's idea as to one way to do things?

I was just wondering what the intended scope of OAI was - just metadata
harvesting, or branching out into other areas such as searching too.

Alan

From tim@tim.brody.btinternet.co.uk  Wed Feb 13 12:43:24 2002
From: tim@tim.brody.btinternet.co.uk (Tim Brody)
Date: Wed, 13 Feb 2002 12:43:24 -0000
Subject: [OAI-implementers] OAI Aggregator
Message-ID: <003501c1b48c$06c46580$6400a8c0@Advocate>

Dear All,

Announcing the release of a beta OAI aggregating tool: OAIA

Based on PERL and MySQL, OAIA is a _very_ simple mechanism for providing
caching and aggregating of OAI repositories.

OAIA will be used as a back-end to DP9 to reduce the load on source
repositories generated by web crawlers, e.g. (with thanks to Xiaoming Liu):
http://arc.cs.odu.edu:8080/dp9/listidentifiers/mit

It may also be useful to repository administrators as a simple mechanism for
distributing load (or speeding-up OAI responses).

As ever, feedback, comments, flames are welcome!

Tim Brody

P.S. If anyone can think of a better name than "OAIA" it would be much
appreciated :-)


From mln@ils.unc.edu  Wed Feb 13 16:25:51 2002
From: mln@ils.unc.edu (Michael L. Nelson)
Date: Wed, 13 Feb 2002 11:25:51 -0500 (EST)
Subject: [OAI-implementers] Queries and OAI
In-Reply-To: <20020213151701.F16742@io.mds.rmit.edu.au>
Message-ID: <Pine.GSO.4.21.0202131107260.27417-100000@ruby.ils.unc.edu>

Hussein Suleman monitors this group, and its his research that the
article discusses
(http://www.dlib.org/dlib/december01/suleman/12suleman.html), but I'll
offer this response until he weighs in.

the example cited is most definitely an "extension" to OAI, and not part
of the core protocol.  in fact, OAI is designed to *not* be a distributed
search protocol, but with the wiggle room available in sets, you can make
it behave like a distributed search protocol (among other things) if you
really, really want.

what you should take home from your reading of their paper is that
communities can agree on many conventions within the OAI protocol
constructs that can result in extensions of functionality (without
breaking the SPs and DPs that are unaware of the extensions).

in addition to exploiting community standards in sets & metadata formats,
you can also imagine "reserved" ids for special records, conventions for
populating namespaces in ids, mirrors & aggregators, even conventions for
different OAI interfaces (e.g., biology.org/x/oai/ implies the existence
of biology.org/y/oai/), etc.

Hussein's paper describes some conventions that will be presumbably used
in the ETD project.  See also the linguistics community use of OAI in
larger framework of metadata interchange:

http://www.language-archives.org/docs.html

regards,

Michael

On Wed, 13 Feb 2002, Alan Kent wrote:

> Hi. I was just reading through a DLib magazine article (Dec 2001), and
> noticed an article talking about OAI and using set id's to put queries into.
> The example was verb=ListIdentifiers&set=odlsearch1/computer%20science/1/10
> 
> Is there any general work being done on such things? Or is this just an
> individual group's idea as to one way to do things?
> 
> I was just wondering what the intended scope of OAI was - just metadata
> harvesting, or branching out into other areas such as searching too.
> 
> Alan
> _______________________________________________
> OAI-implementers mailing list
> OAI-implementers@oaisrv.nsdl.cornell.edu
> http://oaisrv.nsdl.cornell.edu/mailman/listinfo/oai-implementers
> 

---
Michael L. Nelson
NASA Langley Research Center		m.l.nelson@larc.nasa.gov
MS 158, Hampton, VA 23681		http://www.ils.unc.edu/~mln/
+1 757 864 8511				+1 757 864 8342 (f)



From hussein@vt.edu  Wed Feb 13 16:52:18 2002
From: hussein@vt.edu (Hussein Suleman)
Date: Wed, 13 Feb 2002 11:52:18 -0500
Subject: [OAI-implementers] Queries and OAI
References: <Pine.GSO.4.21.0202131107260.27417-100000@ruby.ils.unc.edu>
Message-ID: <3C6A99C2.9040307@vt.edu>

hi

guess i should chip in my 2-cents' worth :)

firstly, as Michael explains, what i am working on falls strictly in the 
category of extensions. the ODL project is trying to evaluate:
- extensibility of the OAI protocol
- suitability of OAI-PMH and OAI-PMH extensions for inter-component 
communication in a componentized DL
- performance issues in networked OAI-PMH-based DLs

OAI-PMH is, and always should be, a protocol for incremental metadata 
transfer.

the whole point of our work is that a usable component model needs a 
baseline communications mechanism and some fundamental philosophies of 
design. if we can build on OAI, as something that is known, we have a 
better chance of success than if we design from scratch (etc ... read 
the paper for more :))

this is not really tied to the ETD project, though that is the first 
prototype i worked on ... the design philosophies, protocols and 
components are meant to be completely retargetable and that is being 
tested on an ongoing basis.

i will send out links, demo websites and even some downloadable software 
very soon (maybe later today). stay tuned for more details :)

ttfn
----hussein

Michael L. Nelson wrote:

> Hussein Suleman monitors this group, and its his research that the
> article discusses
> (http://www.dlib.org/dlib/december01/suleman/12suleman.html), but I'll
> offer this response until he weighs in.
> 
> the example cited is most definitely an "extension" to OAI, and not part
> of the core protocol.  in fact, OAI is designed to *not* be a distributed
> search protocol, but with the wiggle room available in sets, you can make
> it behave like a distributed search protocol (among other things) if you
> really, really want.
> 
> what you should take home from your reading of their paper is that
> communities can agree on many conventions within the OAI protocol
> constructs that can result in extensions of functionality (without
> breaking the SPs and DPs that are unaware of the extensions).
> 
> in addition to exploiting community standards in sets & metadata formats,
> you can also imagine "reserved" ids for special records, conventions for
> populating namespaces in ids, mirrors & aggregators, even conventions for
> different OAI interfaces (e.g., biology.org/x/oai/ implies the existence
> of biology.org/y/oai/), etc.
> 
> Hussein's paper describes some conventions that will be presumbably used
> in the ETD project.  See also the linguistics community use of OAI in
> larger framework of metadata interchange:
> 
> http://www.language-archives.org/docs.html
> 
> regards,
> 
> Michael
> 
> On Wed, 13 Feb 2002, Alan Kent wrote:
> 
> 
>>Hi. I was just reading through a DLib magazine article (Dec 2001), and
>>noticed an article talking about OAI and using set id's to put queries into.
>>The example was verb=ListIdentifiers&set=odlsearch1/computer%20science/1/10
>>
>>Is there any general work being done on such things? Or is this just an
>>individual group's idea as to one way to do things?
>>
>>I was just wondering what the intended scope of OAI was - just metadata
>>harvesting, or branching out into other areas such as searching too.
>>
>>Alan
>>_______________________________________________
>>OAI-implementers mailing list
>>OAI-implementers@oaisrv.nsdl.cornell.edu
>>http://oaisrv.nsdl.cornell.edu/mailman/listinfo/oai-implementers
>>
>>
> 
> ---
> Michael L. Nelson
> NASA Langley Research Center		m.l.nelson@larc.nasa.gov
> MS 158, Hampton, VA 23681		http://www.ils.unc.edu/~mln/
> +1 757 864 8511				+1 757 864 8342 (f)
> 
> 
> _______________________________________________
> OAI-implementers mailing list
> OAI-implementers@oaisrv.nsdl.cornell.edu
> http://oaisrv.nsdl.cornell.edu/mailman/listinfo/oai-implementers
> 


-- 
======================================================================
hussein suleman - hussein@vt.edu - vtcs - http://www.husseinsspace.com
======================================================================


From tim@tim.brody.btinternet.co.uk  Wed Feb 13 17:05:50 2002
From: tim@tim.brody.btinternet.co.uk (Tim Brody)
Date: Wed, 13 Feb 2002 17:05:50 -0000
Subject: [OAI-implementers] OAI Aggregator
References: <003501c1b48c$06c46580$6400a8c0@Advocate>
Message-ID: <001b01c1b4b0$b1246240$6400a8c0@Advocate>

Just noticed the fundamental flaw with my announcement:
OAIA (or whatever) downloadable from
http://sourceforge.net/project/showfiles.php?group_id=21275

All the best,
Tim.

----- Original Message -----
From: "Tim Brody" <tim@tim.brody.btinternet.co.uk>
To: <oai-implementers@oaisrv.nsdl.cornell.edu>
Cc: "Xiaoming Liu" <liu_x@cs.odu.edu>
Sent: Wednesday, February 13, 2002 12:43 PM
Subject: [OAI-implementers] OAI Aggregator


> Dear All,
>
> Announcing the release of a beta OAI aggregating tool: OAIA
>
> Based on PERL and MySQL, OAIA is a _very_ simple mechanism for providing
> caching and aggregating of OAI repositories.
>
> OAIA will be used as a back-end to DP9 to reduce the load on source
> repositories generated by web crawlers, e.g. (with thanks to Xiaoming
Liu):
> http://arc.cs.odu.edu:8080/dp9/listidentifiers/mit
>
> It may also be useful to repository administrators as a simple mechanism
for
> distributing load (or speeding-up OAI responses).
>
> As ever, feedback, comments, flames are welcome!
>
> Tim Brody
>
> P.S. If anyone can think of a better name than "OAIA" it would be much
> appreciated :-)
>
> _______________________________________________
> OAI-implementers mailing list
> OAI-implementers@oaisrv.nsdl.cornell.edu
> http://oaisrv.nsdl.cornell.edu/mailman/listinfo/oai-implementers


From liu_x@cs.odu.edu  Wed Feb 13 17:26:53 2002
From: liu_x@cs.odu.edu (Xiaoming Liu)
Date: Wed, 13 Feb 2002 12:26:53 -0500 (EST)
Subject: [OAI-implementers] Queries and OAI
In-Reply-To: <Pine.GSO.4.21.0202131107260.27417-100000@ruby.ils.unc.edu>
Message-ID: <Pine.SOL.4.10.10202131224220.15469-100000@defiant.cs.odu.edu>

Hi,

There are some similar efforts by Martin Vesely in CERN, it's discussed in 

http://www.openarchives.org/pipermail/oai-general/2002-January/000128.html
http://documents.cern.ch/ettdh/doc/public/OAIRSF.html 

Regards,
liu


On Wed, 13 Feb 2002, Michael L. Nelson wrote:

> 
> Hussein Suleman monitors this group, and its his research that the
> article discusses
> (http://www.dlib.org/dlib/december01/suleman/12suleman.html), but I'll
> offer this response until he weighs in.
> 
> the example cited is most definitely an "extension" to OAI, and not part
> of the core protocol.  in fact, OAI is designed to *not* be a distributed
> search protocol, but with the wiggle room available in sets, you can make
> it behave like a distributed search protocol (among other things) if you
> really, really want.
> 
> what you should take home from your reading of their paper is that
> communities can agree on many conventions within the OAI protocol
> constructs that can result in extensions of functionality (without
> breaking the SPs and DPs that are unaware of the extensions).
> 
> in addition to exploiting community standards in sets & metadata formats,
> you can also imagine "reserved" ids for special records, conventions for
> populating namespaces in ids, mirrors & aggregators, even conventions for
> different OAI interfaces (e.g., biology.org/x/oai/ implies the existence
> of biology.org/y/oai/), etc.
> 
> Hussein's paper describes some conventions that will be presumbably used
> in the ETD project.  See also the linguistics community use of OAI in
> larger framework of metadata interchange:
> 
> http://www.language-archives.org/docs.html
> 
> regards,
> 
> Michael
> 
> On Wed, 13 Feb 2002, Alan Kent wrote:
> 
> > Hi. I was just reading through a DLib magazine article (Dec 2001), and
> > noticed an article talking about OAI and using set id's to put queries into.
> > The example was verb=ListIdentifiers&set=odlsearch1/computer%20science/1/10
> > 
> > Is there any general work being done on such things? Or is this just an
> > individual group's idea as to one way to do things?
> > 
> > I was just wondering what the intended scope of OAI was - just metadata
> > harvesting, or branching out into other areas such as searching too.
> > 
> > Alan
> > _______________________________________________
> > OAI-implementers mailing list
> > OAI-implementers@oaisrv.nsdl.cornell.edu
> > http://oaisrv.nsdl.cornell.edu/mailman/listinfo/oai-implementers
> > 
> 
> ---
> Michael L. Nelson
> NASA Langley Research Center		m.l.nelson@larc.nasa.gov
> MS 158, Hampton, VA 23681		http://www.ils.unc.edu/~mln/
> +1 757 864 8511				+1 757 864 8342 (f)
> 
> 
> _______________________________________________
> OAI-implementers mailing list
> OAI-implementers@oaisrv.nsdl.cornell.edu
> http://oaisrv.nsdl.cornell.edu/mailman/listinfo/oai-implementers
> 


From support@eprints.org  Wed Feb 13 20:42:17 2002
From: support@eprints.org (ePrints Support)
Date: Wed, 13 Feb 2002 20:42:17 +0000
Subject: [OAI-implementers] We should have a "tick" logo.
Message-ID: <20020213204217.GA12670@ecs.soton.ac.uk>

--+QahgC5+KEYLbs62
Content-Type: text/plain; charset=us-ascii
Content-Disposition: inline

When people have succesfully validated on Hussein's 
validator it would be neat if it told them they could 
use a "OAI1.1 Compliant" icon, like CSS, HTML4.01 etc
from W3C.

Something like... (see attached gif)
-- 

 Christopher Gutteridge                   support@eprints.org 
 ePrints Developer                        +44 23 8059 4833


--+QahgC5+KEYLbs62
Content-Type: image/gif
Content-Disposition: attachment; filename="OAI11.gif"
Content-Transfer-Encoding: base64
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--+QahgC5+KEYLbs62--

From hussein@vt.edu  Wed Feb 13 20:51:22 2002
From: hussein@vt.edu (Hussein Suleman)
Date: Wed, 13 Feb 2002 15:51:22 -0500
Subject: [OAI-implementers] We should have a "tick" logo.
References: <20020213204217.GA12670@ecs.soton.ac.uk>
Message-ID: <3C6AD1CA.9070103@vt.edu>

hi

actually, it should be validation at the official site that counts - 
though the idea is good in principle.

ttfn
----hussein

ePrints Support wrote:

> When people have succesfully validated on Hussein's 
> validator it would be neat if it told them they could 
> use a "OAI1.1 Compliant" icon, like CSS, HTML4.01 etc
> from W3C.
> 
> Something like... (see attached gif)
> 
> 
> ------------------------------------------------------------------------
> 


-- 
======================================================================
hussein suleman - hussein@vt.edu - vtcs - http://www.husseinsspace.com
======================================================================


From ajk@mds.rmit.edu.au  Wed Feb 13 23:21:49 2002
From: ajk@mds.rmit.edu.au (Alan Kent)
Date: Thu, 14 Feb 2002 10:21:49 +1100
Subject: [OAI-implementers] OAI Aggregator
In-Reply-To: <003501c1b48c$06c46580$6400a8c0@Advocate>; from Tim Brody on Wed, Feb 13, 2002 at 12:43:24PM -0000
References: <003501c1b48c$06c46580$6400a8c0@Advocate>
Message-ID: <20020214102148.A5577@io.mds.rmit.edu.au>

On Wed, Feb 13, 2002 at 12:43:24PM -0000, Tim Brody wrote:
> Dear All,
> 
> Announcing the release of a beta OAI aggregating tool: OAIA
> 
> Based on PERL and MySQL, OAIA is a _very_ simple mechanism for providing
> caching and aggregating of OAI repositories.

Having read the article http://documents.cern.ch/ettdh/doc/public/OAIRSF.html
which talks about hierarchical harvesting, is the idea then for this
package to collect data from multiple data providers, then provide the
data to multiple service providers?

If this is the case, should more work be done in terms of mapping out
the relationship between different OAI repositories and copies? As
a new person to this list, I just looked at the list of available sites
and said "great, I will crawl them all!". But a recent mail I got
indicated that one of the repositories was a copy (or included all
of) another repository. This would seem to occur even more often with
OAIA-like packages becoming available.

There are several possible strategies I could think of quickly (I am
sure others have been thinking longer about it):

(1) Improve the sophistication of the global XML document listing
    various OAI repositories, showing how they inter-relate.

(2) Extend the XML of the Identify return to (optionally) include
    details such as 'I have local data', and 'I also have data
    crawled from this other site using this query (set name)'.
    The default assumption would be its local data.

Putting it into the Identify command would avoid registration complexity.



Hmmm, serious question time!

Does the aggregator keep the original identifiers for metadata (or
assign new local identifiers)? Does an instance of OAIA get registered
as a new repository? Would this imply a site can return metadata with
an identifier from a different site? Would this in turn mean that
harvesters need to be careful - if they harvest from 2 OAIA sites,
which both harvest from the same original site, where one OAIA site
more up to date than the other then you may get old metadata back.
This means a harvester can no longer blindly (like mine! :-) crawl
sites and rely on the sites returning data in an appropriate order.
The harvester must compare the date on the retrieved record to the
date on the local cached copy of the record to make sure the data
(or delete request!!) is more up to date than the local data.

Maybe I should be doing this anyway. Since lists are not ordered,
and I cannot remember any guarantee that a list may not contain
two updates to the same record. Makes deletes a bit more tricky too.
Its not safe just to delete the local copy. I really need to cache
the delete notification to be able to compare date/time stamps.

All very interesting.

Alan

From tim@tim.brody.btinternet.co.uk  Thu Feb 14 12:55:35 2002
From: tim@tim.brody.btinternet.co.uk (Tim Brody)
Date: Thu, 14 Feb 2002 12:55:35 -0000
Subject: [OAI-implementers] OAI Aggregator
References: <003501c1b48c$06c46580$6400a8c0@Advocate> <20020214102148.A5577@io.mds.rmit.edu.au>
Message-ID: <007601c1b556$e4b7a4e0$14414e98@Shrek>

Apologies for long email ...

----- Original Message -----
From: "Alan Kent" <ajk@mds.rmit.edu.au>
To: "Tim Brody" <tim@tim.brody.btinternet.co.uk>; "OAI Implementors"
<oai-implementers@oaisrv.nsdl.cornell.edu>
Sent: Wednesday, February 13, 2002 11:21 PM
Subject: Re: [OAI-implementers] OAI Aggregator


> On Wed, Feb 13, 2002 at 12:43:24PM -0000, Tim Brody wrote:
>
> > Announcing the release of a beta OAI aggregating tool: OAIA
> >
> > Based on PERL and MySQL, OAIA is a _very_ simple mechanism for providing
> > caching and aggregating of OAI repositories.
>
> Having read the article
http://documents.cern.ch/ettdh/doc/public/OAIRSF.html
> which talks about hierarchical harvesting, is the idea then for this
> package to collect data from multiple data providers, then provide the
> data to multiple service providers?

It could do, yes.

The reason for writing OAIA was to alleviate the problem of DP9 overloading
data providers (which is especially troublesome because it is based on
GetRecord, rather than ListRecords requests).

OAIA could also be used to build unified community, or perhaps geographical,
specific collections. This alleviates the maintenance problems that global
SPs will have, as they will only need to harvest half a dozen DPs, compared
to potentially 1000s.

> If this is the case, should more work be done in terms of mapping out
> the relationship between different OAI repositories and copies? As
> a new person to this list, I just looked at the list of available sites
> and said "great, I will crawl them all!". But a recent mail I got
> indicated that one of the repositories was a copy (or included all
> of) another repository. This would seem to occur even more often with
> OAIA-like packages becoming available.

I don't see there being a big problem with harvesting the same records from
multiple sources, as long as:
a) Datestamps are always updated to the day of harvest, or the day the
record was changed
b) Harvesters are discerning about what they harvest

(I have built an OAI export for web-logs but would you want to harvest it,
even if it is original?)

> (1) Improve the sophistication of the global XML document listing
>     various OAI repositories, showing how they inter-relate.

Sounds too complex. OAI should (eventually) cluster around communities,
which will solve this problem to a large extent. At the moment the coverage
is too fragmented to become self-organising - with the notable exception of
OLAC.

> (2) Extend the XML of the Identify return to (optionally) include
>     details such as 'I have local data', and 'I also have data
>     crawled from this other site using this query (set name)'.
>     The default assumption would be its local data.
>
> Putting it into the Identify command would avoid registration complexity.

Done (kind of):
http://citebase.eprints.org/cgi-bin/oai?verb=Identify

> Does the aggregator keep the original identifiers for metadata?

Yes. So you could compare the repositoryName (as returned by Identify) to
the record identifiers its returning, to work out which records are local,
and which re-exported.

> Does an instance of OAIA get registered as a new repository?

It could do (of existing aggregators citebase is, arc isn't - but then
citebase is also a hidden-augmentor ...).

> Would this imply a site can return metadata with
> an identifier from a different site? Would this in turn mean that
> harvesters need to be careful - if they harvest from 2 OAIA sites,
> which both harvest from the same original site, where one OAIA site
> more up to date than the other then you may get old metadata back.

Assuming above caveat a) is adherred to, you should just compare datestamps
and take the newer one. Things get complex if one aggregator is changing the
metadata, while another one isn't - an issue that the technical folks in OAI
2.0 were thinking about. The idea was proposed that the identifier be
changed if a harvester alters the metadata, then re-exports - then the
problem is how to resolve multiple near-duplicate records.

> Makes deletes a bit more tricky too.
> Its not safe just to delete the local copy. I really need to cache
> the delete notification to be able to compare date/time stamps.

I don't treat a status=deleted as an order to delete the record. arXiv.org
and EPrints.org both treat a deletion as a flag, so that should a user come
across a deleted record they don't get a 404, but a notification that what
they were looking for has been withdrawn, and why.
If you store the deletion as a metadata field, it will be handled by the
same datestamp test as the rest of the metadata.

All the best,
Tim.


From simeon@cs.cornell.edu  Thu Feb 14 15:20:04 2002
From: simeon@cs.cornell.edu (Simeon Warner)
Date: Thu, 14 Feb 2002 10:20:04 -0500 (EST)
Subject: FW: [OAI-implementers] Open Archives Initiative Protocol for
 Meta data Harvesting Version 2 news
In-Reply-To: <Pine.SOL.4.10.10202080722430.12226-100000@defiant.cs.odu.edu>
Message-ID: <Pine.LNX.4.44.0202141016220.6973-100000@ice.cs.cornell.edu>

On Fri, 8 Feb 2002, Xiaoming Liu wrote:
> Because the datastamp is always increasing in OAI, I think  Alan's
> method (high resolution date stamps and results is ordered by
> time) will also work, but not necessarily monatomically, if the DP could
> return all records of a specific datestamp in one reply. But it did
> put some dangers to harvester as Walter suggested, if suddenly DP creates
> 10K records with same datestamp, it has to return them in one response, it
> quite possibly will break the harvester.

This is pretty much the solution I adopted for arXiv. The resumptionToken 
is essentially a query to resume the list and where possible this follows
day granularity. However, we have a few days with large numbers of updates
(migrations) so to cope with this I add an index within the day.
--
Simeon


From simeon@cs.cornell.edu  Thu Feb 14 15:38:23 2002
From: simeon@cs.cornell.edu (Simeon Warner)
Date: Thu, 14 Feb 2002 10:38:23 -0500 (EST)
Subject: [OAI-implementers] Resumption 'from' date.
In-Reply-To: <Pine.SOL.4.10.10202102100510.13729-100000@defiant.cs.odu.edu>
Message-ID: <Pine.LNX.4.44.0202141025320.6973-100000@ice.cs.cornell.edu>

This sounds like a best-practice rather than something that should be
mandated. Perhaps the suggestion should be:

"Repositories are encouraged to implement persistent resumptionTokens
that can be re-used in the event that one a request is not successfully
completed. One way for repositories to do this is to use the 
resumptionToken in a way that it encodes the next query in a set of 
queries that will complete the original List request.

On failing to complete a request using a resumptionToken, a harvester may 
re-issue the request using the same resumptionToken. If the repository 
supports this use then it will give the correct response. Otherwise it 
will respond with an badResumptionToken error, in which case the 
harvester must start the complete List request again." 

--
Simeon

On Sun, 10 Feb 2002, Xiaoming Liu wrote:
> On Mon, 11 Feb 2002, Alan Kent wrote:
> 
> > If a goal of OAI is to keep it simple and not change radically (which
> > I can appreciate), then I would revert to my simpler proposed extension
> 
> Based on previous discussions in this list, I think there is one way to
> implement a consistent/stateless view (from the harvester) without
> modifying protocol.
> 
> The suggested way is to encode the resumptionToken with the query
> parameter, at the same time data provider always uses datestamp to sort
> the query result.
> 
> The format should be almost same as I suggested before, but the cursor
> will be the current processed datestamp (borrowed from your solution).
> likely:
> 
> resumptionToken=sets:from:until:metadataformat:processed_datestamp.
> 
> The resumptionToken is transparent to service provider, but when data
> provider sees this resumptionToken, it will re-create the query, and use
> this "processed_datestamp" as a "from" date.
> 
> And whether to implement such a mechanism is totally depended on the data
> provider, a large /frequently changed data provider may want to use such a
> mechanism to support a consistent view to harvester. 
> 
> regards,
> liu
> 
> 
> > which is to allow a server to return an optional addtional date/time in
> > ListRecords/ListIdentifiers responses indicating that "the client can
> > use this as a 'from' date to resume if the response token times out".
> > 
> > For the very simple implementations (or small data volume sites), the
> > server just omits this value.
> > 
> > For more sophisticated implementations with a database engine behind
> > the scenes (for example, so it can easly sort the records), then for
> > each packet it can say "I am guaranteeing to at least have returned
> > everything up to this date". This allows a harvester client hitting a
> > large site for a first time to not have to start again from scratch if
> > something goes wrong (resumption token time out etc). Date resolution
> > is fine here (getting some entries a second time is not the problem -
> > the problem is starting again from the very beginning).
> > 
> > My first attempt at a client harvester for example took about a day to
> > go to several sites and download everything. It hung several times
> > (unknown network issues), meaning I had to restart it on some large
> > sites from scratch. Many other sites it failed for (I can post a list
> > if people are interested - many seemed to only support GET and not POST).
> > 
> > Alan
> > _______________________________________________
> > OAI-implementers mailing list
> > OAI-implementers@oaisrv.nsdl.cornell.edu
> > http://oaisrv.nsdl.cornell.edu/mailman/listinfo/oai-implementers
> > 
> 
> _______________________________________________
> OAI-implementers mailing list
> OAI-implementers@oaisrv.nsdl.cornell.edu
> http://oaisrv.nsdl.cornell.edu/mailman/listinfo/oai-implementers
> 


From ajk@mds.rmit.edu.au  Fri Feb 15 00:13:59 2002
From: ajk@mds.rmit.edu.au (Alan Kent)
Date: Fri, 15 Feb 2002 11:13:59 +1100
Subject: [OAI-implementers] Resumption 'from' date.
In-Reply-To: <Pine.LNX.4.44.0202141025320.6973-100000@ice.cs.cornell.edu>; from Simeon Warner on Thu, Feb 14, 2002 at 10:38:23AM -0500
References: <Pine.SOL.4.10.10202102100510.13729-100000@defiant.cs.odu.edu> <Pine.LNX.4.44.0202141025320.6973-100000@ice.cs.cornell.edu>
Message-ID: <20020215111359.C27694@io.mds.rmit.edu.au>

On Thu, Feb 14, 2002 at 10:38:23AM -0500, Simeon Warner wrote:
> 
> This sounds like a best-practice rather than something that should be
> mandated. Perhaps the suggestion should be:
> 
> "Repositories are encouraged to implement persistent resumptionTokens
> that can be re-used in the event that one a request is not successfully
> completed. One way for repositories to do this is to use the 
> resumptionToken in a way that it encodes the next query in a set of 
> queries that will complete the original List request.
> 
> On failing to complete a request using a resumptionToken, a harvester may 
> re-issue the request using the same resumptionToken. If the repository 
> supports this use then it will give the correct response. Otherwise it 
> will respond with an badResumptionToken error, in which case the 
> harvester must start the complete List request again." 

The only thing to watch out for is that for this to work, there is
also an implicit 'resumptionTokens must never reused' (that is,
they are unique and change per request). Otherwise if a
harvester reuses a token, it wont know if the response is the last
batch again, or the next batch. Is this an acceptable restriction?
I would have thought it would be undesirable. I can imagine a simple
OAI data provider using the resumption token to identify a cached query
that results are being pulled from. There would be no need to change
token. Mind you, just as easily I guess that implementation could put
a count on the end of the token (1, 2, 3) making each token unique
fairly easily. So I am unsure whether the restriction is acceptable
in general or not (people seem strongly in favour of not adding
restrictions, which is fair enough).

Maybe a mix of your proposal plus some information in the Identify response
which indicates that resumptionToken's can be used in this way. In that
case, the proposed text could be simpler - if the server says it supports
unique tokens and for tokens to be reused (unless they time out), then
the harvester can attempt to recover. Otherwise, start again. Then there
does not need to be a new error condition (other than what servers already
implement if unknown or timed out resumptionTOkens are used).

Alan

From ldodds@ingenta.com  Mon Feb 18 17:25:44 2002
From: ldodds@ingenta.com (Leigh Dodds)
Date: Mon, 18 Feb 2002 17:25:44 -0000
Subject: [OAI-implementers] Validating ListMetadataFormats
In-Reply-To: <200202081524.g18FOuG14131@unagi.cis.upenn.edu>
Message-ID: <NCBBKFMJCLIMOBIGKFMJCEHCHDAA.ldodds@ingenta.com>

> Of course it is trivial to write a program to do the test, but I was hoping
> to find a fully declarative solution, so that our formal requirements
> [http://www.language-archives.org/OLAC/protocol.html] can be accompanied by
> one or more XML documents which more or less transparently implement them.
> 
> I would be grateful for any advice about how to test for set membership
> using an XML validation language.

You should take a look at Schematron [1] which is an validation language 
implemented using XSLT. I presented a paper at XSLT-UK provides 
some addtional background [2]. 

Schematron provides the kinds of constraints checking that you require, 
and can be used in conjunction with other schema languages. For 
example the topologi schema tool [3] is capable of taking a W3C XML 
Schema which contains embedded Schematron rules and applying 
both sets of constraints.

Let me know if you need any help.

Cheers,

L.

[1]. http://www.ascc.net/xml/resource/schematron/schematron.html
[2]. http://www.bath.ac.uk/~ccslrd/papers/schematron_xsltuk.html
[3]. http://www.topologi.com


-- 
Leigh Dodds, Research Group, Ingenta | "Pluralitas non est ponenda
http://weblogs.userland.com/eclectic |    sine necessitate"
http://www.xml.com/pub/xmldeviant    |     -- William of Ockham

From ldodds@ingenta.com  Mon Feb 18 17:35:59 2002
From: ldodds@ingenta.com (Leigh Dodds)
Date: Mon, 18 Feb 2002 17:35:59 -0000
Subject: [OAI-implementers] Registered Data Providers
Message-ID: <NCBBKFMJCLIMOBIGKFMJMEHCHDAA.ldodds@ingenta.com>

Is the list of registered data providers given at [1] 
the most definitive list of OAI repositories available? (I assume 
so, but am just checking).

It would also be useful for the XML version of this list [2] to 
include the repository names as well as the id and Base-URL.

Cheers,

L.

[1]. http://www.openarchives.org/Register/BrowseSites.pl
[2]. http://www.openarchives.org/Register/ListFriends.pl


-- 
Leigh Dodds, Research Group, Ingenta | "Pluralitas non est ponenda
http://weblogs.userland.com/eclectic |    sine necessitate"
http://www.xml.com/pub/xmldeviant    |     -- William of Ockham

From bergmark@CS.Cornell.EDU  Mon Feb 18 17:55:01 2002
From: bergmark@CS.Cornell.EDU (Donna Bergmark)
Date: Mon, 18 Feb 2002 12:55:01 -0500
Subject: [OAI-implementers] Registered Data Providers
Message-ID: <200202181755.g1IHt1P26067@elgin.cs.cornell.edu>

Hi, Leigh -

BrowseSites lists only those repositories who registered themselves
with the Open Archives Initiative and passed the validation test.
We think that there are many, many OAI archives out there who for
one reason or another did not register.  I doubt that there is a
definitive list anywhere.

Some organizations use OAI for their own internal purposes and so
would not be likely to register.

About the second question, whether the ListFriends.pl script should
also include the repository name -- is there demand out there for
that?  It seems that one could just harvest information like that.

Donna Bergmark


From tim@tim.brody.btinternet.co.uk  Mon Feb 18 21:39:01 2002
From: tim@tim.brody.btinternet.co.uk (Tim Brody)
Date: Mon, 18 Feb 2002 21:39:01 -0000
Subject: [OAI-implementers] Registered Data Providers
References: <NCBBKFMJCLIMOBIGKFMJMEHCHDAA.ldodds@ingenta.com>
Message-ID: <001f01c1b8c4$aeda7de0$6400a8c0@Advocate>

I believe harvesters also lift the list of repositories stored in Hussein's
OAI repository tool (linked from the OA tools page), although it would be a
good idea to check with their admins before harvesting!

All the best,
Tim.

----- Original Message -----
From: "Leigh Dodds" <ldodds@ingenta.com>
To: "OAI Implementors" <oai-implementers@oaisrv.nsdl.cornell.edu>
Sent: Monday, February 18, 2002 5:35 PM
Subject: [OAI-implementers] Registered Data Providers


> Is the list of registered data providers given at [1]
> the most definitive list of OAI repositories available? (I assume
> so, but am just checking).
>
> It would also be useful for the XML version of this list [2] to
> include the repository names as well as the id and Base-URL.
>
> Cheers,
>
> L.
>
> [1]. http://www.openarchives.org/Register/BrowseSites.pl
> [2]. http://www.openarchives.org/Register/ListFriends.pl
>
>
> --
> Leigh Dodds, Research Group, Ingenta | "Pluralitas non est ponenda
> http://weblogs.userland.com/eclectic |    sine necessitate"
> http://www.xml.com/pub/xmldeviant    |     -- William of Ockham
> _______________________________________________
> OAI-implementers mailing list
> OAI-implementers@oaisrv.nsdl.cornell.edu
> http://oaisrv.nsdl.cornell.edu/mailman/listinfo/oai-implementers


From hussein@vt.edu  Tue Feb 19 05:15:59 2002
From: hussein@vt.edu (Hussein Suleman)
Date: Tue, 19 Feb 2002 00:15:59 -0500
Subject: [OAI-implementers] Open Digital Libraries (ODL)
Message-ID: <3C71DF8F.1000001@vt.edu>

Announcement: Open Digital Libraries Project

The creation of Open Digital Libraries (ODLs) is the aim of a research 
project at Virginia Tech, investigating the building of digital 
libraries as networks of independent components, with inter-component 
communication based on the OAI Protocol for Metadata Harvesting and 
extensions thereof.

More documentation, online demonstrations and prototype components can 
be found on the project website at:
    http://oai.dlib.vt.edu/odl/

The current suite of tools available for experimentation include:
  - Harvest, a Perl-based OAI/ODL harvester module
  - DBUnion, to perform aggregation of OAI/ODL archives
  - IRDB, search engine over an arbitrary OAI/ODL archive
  - sample user interface to the IRDB search engine
(Additional components are under development to provide other typical DL 
services such as submission and browsing.)

Common features of the current component suite includes:
  - simplicity: minimal number of external dependencies and no makefiles
  - object-oriented Perl to support extensibility
  - XML Schema for all configuration information
  - single installation, multiple instance model
  - configure.pl to create instances and set/edit parameters

For comments, suggestions, or questions, please email hussein@vt.edu

-- 
=======================================================================
hussein suleman -- hussein@vt.edu - vtcs - http://www.husseinsspace.com
=======================================================================


From tim@tim.brody.btinternet.co.uk  Tue Feb 19 12:04:13 2002
From: tim@tim.brody.btinternet.co.uk (Tim Brody)
Date: Tue, 19 Feb 2002 12:04:13 -0000
Subject: [OAI-implementers] OAI Identifiers
Message-ID: <00d701c1b93d$8be5a070$14414e98@Shrek>

Hi,

A thought on OAI identifiers, at the moment the "repository" bit of
identifiers is somewhat arbitrary, and could quite easily lead to conflicts.
How about using the repository URL (or partial URL) to make up the
identifier, e.g.:
arXiv.org => oai:org:arXiv:sub-arxiv/xxx
CogPrints => oai:uk:ac:soton:cogprints/xxx

Which also makes the identifiers a little more informative?
(especially for institutional archives which might be
oai:country:ac:institution:server:paperid)

All the best,
Tim.


From simeon@cs.cornell.edu  Tue Feb 19 15:45:58 2002
From: simeon@cs.cornell.edu (Simeon Warner)
Date: Tue, 19 Feb 2002 10:45:58 -0500 (EST)
Subject: [OAI-implementers] OAI Identifiers
In-Reply-To: <00d701c1b93d$8be5a070$14414e98@Shrek>
Message-ID: <Pine.LNX.4.44.0202191037450.23996-100000@ice.cs.cornell.edu>

If I recall, when the oai identifier scheme was proposed it was felt that
benefit of a layer of abstract permitting persisitence of ids even if URLs
change outweighed the possible registration difficulties. Note that the
schema says:
    <!-- * A "repositoryIdentifier" that is a unique identifier for a -->
    <!-- repository.  Its uniqueness will be tested as part of a -->
    <!-- registration process.  The repositoryIdentifier is case -->
    <!-- sensitive and may contain the characters [a-z]|[A-Z]|[0-9] -->
    <!-- e.g. arXiv, VTETD. -->

Note also that OAI-PMH does not mandate this scheme and not all registered
repositories have chosen to use it.

Cheers,
Simeon

On Tue, 19 Feb 2002, Tim Brody wrote:
> A thought on OAI identifiers, at the moment the "repository" bit of
> identifiers is somewhat arbitrary, and could quite easily lead to conflicts.
> How about using the repository URL (or partial URL) to make up the
> identifier, e.g.:
> arXiv.org => oai:org:arXiv:sub-arxiv/xxx
> CogPrints => oai:uk:ac:soton:cogprints/xxx
> 
> Which also makes the identifiers a little more informative?
> (especially for institutional archives which might be
> oai:country:ac:institution:server:paperid)
> 
> All the best,
> Tim.


From Steven Bird <sb@ldc.upenn.edu>  Wed Feb 20 21:32:41 2002
From: Steven Bird <sb@ldc.upenn.edu> (Steven Bird)
Date: Wed, 20 Feb 2002 16:32:41 EST
Subject: [OAI-implementers] Validating ListMetadataFormats
In-Reply-To: Your mail dated Monday 18 February, 2002.
Message-ID: <200202202132.g1KLWfG28016@unagi.cis.upenn.edu>

I wrote:

> I would like to use an XML validation language (e.g. XML Schema) to test
> that the document returned by ListMetadataFormats includes a specific
> format.  The return typically lists multiple formats, and I just want to
> check that the list includes one specific format, e.g.:
>
> <ListMetadataFormats>
>   ...
>   <metadataFormat>
>     <metadataPrefix>olac</metadataPrefix>
>     <schema>http://www.language-archives.org/OLAC/0.4/olac.xsd</schema>
>     <metadataNamespace>http://www.language-archives.org/OLAC/0.4/</metadataNamespace>
>   </metadataFormat>
>   ...
> </ListMetadataFormats>
> 
> The ListMetadataFormats container is supposed to have set semantics.  I
> guess I need a set-membership test, and it also needs to work on element
> content (not just element names, attribute names, or attribute values).


Leigh Dodds replied:
> You should take a look at Schematron [1] which is an validation language
> implemented using XSLT.  ... Schematron provides the kinds of constraints
> checking that you require ...


Actually, I don't believe that it possible to implement a set-membership
test using schematron.  As I understand it, schematron only lets you assert
implication relations between xpath expressions.

Here is a simpler statement of the problem.  Check that one of the
elements in the following list is OLAC (two versions):

<set>
  <elt>a</elt>
  <elt>b</elt>
  <elt>c</elt>
  <elt>olac</elt>
  <elt>d</elt>
</set>

<set>
  <elt><a/></elt>
  <elt><b/></elt>
  <elt><c/></elt>
  <elt><olac/></elt>
  <elt><d/></elt>
</set>

The schematron rule context is just "/set", and the assertion (which cannot
be expressed in schematron) is that one of the <elt> elements contains
"olac" or <olac/>.

All of the other OLAC requirements can be checked with schematron, and
here is the schematron code I wrote a couple of weeks ago:
[http://www.ldc.upenn.edu/sb/schematron/olac-pmh.xml]

Thus, I think we are left writing programs to validate the response to the
Identify and ListMetadataFormats requests.  I'd be glad to be proven wrong,
so please let me know if schematron or some other XML validation language
can do a set-membership test.

Thanks,
Steven Bird

--
Steven.Bird@ldc.upenn.edu  http://www.ldc.upenn.edu/sb
Assoc Director, LDC; Adj Assoc Prof, CIS & Linguistics
Linguistic Data Consortium, University of Pennsylvania
3615 Market St, Suite 200, Philadelphia, PA 19104-2608






From ajk@mds.rmit.edu.au  Fri Feb 22 03:27:43 2002
From: ajk@mds.rmit.edu.au (Alan Kent)
Date: Fri, 22 Feb 2002 14:27:43 +1100
Subject: [OAI-implementers] OAI Identifiers
In-Reply-To: <Pine.LNX.4.44.0202191037450.23996-100000@ice.cs.cornell.edu>; from Simeon Warner on Tue, Feb 19, 2002 at 10:45:58AM -0500
References: <00d701c1b93d$8be5a070$14414e98@Shrek> <Pine.LNX.4.44.0202191037450.23996-100000@ice.cs.cornell.edu>
Message-ID: <20020222142743.H7920@io.mds.rmit.edu.au>

On Tue, Feb 19, 2002 at 10:45:58AM -0500, Simeon Warner wrote:
> If I recall, when the oai identifier scheme was proposed it was felt that
> benefit of a layer of abstract permitting persisitence of ids even if URLs
> change outweighed the possible registration difficulties.

I think the abstraction is useful, but I am possibly interested in OAI
in other domains than digitial libraries, so registration might be
a bit more problematic (that is, they might not want to register
with a central service).

> Note that the
> schema says:
>     <!-- * A "repositoryIdentifier" that is a unique identifier for a -->
>     <!-- repository.  Its uniqueness will be tested as part of a -->
>     <!-- registration process.  The repositoryIdentifier is case -->
>     <!-- sensitive and may contain the characters [a-z]|[A-Z]|[0-9] -->
>     <!-- e.g. arXiv, VTETD. -->

If you allowed '.' in the name then sites (and maybe '-'?), then you could
at least use domain names. oai:mds.rmit.edu.au:1234. It would not be
mandated, but people would be reasonably confident of having a unique
name without collision. They can always tack something on the start
if they have to repositories on one site. But I am really suggesting
this as something a site could choose to do if it does not want to
go to the global registry.

Digitial Libraries might want to keep OAI in-house. The idea of central
registries just seems a pain if the protocol ever took off. Reusing
domain names registry processes would be an easy 'convention' to 
follow without having to go to the extreme of full URLs.

> Note also that OAI-PMH does not mandate this scheme and not all registered
> repositories have chosen to use it.

Yes, I noticed 'mit.ethese', 'UKOLN-ejournals', and 'NSDL-DEV-CU'.
Should I then fail to harvest these sites? :-)

Alan

From simeon@cs.cornell.edu  Fri Feb 22 14:17:20 2002
From: simeon@cs.cornell.edu (Simeon Warner)
Date: Fri, 22 Feb 2002 09:17:20 -0500 (EST)
Subject: [OAI-implementers] OAI Identifiers
In-Reply-To: <20020222142743.H7920@io.mds.rmit.edu.au>
Message-ID: <Pine.LNX.4.44.0202220902460.31262-100000@ice.cs.cornell.edu>

On Fri, 22 Feb 2002, Alan Kent wrote:
<chopped>
> > Note that the
> > schema says:
> >     <!-- * A "repositoryIdentifier" that is a unique identifier for a -->
> >     <!-- repository.  Its uniqueness will be tested as part of a -->
> >     <!-- registration process.  The repositoryIdentifier is case -->
> >     <!-- sensitive and may contain the characters [a-z]|[A-Z]|[0-9] -->
> >     <!-- e.g. arXiv, VTETD. -->
> 
> If you allowed '.' in the name then sites (and maybe '-'?), then you could
> at least use domain names. oai:mds.rmit.edu.au:1234. It would not be
> mandated, but people would be reasonably confident of having a unique
> name without collision. They can always tack something on the start
> if they have to repositories on one site. But I am really suggesting
> this as something a site could choose to do if it does not want to
> go to the global registry.
>
> Digitial Libraries might want to keep OAI in-house. The idea of central
> registries just seems a pain if the protocol ever took off. Reusing
> domain names registry processes would be an easy 'convention' to 
> follow without having to go to the extreme of full URLs.

I don't see harm in allowing also '-' and '.'. (I wouldn't want to make it
case insensitive.) However, without some enforceable policy about naming
(avoiding the need for OAI registration which currently solves the
uniqueness problem) does this really buy us anything? After all, I could
use identifiers "http://arXiv.org/abs/hep-th/9901001" and such for arXiv
but I choose to use the simpler oai scheme "oai:arXiv:hep-th/9901001".
 
I don't see that there is any collision problem for in-house use. Instead
of a global registry you have one local-one (likely a person coordinating
the effort).

> > Note also that OAI-PMH does not mandate this scheme and not all registered
> > repositories have chosen to use it.
> 
> Yes, I noticed 'mit.ethese', 'UKOLN-ejournals', and 'NSDL-DEV-CU'.
> Should I then fail to harvest these sites? :-)

You could _choose_ to harvest only sites that use oai identifiers but it
was never the intention to force this scheme on everyone. These sites can
still be 'OAI compliant'.

Cheers,
Simeon.



From khage@umich.edu  Mon Feb 25 15:54:48 2002
From: khage@umich.edu (Kat Hagedorn)
Date: Mon, 25 Feb 2002 10:54:48 -0500
Subject: [OAI-implementers] Launch of OAIster Project
Message-ID: <FEDABD78-2A07-11D6-900A-0003934CA344@umich.edu>

Everyone,

We at the Digital Library Production Service of the University of 
Michigan Libraries are pleased to announce the recent launch of the 
OAIster project. You can access our project site at 
http://oaister.umdl.umich.edu/.

The OAIster project is one of the Metadata Harvesting Initiative Mellon 
Foundation grants awarded to 7 institutions in July 2001. We are 
collaborating with UIUC, one of these institutions, to develop a search 
service using the harvester that they are building.

Our goal is to create a wide-ranging repository of free, useful, 
previously difficult-to-access digital resources irrespective of subject 
area or format that is easily searchable by anyone. The novelty of this 
service is multi-fold:

 Our service will reveal digital resources previously "hidden" from 
users behind web scripts, using the OAI metadata harvesting protocol.

 There won't be any dead ends. Users will not be retrieving merely 
information (metadata) about resources -- they will have access to the 
real things.

 The service will provide one-stop "shopping" for users interested in 
useful digital resources.

 Digital resources will be easily findable and viewable through our 
service. The middleware DLPS uses to index these resources makes this 
possible (http://www.dlxs.org/aboutdlxs.html).

At the same time, we are launching a survey, designed to reveal how 
people use digital resources and what features would interest them in 
the OAIster service. The survey can be taken at 
http://www.surveymonkey.com/s.asp?u=1429194588. Please do take the 
survey, and forward it to anyone you know who uses or is interested in 
using digital resources.

If you have any questions about our service, please don't hesitate to 
contact me.

Thanks,
Kat

-------------------
Kat Hagedorn
OAIster Librarian
Digital Library Production Service
University of Michigan
khage@umich.edu
734-647-8000 (not a direct line)


From Martin Vesely <Martin.Vesely@cern.ch>  Mon Feb 25 19:02:45 2002
From: Martin Vesely <Martin.Vesely@cern.ch> (Martin Vesely)
Date: Mon, 25 Feb 2002 20:02:45 +0100 (CET)
Subject: [OAI-implementers] OAI Aggregator
In-Reply-To: <20020214102148.A5577@io.mds.rmit.edu.au>
Message-ID: <Pine.LNX.3.95a.1020225190022.10956C-100000@lxplus026.cern.ch>

Hello,


>Having read the article http://documents.cern.ch/ettdh/doc/public/OAIRSF.html
>which talks about hierarchical harvesting, is the idea then for this
>package to collect data from multiple data providers, then provide the
>data to multiple service providers?

For detailed description of hierarchical harvesting see:
http://www.dlib.org/dlib/april01/liu/04liu.html

This is an architectural issue and I think as such it does not cause
conflicts.

The critical point here is the usage of OAI identifiers, depending on the
interpretation of OAI-PMH statement. Reading the protocol:



"A unique identifier is a key for extracting metadata from an item in a
repository.",



the intepretation of this statement seems ambiguous and I think that
Alan's question was answered for one instance only (OAIA), but not in
general, as this concerns all service providers that act as data providers
at the same time: 

>Hmmm, serious question time!
>
>Does the aggregator keep the original identifiers for metadata (or
>assign new local identifiers)?

So the question is: Does the protocol require that service providers keep
the original identifiers?



Thank you,
Martin

--
CERN Document Server ** <http://cds.cern.ch/> ** <cds.support@cern.ch>
Room: Bldg 510-1-015 ** Voice: +41-22-7673527 ** Fax: +41-22-7678142



From ajk@mds.rmit.edu.au  Thu Feb 28 23:05:27 2002
From: ajk@mds.rmit.edu.au (Alan Kent)
Date: Fri, 1 Mar 2002 10:05:27 +1100
Subject: [OAI-implementers] OAI 2.0? (XML namespaces change request)
Message-ID: <20020301100527.B12806@io.mds.rmit.edu.au>

Is OAI 2.0 still planned to be released end of March (or is my
memory faulty)? I am not sure if this is the forum for change
requests, but I have one hopefully minor thing I would like to
see changed. This may be a known issue, but I just hit it in
some code I was writing, so thought I would mail again just
in case.

At present, a separate namespace is defined per verb (GetRecords,
ListRecords, etc). Could this be changed for one namespace for 
an OAI version? I can see no benefit in having one namespace
per verb, and there are real disadvantages when tryiing to
write namespace aware code.

At the risk of preaching to the knowledgable, when you use a
namespace aware tool, the element name is not just the name
in the tag (<record>, <metadata> etc), its the element name
(local name) plus the namespace name. For convenience, some
people write this as {http://www.openarchives.org/OAI/1.1/GetRecord}record
(I might have the namespace wrong, but you get the idea).

I am in the process of reworking my harvester code based on my
better knoweldge and experience with OAI. It turns out my old
program discarded some information that was important - so I
have to recrawl everything <:-(. Oh well. So the new code I
am trying to do correctly with namespaces etc.

The problem I am hitting is that all the full names of elements
change depending on whether its a GetRecord request or a ListRecords
request. I cannot write generic code (easily) to process a
<record> element, because the name is one of

    {http://www.openarchives.org/OAI/1.1/GetRecord}record
    {http://www.openarchives.org/OAI/1.1/ListRecords}record

It is not correct to ignore the namespace name, so everywhere
I check element names, I have to check for multiple element names.

With OAI 2.0 coming along, it would make life easier if a single
namespace URI was used for the whole protocol meaning the <record>
full name in both GetRecord and ListRecords would become

    {http://www.openarchives.org/OAI/2.0/}record

Thanks!
Alan
-- 
Alan Kent (mailto:ajk@mds.rmit.edu.au, http://www.mds.rmit.edu.au)
Postal: Multimedia Database Systems, RMIT, GPO Box 2476V, Melbourne 3001.
Where: RMIT MDS, Bld 91, Level 3, 110 Victoria St, Carlton 3053, VIC Australia.
Phone: +61 3 9925 4114  Reception: +61 3 9925 4099  Fax: +61 3 9925 4098 

From ajk@mds.rmit.edu.au  Thu Feb 28 23:17:37 2002
From: ajk@mds.rmit.edu.au (Alan Kent)
Date: Fri, 1 Mar 2002 10:17:37 +1100
Subject: [OAI-implementers] Interest in search engines?
Message-ID: <20020301101737.C12806@io.mds.rmit.edu.au>

Hi all,

If you read my previous post, you probably know that I am going to
recrawl various OAI sites to rebuild my database. The first time I
did it, I tried to crawl everything in sight to see what happened.

This time around, I was wondering about reducing the list of sites
to crawl. The other thing I was thinking of was making a search
interface available. Is this of interest to anyone? Are people
happy with the status quo in terms of searching capabilities?
I ask only because I can either do whatever I feel like for my
personal satisfaction, or I could investigate providing a bit of a
service to others.

I was also not sure if I hosted a public search service, if I need
to ask permission from data source providers relating to copyright
and other legal issues. Records contain such information,
but I don't want to read through the records one by one! :-)
(This may be an interesting legal issue in its own right.
If someone provides data via OAI, how can a crawler know if
its allow to keep a local copy - or is this implicit by
providing a public OAI interface?)

Please note - I am still not looking at being a data provider, only a
service provider (at this stage anyway). And being in Australia, I am
not sure if (due to network distances and delays) I would be the most
logical site to host a search service. This is also still an evening
play job for me, so I will be doing things with minimal effort. But if
I can help out while playing, I am happy to do so.  And I can probably
convince work to spare me disk space on the public server here if I say
loaded up lots of OAI data and made it available via Z39.50 (XML record
syntax etc), ZiNG, etc as a bit of a demo of our product.

Anyway, if anyone had *needs* that were not being currently met in
terms of searching, it would be interesting to know what they were.

Alan

-- 
Alan Kent (mailto:ajk@mds.rmit.edu.au, http://www.mds.rmit.edu.au)
Postal: Multimedia Database Systems, RMIT, GPO Box 2476V, Melbourne 3001.
Where: RMIT MDS, Bld 91, Level 3, 110 Victoria St, Carlton 3053, VIC Australia.
Phone: +61 3 9925 4114  Reception: +61 3 9925 4099  Fax: +61 3 9925 4098 

